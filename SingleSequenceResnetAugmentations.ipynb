{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SingleSequenceResnetAugmentations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PurabPatel555/SingleSequenceResnetAugmentations/blob/main/SingleSequenceResnetAugmentations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bUnRlr5Plx-"
      },
      "source": [
        "sample_names_indices = []\n",
        "for _, sample_name in enumerate(tqdm(sample_names)):\n",
        "  num_augmentations = get_num_lines(sample_name, TRAIN_PATH)\n",
        "  augmentation_indices = np.zeros(max_augmentations, dtype=int)\n",
        "  for i in range(math.floor(max_augmentations/num_augmentations)):\n",
        "    augmentation_indices_batch = np.arange(num_augmentations)\n",
        "    np.random.shuffle(augmentation_indices_batch)\n",
        "    augmentation_indices = np.concatenate((augmentation_indices, augmentation_indices_batch))\n",
        "  augmentation_indices_batch = np.arange(num_augmentations)\n",
        "  np.random.shuffle(augmentation_indices_batch)\n",
        "  augmentation_indices = np.concatenate((augmentation_indices, augmentation_indices_batch[:(max_augmentations%num_augmentations)]))\n",
        "\n",
        "  sample_names_indices.append([sample_name, augmentation_indices.tolist()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM6UULEXeCgT"
      },
      "source": [
        "def alignment(seq_name, sample_num, label):\n",
        "  with open(os.path.join(AUG_PATH, (seq_name + '.a3m'))) as fp:\n",
        "    for i, line in enumerate(fp):\n",
        "        if i == sample_num:\n",
        "            augmented_seq = line\n",
        "  label_aug = \"\"\n",
        "  augmented_seq = augmented_seq[:-1]\n",
        "  print(augmented_seq)\n",
        "  j = 0\n",
        "  for id, aa in enumerate(augmented_seq):\n",
        "    if (aa == \"-\"):\n",
        "      pass\n",
        "    elif (aa.isupper()):\n",
        "      label_aug += (label[id-j])\n",
        "    else:\n",
        "      j = j+1\n",
        "      label_aug += ('X')\n",
        "  return augmented_seq.replace('-', '').upper(), label_aug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20HR2bw99In9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae08125-a40c-478f-83ad-aa0be3695e4f"
      },
      "source": [
        "#Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYXOvQnWXfV7"
      },
      "source": [
        "def get_num_lines(sample_name, train_path):\n",
        "  full_path = os.path.join(train_path, (sample_name+'.a3m'))\n",
        "  with open(full_path) as file:\n",
        "    lines = len(file.readlines())\n",
        "  return lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7k8AaYlhlCZ"
      },
      "source": [
        "#Paths\n",
        "TRAIN_PATH = '/content/drive/My Drive/Sparks/SPOT-1D-single/data/train/train.DSSP'\n",
        "AUG_PATH = '/content/drive/My Drive/Sparks/datasets/train_aug/a3m-sample'\n",
        "VALID_PATH = '/content/drive/My Drive/Sparks/SPOT-1D-single/data/validation/validation.DSSP'\n",
        "CHECKPOINT_PATH = '/content/drive/My Drive/Sparks/SingleSequenceResnetAugmentationsCheckpoint'\n",
        "MODEL_PATH = '/content/drive/My Drive/Sparks/SingleSequenceResnetAugmentationsModel'\n",
        "TEST_PATH = '/content/drive/My Drive/Sparks/SPOT-1D-single/data/SPOT/SPOT.dssp'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csMIFoF-Bq_u"
      },
      "source": [
        "#Imports\n",
        "import os, sys\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "import math\n",
        "import pickle\n",
        "from random import choice\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66mEdZMEFYD3"
      },
      "source": [
        "#Hyperparameters\n",
        "n_layers = 60\n",
        "n_filters = 60\n",
        "epochs = 100\n",
        "bs_train=1\n",
        "bs_valid=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYzFQhbFighB"
      },
      "source": [
        "#Data exploration and loading\n",
        "\"\"\"\n",
        "The format of this data is:\n",
        ">\n",
        "sequence1\n",
        "structure1\n",
        ">\n",
        "sequence2\n",
        "structure2\n",
        ".\n",
        ".\n",
        ".\n",
        "\"\"\"\n",
        "f = open(TRAIN_PATH, \"r\")\n",
        "sequences = []\n",
        "structures = []\n",
        "while True:\n",
        "  line = f.readline()\n",
        "  if len(line) == 0:\n",
        "    break\n",
        "  if (line.find('>') != -1):\n",
        "    sequence = line[1:].split(\" \")[0]\n",
        "    _ = f.readline()\n",
        "    structure = f.readline()\n",
        "    sequences.append(sequence)\n",
        "    structures.append(structure)\n",
        "f2 = open(VALID_PATH, \"r\")\n",
        "sequences_valid = []\n",
        "structures_valid = []\n",
        "while True:\n",
        "  line = f2.readline()\n",
        "  if len(line) == 0:\n",
        "    break\n",
        "  if ((line).find('>') != -1):\n",
        "    sequence_valid = f2.readline()\n",
        "    structure_valid = f2.readline()\n",
        "    sequences_valid.append(sequence_valid)\n",
        "    structures_valid.append(structure_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFz6nNBM5R2e"
      },
      "source": [
        "sequence_length_exclude = [[sequence, get_num_lines(sequence, AUG_PATH), []] for sequence in tqdm(sequences)]\n",
        "with open('/content/drive/My Drive/Sparks/sequence_length_exclude.pkl', 'wb') as f:\n",
        "  pickle.dump(sequence_length_exclude, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YABlE7KeaqX9"
      },
      "source": [
        "with open('/content/drive/My Drive/Sparks/sequence_length_exclude.pkl', 'rb') as f:\n",
        "  sequence_length_exclude = pickle.load(f)\n",
        "  print(len(sequence_length_exclude))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SblYui_gnAFO"
      },
      "source": [
        "#Create a data generator to load data for training (with augmentations)\n",
        "class DataGeneratorTrain(keras.utils.Sequence):\n",
        "    def alignment(self, seq_name, sample_num, label):\n",
        "      with open(os.path.join(AUG_PATH, (seq_name + '.a3m'))) as fp:\n",
        "        for i, line in enumerate(fp):\n",
        "            if i == sample_num:\n",
        "                augmented_seq = line\n",
        "      label_aug = \"\"\n",
        "      augmented_seq = augmented_seq[:-1]\n",
        "      j = 0\n",
        "      for id2, aa in enumerate(augmented_seq):\n",
        "        if (aa == \"-\"):\n",
        "          pass\n",
        "        elif (aa.isupper()):\n",
        "          label_aug += (label[id2-j])\n",
        "        else:\n",
        "          j = j+1\n",
        "          label_aug += ('X')\n",
        "      return augmented_seq.replace('-', '').upper(), label_aug\n",
        "\n",
        "    def __init__(self, sequences, structures, batch_size=1, shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.structures = structures\n",
        "        self.sequences = sequences\n",
        "        self.shuffle=shuffle\n",
        "        self.on_epoch_end()\n",
        "        for i in range(len(self.sequences)):\n",
        "          self.sequences[i][2] = [] \n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.structures) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        id = indexes[0]\n",
        "        print(id)\n",
        "        seq_data_formatted=[]\n",
        "        str_data_formatted=[]\n",
        "        aas = 'ARNDCEQGHILKMFPSTWYV'  #Amino acid symbols (input feature categories)\n",
        "        aa_to_int = dict((a, i) for i, a in enumerate(aas))\n",
        "        sss = 'GHITEBSCX' #Secondary structure options (output categories) \n",
        "        ss_to_int = dict((s, i) for i, s in enumerate(sss))\n",
        "\n",
        "        condition = True\n",
        "        while condition:\n",
        "          seq_data = self.sequences[id]\n",
        "          print(seq_data[0])\n",
        "          exclude = seq_data[2]\n",
        "          if(seq_data[1]==len(exclude)):\n",
        "            self.sequences[id][2] = [] \n",
        "            exclude = []\n",
        "          aug_choice = choice([i for i in range(int(seq_data[1])) if i not in exclude])\n",
        "          self.sequences[id][2].append(aug_choice) \n",
        "          seq_data, str_data = self.alignment(seq_name=seq_data[0], sample_num=aug_choice, label=self.structures[id][:-1])\n",
        "          #if (((seq_data.find('X') == -1) and (seq_data.find('B') == -1) and (seq_data.find('Z') == -1) and (seq_data.find('U') == -1) and (seq_data.find('O') == -1)) and (str_data.count('X')<len(str_data))):\n",
        "              #break\n",
        "\n",
        "          condition = False\n",
        "          if (str_data.count('X')>=len(str_data)):\n",
        "            condition = True\n",
        "          else:\n",
        "            for character in seq_data:\n",
        "              if aas.find(character) == -1:\n",
        "                condition = True\n",
        "\n",
        "        seq_data = [seq_data]\n",
        "        str_data = [str_data]\n",
        "\n",
        "        #print(seq_data)\n",
        "\n",
        "        lengths = [len(sequence) for sequence in seq_data]  #Keep lengths of each sequence (for later padding purposes)\n",
        "        max_length = max(lengths) #Find the maximum length in the batch (for padding all other sequences to this length)\n",
        "\n",
        "        for seq in seq_data:\n",
        "          padding = max_length-len(seq) #Find the number of padded elements needed in the sequence\n",
        "          integer_encoded_seq = [aa_to_int[aa] for aa in seq] #Encode each amino acid as an integer\n",
        "          integer_encoded_seq = np.pad(integer_encoded_seq, (0,padding), 'constant', constant_values=20)  #Pad \n",
        "          seq_one_hot = np.eye(21)[integer_encoded_seq] #One-hot encoding\n",
        "          seq_data_formatted.append(seq_one_hot.astype('float32'))\n",
        "        X = np.asarray(seq_data_formatted)\n",
        "\n",
        "        for str_ in str_data:\n",
        "          padding = max_length-len(str_)  #Find the number of padded elements needed in the structure\n",
        "          integer_encoded_str = [ss_to_int[ss] for ss in str_]  #Encode each secondary structure element as an integer\n",
        "          integer_encoded_str = np.pad(integer_encoded_str, (0,padding), 'constant', constant_values=8) #Pad\n",
        "          str_one_hot = np.eye(9)[integer_encoded_str]  #One-hot encoding\n",
        "          str_one_hot = str_one_hot[:,:-1]\n",
        "          str_data_formatted.append(str_one_hot.astype('float32'))\n",
        "        y = np.asarray(str_data_formatted)\n",
        "        print(self.sequences[id][2])\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.structures))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpjANdjtYUi6"
      },
      "source": [
        "#Create a data generator for the validation and testing (without augmentations)\n",
        "class DataGeneratorValidTest(keras.utils.Sequence):\n",
        "    def __init__(self, sequences, structures, batch_size=1, shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.structures = structures\n",
        "        self.sequences = sequences\n",
        "        self.shuffle=shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.structures) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        seq_data_formatted=[]\n",
        "        str_data_formatted=[]\n",
        "        aas = 'ARNDCEQGHILKMFPSTWYV'  #Amino acid symbols (input feature categories)\n",
        "        aa_to_int = dict((a, i) for i, a in enumerate(aas))\n",
        "        sss = 'GHITEBSCX' #Secondary structure options (output categories) \n",
        "        ss_to_int = dict((s, i) for i, s in enumerate(sss))\n",
        "        seq_data = [self.sequences[i][:-1] for i in indexes]\n",
        "        lengths = [len(sequence) for sequence in seq_data]  #Keep lengths of each sequence (for later padding purposes)\n",
        "        max_length = max(lengths) #Find the maximum length in the batch (for padding all other sequences to this length)\n",
        "        for seq in seq_data:\n",
        "          padding = max_length-len(seq) #Find the number of padded elements needed in the sequence\n",
        "          integer_encoded_seq = [aa_to_int[aa] for aa in seq] #Encode each amino acid as an integer\n",
        "          integer_encoded_seq = np.pad(integer_encoded_seq, (0,padding), 'constant', constant_values=20)  #Pad \n",
        "          seq_one_hot = np.eye(21)[integer_encoded_seq] #One-hot encoding\n",
        "          seq_data_formatted.append(seq_one_hot.astype('float32'))\n",
        "        X = np.asarray(seq_data_formatted)\n",
        "\n",
        "        str_data = [self.structures[i][:-1] for i in indexes]\n",
        "        for str_ in str_data:\n",
        "          padding = max_length-len(str_)  #Find the number of padded elements needed in the structure\n",
        "          integer_encoded_str = [ss_to_int[ss] for ss in str_]  #Encode each secondary structure element as an integer\n",
        "          integer_encoded_str = np.pad(integer_encoded_str, (0,padding), 'constant', constant_values=8) #Pad\n",
        "          str_one_hot = np.eye(9)[integer_encoded_str]  #One-hot encoding\n",
        "          str_one_hot = str_one_hot[:,:-1]\n",
        "          str_data_formatted.append(str_one_hot.astype('float32'))\n",
        "        y = np.asarray(str_data_formatted)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.structures))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N31HDlJBYPrB"
      },
      "source": [
        "#Define the Resnet model using Keras Functional API\n",
        "def block(input, n_filters, kernel, dilation):  #Helper function to create blocks\n",
        "  output_res = input\n",
        "  output = tf.keras.layers.Conv1D(filters=n_filters, kernel_size=kernel, strides=1, padding='same', dilation_rate=dilation)(input)\n",
        "  output = tfa.layers.InstanceNormalization()(output)\n",
        "  output = tf.keras.layers.ELU(alpha=1.0)(output)\n",
        "  output = tf.keras.layers.Dropout(rate=0.15)(output)\n",
        "  output = tf.keras.layers.Conv1D(filters=n_filters, kernel_size=kernel, strides=1, padding='same', dilation_rate=dilation)(output)\n",
        "  output = tf.keras.layers.ELU(alpha=1.0)(output_res+output)\n",
        "  return output\n",
        "\n",
        "inputs = tf.keras.Input(shape=(None,21), dtype=tf.float32)  #Input layer\n",
        "x = inputs\n",
        "x = tf.keras.layers.Conv1D(filters=n_filters, kernel_size=3, strides=1, padding='same')(x)\n",
        "x = output = tfa.layers.InstanceNormalization()(x)\n",
        "x = tf.keras.layers.ELU(alpha=1.0)(x)\n",
        "\n",
        "dilation = 1\n",
        "for i in range(n_layers):\n",
        "  x = block(input=x, n_filters=n_filters, kernel=3, dilation=dilation)\n",
        "  dilation *= 2\n",
        "  if(dilation == 16):\n",
        "    dilation = 1\n",
        "outputs = x\n",
        "outputs = tf.keras.layers.Conv1D(8, kernel_size=3, strides=1, padding='same')(x)\n",
        "outputs = tf.nn.softmax(outputs)  #Output layer\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfgt4lewdC2B",
        "outputId": "85fd16f8-2c4c-463a-b91a-c1608f52baa0"
      },
      "source": [
        "class MyModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "\n",
        "        inputs, targets = data\n",
        "        trainable_vars = self.trainable_variables\n",
        "        with tf.GradientTape() as tape1:\n",
        "            preds = self(inputs, training=True)  # Forward pass\n",
        "                # Compute the loss value\n",
        "                # (the loss function is configured in `compile()`)\n",
        "            loss = self.compiled_loss(targets, preds)\n",
        "            # Compute first-order gradients\n",
        "        dl_dw = tape1.gradient(loss, trainable_vars)\n",
        "\n",
        "        print(\"Max of dl_dw[0]: %.4f\" % tf.reduce_max(dl_dw[0]))\n",
        "        print(\"Min of dl_dw[0]: %.4f\" % tf.reduce_min(dl_dw[0]))\n",
        "        print(\"Mean of dl_dw[0]: %.4f\" % tf.reduce_mean(dl_dw[0]))\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(dl_dw, trainable_vars))\n",
        "\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "        self.compiled_metrics.update_state(targets, preds)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "model = MyModel(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 21)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_122 (Conv1D)             (None, None, 60)     3840        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_61 (Inst (None, None, 60)     120         conv1d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_121 (ELU)                   (None, None, 60)     0           instance_normalization_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_123 (Conv1D)             (None, None, 60)     10860       elu_121[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_62 (Inst (None, None, 60)     120         conv1d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_122 (ELU)                   (None, None, 60)     0           instance_normalization_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, None, 60)     0           elu_122[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_124 (Conv1D)             (None, None, 60)     10860       dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_60 (TensorFlo [(None, None, 60)]   0           elu_121[0][0]                    \n",
            "                                                                 conv1d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_123 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_60[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_125 (Conv1D)             (None, None, 60)     10860       elu_123[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_63 (Inst (None, None, 60)     120         conv1d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_124 (ELU)                   (None, None, 60)     0           instance_normalization_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, None, 60)     0           elu_124[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_126 (Conv1D)             (None, None, 60)     10860       dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_61 (TensorFlo [(None, None, 60)]   0           elu_123[0][0]                    \n",
            "                                                                 conv1d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_125 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_61[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_127 (Conv1D)             (None, None, 60)     10860       elu_125[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_64 (Inst (None, None, 60)     120         conv1d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_126 (ELU)                   (None, None, 60)     0           instance_normalization_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, None, 60)     0           elu_126[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_128 (Conv1D)             (None, None, 60)     10860       dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_62 (TensorFlo [(None, None, 60)]   0           elu_125[0][0]                    \n",
            "                                                                 conv1d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_127 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_62[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_129 (Conv1D)             (None, None, 60)     10860       elu_127[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_65 (Inst (None, None, 60)     120         conv1d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_128 (ELU)                   (None, None, 60)     0           instance_normalization_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, None, 60)     0           elu_128[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_130 (Conv1D)             (None, None, 60)     10860       dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_63 (TensorFlo [(None, None, 60)]   0           elu_127[0][0]                    \n",
            "                                                                 conv1d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_129 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_63[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_131 (Conv1D)             (None, None, 60)     10860       elu_129[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_66 (Inst (None, None, 60)     120         conv1d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_130 (ELU)                   (None, None, 60)     0           instance_normalization_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, None, 60)     0           elu_130[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_132 (Conv1D)             (None, None, 60)     10860       dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_64 (TensorFlo [(None, None, 60)]   0           elu_129[0][0]                    \n",
            "                                                                 conv1d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_131 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_64[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_133 (Conv1D)             (None, None, 60)     10860       elu_131[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_67 (Inst (None, None, 60)     120         conv1d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_132 (ELU)                   (None, None, 60)     0           instance_normalization_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, None, 60)     0           elu_132[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_134 (Conv1D)             (None, None, 60)     10860       dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_65 (TensorFlo [(None, None, 60)]   0           elu_131[0][0]                    \n",
            "                                                                 conv1d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_133 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_65[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_135 (Conv1D)             (None, None, 60)     10860       elu_133[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_68 (Inst (None, None, 60)     120         conv1d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_134 (ELU)                   (None, None, 60)     0           instance_normalization_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, None, 60)     0           elu_134[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_136 (Conv1D)             (None, None, 60)     10860       dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_66 (TensorFlo [(None, None, 60)]   0           elu_133[0][0]                    \n",
            "                                                                 conv1d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_135 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_66[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_137 (Conv1D)             (None, None, 60)     10860       elu_135[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_69 (Inst (None, None, 60)     120         conv1d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_136 (ELU)                   (None, None, 60)     0           instance_normalization_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, None, 60)     0           elu_136[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_138 (Conv1D)             (None, None, 60)     10860       dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_67 (TensorFlo [(None, None, 60)]   0           elu_135[0][0]                    \n",
            "                                                                 conv1d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_137 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_67[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_139 (Conv1D)             (None, None, 60)     10860       elu_137[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_70 (Inst (None, None, 60)     120         conv1d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_138 (ELU)                   (None, None, 60)     0           instance_normalization_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, None, 60)     0           elu_138[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_140 (Conv1D)             (None, None, 60)     10860       dropout_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_68 (TensorFlo [(None, None, 60)]   0           elu_137[0][0]                    \n",
            "                                                                 conv1d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_139 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_68[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_141 (Conv1D)             (None, None, 60)     10860       elu_139[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_71 (Inst (None, None, 60)     120         conv1d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_140 (ELU)                   (None, None, 60)     0           instance_normalization_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, None, 60)     0           elu_140[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_142 (Conv1D)             (None, None, 60)     10860       dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_69 (TensorFlo [(None, None, 60)]   0           elu_139[0][0]                    \n",
            "                                                                 conv1d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_141 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_143 (Conv1D)             (None, None, 60)     10860       elu_141[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_72 (Inst (None, None, 60)     120         conv1d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_142 (ELU)                   (None, None, 60)     0           instance_normalization_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, None, 60)     0           elu_142[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_144 (Conv1D)             (None, None, 60)     10860       dropout_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_70 (TensorFlo [(None, None, 60)]   0           elu_141[0][0]                    \n",
            "                                                                 conv1d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_143 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_70[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_145 (Conv1D)             (None, None, 60)     10860       elu_143[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_73 (Inst (None, None, 60)     120         conv1d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_144 (ELU)                   (None, None, 60)     0           instance_normalization_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, None, 60)     0           elu_144[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_146 (Conv1D)             (None, None, 60)     10860       dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_71 (TensorFlo [(None, None, 60)]   0           elu_143[0][0]                    \n",
            "                                                                 conv1d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_145 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_71[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_147 (Conv1D)             (None, None, 60)     10860       elu_145[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_74 (Inst (None, None, 60)     120         conv1d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_146 (ELU)                   (None, None, 60)     0           instance_normalization_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, None, 60)     0           elu_146[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_148 (Conv1D)             (None, None, 60)     10860       dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_72 (TensorFlo [(None, None, 60)]   0           elu_145[0][0]                    \n",
            "                                                                 conv1d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_147 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_72[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_149 (Conv1D)             (None, None, 60)     10860       elu_147[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_75 (Inst (None, None, 60)     120         conv1d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_148 (ELU)                   (None, None, 60)     0           instance_normalization_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, None, 60)     0           elu_148[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_150 (Conv1D)             (None, None, 60)     10860       dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_73 (TensorFlo [(None, None, 60)]   0           elu_147[0][0]                    \n",
            "                                                                 conv1d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_149 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_73[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_151 (Conv1D)             (None, None, 60)     10860       elu_149[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_76 (Inst (None, None, 60)     120         conv1d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_150 (ELU)                   (None, None, 60)     0           instance_normalization_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, None, 60)     0           elu_150[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_152 (Conv1D)             (None, None, 60)     10860       dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_74 (TensorFlo [(None, None, 60)]   0           elu_149[0][0]                    \n",
            "                                                                 conv1d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_151 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_74[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_153 (Conv1D)             (None, None, 60)     10860       elu_151[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_77 (Inst (None, None, 60)     120         conv1d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_152 (ELU)                   (None, None, 60)     0           instance_normalization_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, None, 60)     0           elu_152[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_154 (Conv1D)             (None, None, 60)     10860       dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_75 (TensorFlo [(None, None, 60)]   0           elu_151[0][0]                    \n",
            "                                                                 conv1d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_153 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_75[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, None, 60)     10860       elu_153[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_78 (Inst (None, None, 60)     120         conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_154 (ELU)                   (None, None, 60)     0           instance_normalization_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, None, 60)     0           elu_154[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, None, 60)     10860       dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_76 (TensorFlo [(None, None, 60)]   0           elu_153[0][0]                    \n",
            "                                                                 conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_155 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_76[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, None, 60)     10860       elu_155[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_79 (Inst (None, None, 60)     120         conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_156 (ELU)                   (None, None, 60)     0           instance_normalization_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, None, 60)     0           elu_156[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_158 (Conv1D)             (None, None, 60)     10860       dropout_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_77 (TensorFlo [(None, None, 60)]   0           elu_155[0][0]                    \n",
            "                                                                 conv1d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_157 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_77[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_159 (Conv1D)             (None, None, 60)     10860       elu_157[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_80 (Inst (None, None, 60)     120         conv1d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_158 (ELU)                   (None, None, 60)     0           instance_normalization_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, None, 60)     0           elu_158[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_160 (Conv1D)             (None, None, 60)     10860       dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_78 (TensorFlo [(None, None, 60)]   0           elu_157[0][0]                    \n",
            "                                                                 conv1d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_159 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_78[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_161 (Conv1D)             (None, None, 60)     10860       elu_159[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_81 (Inst (None, None, 60)     120         conv1d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_160 (ELU)                   (None, None, 60)     0           instance_normalization_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, None, 60)     0           elu_160[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_162 (Conv1D)             (None, None, 60)     10860       dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_79 (TensorFlo [(None, None, 60)]   0           elu_159[0][0]                    \n",
            "                                                                 conv1d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_161 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_79[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_163 (Conv1D)             (None, None, 60)     10860       elu_161[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_82 (Inst (None, None, 60)     120         conv1d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_162 (ELU)                   (None, None, 60)     0           instance_normalization_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, None, 60)     0           elu_162[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_164 (Conv1D)             (None, None, 60)     10860       dropout_80[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_80 (TensorFlo [(None, None, 60)]   0           elu_161[0][0]                    \n",
            "                                                                 conv1d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_163 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_80[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_165 (Conv1D)             (None, None, 60)     10860       elu_163[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_83 (Inst (None, None, 60)     120         conv1d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_164 (ELU)                   (None, None, 60)     0           instance_normalization_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_81 (Dropout)            (None, None, 60)     0           elu_164[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_166 (Conv1D)             (None, None, 60)     10860       dropout_81[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_81 (TensorFlo [(None, None, 60)]   0           elu_163[0][0]                    \n",
            "                                                                 conv1d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_165 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_81[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_167 (Conv1D)             (None, None, 60)     10860       elu_165[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_84 (Inst (None, None, 60)     120         conv1d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_166 (ELU)                   (None, None, 60)     0           instance_normalization_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_82 (Dropout)            (None, None, 60)     0           elu_166[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_168 (Conv1D)             (None, None, 60)     10860       dropout_82[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_82 (TensorFlo [(None, None, 60)]   0           elu_165[0][0]                    \n",
            "                                                                 conv1d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_167 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_82[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_169 (Conv1D)             (None, None, 60)     10860       elu_167[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_85 (Inst (None, None, 60)     120         conv1d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_168 (ELU)                   (None, None, 60)     0           instance_normalization_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_83 (Dropout)            (None, None, 60)     0           elu_168[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_170 (Conv1D)             (None, None, 60)     10860       dropout_83[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_83 (TensorFlo [(None, None, 60)]   0           elu_167[0][0]                    \n",
            "                                                                 conv1d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_169 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_83[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_171 (Conv1D)             (None, None, 60)     10860       elu_169[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_86 (Inst (None, None, 60)     120         conv1d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_170 (ELU)                   (None, None, 60)     0           instance_normalization_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, None, 60)     0           elu_170[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_172 (Conv1D)             (None, None, 60)     10860       dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_84 (TensorFlo [(None, None, 60)]   0           elu_169[0][0]                    \n",
            "                                                                 conv1d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_171 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_84[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_173 (Conv1D)             (None, None, 60)     10860       elu_171[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_87 (Inst (None, None, 60)     120         conv1d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_172 (ELU)                   (None, None, 60)     0           instance_normalization_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, None, 60)     0           elu_172[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_174 (Conv1D)             (None, None, 60)     10860       dropout_85[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_85 (TensorFlo [(None, None, 60)]   0           elu_171[0][0]                    \n",
            "                                                                 conv1d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_173 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_85[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_175 (Conv1D)             (None, None, 60)     10860       elu_173[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_88 (Inst (None, None, 60)     120         conv1d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_174 (ELU)                   (None, None, 60)     0           instance_normalization_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, None, 60)     0           elu_174[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_176 (Conv1D)             (None, None, 60)     10860       dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_86 (TensorFlo [(None, None, 60)]   0           elu_173[0][0]                    \n",
            "                                                                 conv1d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_175 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_86[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_177 (Conv1D)             (None, None, 60)     10860       elu_175[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_89 (Inst (None, None, 60)     120         conv1d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_176 (ELU)                   (None, None, 60)     0           instance_normalization_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_87 (Dropout)            (None, None, 60)     0           elu_176[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_178 (Conv1D)             (None, None, 60)     10860       dropout_87[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_87 (TensorFlo [(None, None, 60)]   0           elu_175[0][0]                    \n",
            "                                                                 conv1d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_177 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_87[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_179 (Conv1D)             (None, None, 60)     10860       elu_177[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_90 (Inst (None, None, 60)     120         conv1d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_178 (ELU)                   (None, None, 60)     0           instance_normalization_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_88 (Dropout)            (None, None, 60)     0           elu_178[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_180 (Conv1D)             (None, None, 60)     10860       dropout_88[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_88 (TensorFlo [(None, None, 60)]   0           elu_177[0][0]                    \n",
            "                                                                 conv1d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_179 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_88[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_181 (Conv1D)             (None, None, 60)     10860       elu_179[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_91 (Inst (None, None, 60)     120         conv1d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_180 (ELU)                   (None, None, 60)     0           instance_normalization_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_89 (Dropout)            (None, None, 60)     0           elu_180[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_182 (Conv1D)             (None, None, 60)     10860       dropout_89[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_89 (TensorFlo [(None, None, 60)]   0           elu_179[0][0]                    \n",
            "                                                                 conv1d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_181 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_89[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_183 (Conv1D)             (None, None, 60)     10860       elu_181[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_92 (Inst (None, None, 60)     120         conv1d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_182 (ELU)                   (None, None, 60)     0           instance_normalization_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_90 (Dropout)            (None, None, 60)     0           elu_182[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_184 (Conv1D)             (None, None, 60)     10860       dropout_90[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_90 (TensorFlo [(None, None, 60)]   0           elu_181[0][0]                    \n",
            "                                                                 conv1d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_183 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_90[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_185 (Conv1D)             (None, None, 60)     10860       elu_183[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_93 (Inst (None, None, 60)     120         conv1d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_184 (ELU)                   (None, None, 60)     0           instance_normalization_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_91 (Dropout)            (None, None, 60)     0           elu_184[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_186 (Conv1D)             (None, None, 60)     10860       dropout_91[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_91 (TensorFlo [(None, None, 60)]   0           elu_183[0][0]                    \n",
            "                                                                 conv1d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_185 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_91[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_187 (Conv1D)             (None, None, 60)     10860       elu_185[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_94 (Inst (None, None, 60)     120         conv1d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_186 (ELU)                   (None, None, 60)     0           instance_normalization_94[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_92 (Dropout)            (None, None, 60)     0           elu_186[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_188 (Conv1D)             (None, None, 60)     10860       dropout_92[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_92 (TensorFlo [(None, None, 60)]   0           elu_185[0][0]                    \n",
            "                                                                 conv1d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_187 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_92[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_189 (Conv1D)             (None, None, 60)     10860       elu_187[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_95 (Inst (None, None, 60)     120         conv1d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_188 (ELU)                   (None, None, 60)     0           instance_normalization_95[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, None, 60)     0           elu_188[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_190 (Conv1D)             (None, None, 60)     10860       dropout_93[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_93 (TensorFlo [(None, None, 60)]   0           elu_187[0][0]                    \n",
            "                                                                 conv1d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_189 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_93[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_191 (Conv1D)             (None, None, 60)     10860       elu_189[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_96 (Inst (None, None, 60)     120         conv1d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_190 (ELU)                   (None, None, 60)     0           instance_normalization_96[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_94 (Dropout)            (None, None, 60)     0           elu_190[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_192 (Conv1D)             (None, None, 60)     10860       dropout_94[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_94 (TensorFlo [(None, None, 60)]   0           elu_189[0][0]                    \n",
            "                                                                 conv1d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_191 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_94[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_193 (Conv1D)             (None, None, 60)     10860       elu_191[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_97 (Inst (None, None, 60)     120         conv1d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_192 (ELU)                   (None, None, 60)     0           instance_normalization_97[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_95 (Dropout)            (None, None, 60)     0           elu_192[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_194 (Conv1D)             (None, None, 60)     10860       dropout_95[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_95 (TensorFlo [(None, None, 60)]   0           elu_191[0][0]                    \n",
            "                                                                 conv1d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_193 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_95[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_195 (Conv1D)             (None, None, 60)     10860       elu_193[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_98 (Inst (None, None, 60)     120         conv1d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_194 (ELU)                   (None, None, 60)     0           instance_normalization_98[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_96 (Dropout)            (None, None, 60)     0           elu_194[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_196 (Conv1D)             (None, None, 60)     10860       dropout_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_96 (TensorFlo [(None, None, 60)]   0           elu_193[0][0]                    \n",
            "                                                                 conv1d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_195 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_96[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_197 (Conv1D)             (None, None, 60)     10860       elu_195[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_99 (Inst (None, None, 60)     120         conv1d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_196 (ELU)                   (None, None, 60)     0           instance_normalization_99[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_97 (Dropout)            (None, None, 60)     0           elu_196[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_198 (Conv1D)             (None, None, 60)     10860       dropout_97[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_97 (TensorFlo [(None, None, 60)]   0           elu_195[0][0]                    \n",
            "                                                                 conv1d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_197 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_97[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_199 (Conv1D)             (None, None, 60)     10860       elu_197[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_100 (Ins (None, None, 60)     120         conv1d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_198 (ELU)                   (None, None, 60)     0           instance_normalization_100[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_98 (Dropout)            (None, None, 60)     0           elu_198[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_200 (Conv1D)             (None, None, 60)     10860       dropout_98[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_98 (TensorFlo [(None, None, 60)]   0           elu_197[0][0]                    \n",
            "                                                                 conv1d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_199 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_98[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_201 (Conv1D)             (None, None, 60)     10860       elu_199[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_101 (Ins (None, None, 60)     120         conv1d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_200 (ELU)                   (None, None, 60)     0           instance_normalization_101[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_99 (Dropout)            (None, None, 60)     0           elu_200[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_202 (Conv1D)             (None, None, 60)     10860       dropout_99[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_99 (TensorFlo [(None, None, 60)]   0           elu_199[0][0]                    \n",
            "                                                                 conv1d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_201 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_99[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_203 (Conv1D)             (None, None, 60)     10860       elu_201[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_102 (Ins (None, None, 60)     120         conv1d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_202 (ELU)                   (None, None, 60)     0           instance_normalization_102[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_100 (Dropout)           (None, None, 60)     0           elu_202[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_204 (Conv1D)             (None, None, 60)     10860       dropout_100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_100 (TensorFl [(None, None, 60)]   0           elu_201[0][0]                    \n",
            "                                                                 conv1d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_203 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_100[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_205 (Conv1D)             (None, None, 60)     10860       elu_203[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_103 (Ins (None, None, 60)     120         conv1d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_204 (ELU)                   (None, None, 60)     0           instance_normalization_103[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_101 (Dropout)           (None, None, 60)     0           elu_204[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_206 (Conv1D)             (None, None, 60)     10860       dropout_101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_101 (TensorFl [(None, None, 60)]   0           elu_203[0][0]                    \n",
            "                                                                 conv1d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_205 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_101[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_207 (Conv1D)             (None, None, 60)     10860       elu_205[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_104 (Ins (None, None, 60)     120         conv1d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_206 (ELU)                   (None, None, 60)     0           instance_normalization_104[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_102 (Dropout)           (None, None, 60)     0           elu_206[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_208 (Conv1D)             (None, None, 60)     10860       dropout_102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_102 (TensorFl [(None, None, 60)]   0           elu_205[0][0]                    \n",
            "                                                                 conv1d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_207 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_102[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_209 (Conv1D)             (None, None, 60)     10860       elu_207[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_105 (Ins (None, None, 60)     120         conv1d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_208 (ELU)                   (None, None, 60)     0           instance_normalization_105[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, None, 60)     0           elu_208[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_210 (Conv1D)             (None, None, 60)     10860       dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_103 (TensorFl [(None, None, 60)]   0           elu_207[0][0]                    \n",
            "                                                                 conv1d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_209 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_103[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_211 (Conv1D)             (None, None, 60)     10860       elu_209[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_106 (Ins (None, None, 60)     120         conv1d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_210 (ELU)                   (None, None, 60)     0           instance_normalization_106[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, None, 60)     0           elu_210[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_212 (Conv1D)             (None, None, 60)     10860       dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_104 (TensorFl [(None, None, 60)]   0           elu_209[0][0]                    \n",
            "                                                                 conv1d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_211 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_104[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_213 (Conv1D)             (None, None, 60)     10860       elu_211[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_107 (Ins (None, None, 60)     120         conv1d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_212 (ELU)                   (None, None, 60)     0           instance_normalization_107[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, None, 60)     0           elu_212[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_214 (Conv1D)             (None, None, 60)     10860       dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_105 (TensorFl [(None, None, 60)]   0           elu_211[0][0]                    \n",
            "                                                                 conv1d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_213 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_105[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_215 (Conv1D)             (None, None, 60)     10860       elu_213[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_108 (Ins (None, None, 60)     120         conv1d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_214 (ELU)                   (None, None, 60)     0           instance_normalization_108[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, None, 60)     0           elu_214[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_216 (Conv1D)             (None, None, 60)     10860       dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_106 (TensorFl [(None, None, 60)]   0           elu_213[0][0]                    \n",
            "                                                                 conv1d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_215 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_106[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_217 (Conv1D)             (None, None, 60)     10860       elu_215[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_109 (Ins (None, None, 60)     120         conv1d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_216 (ELU)                   (None, None, 60)     0           instance_normalization_109[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, None, 60)     0           elu_216[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_218 (Conv1D)             (None, None, 60)     10860       dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_107 (TensorFl [(None, None, 60)]   0           elu_215[0][0]                    \n",
            "                                                                 conv1d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_217 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_107[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_219 (Conv1D)             (None, None, 60)     10860       elu_217[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_110 (Ins (None, None, 60)     120         conv1d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_218 (ELU)                   (None, None, 60)     0           instance_normalization_110[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, None, 60)     0           elu_218[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_220 (Conv1D)             (None, None, 60)     10860       dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_108 (TensorFl [(None, None, 60)]   0           elu_217[0][0]                    \n",
            "                                                                 conv1d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_219 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_108[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_221 (Conv1D)             (None, None, 60)     10860       elu_219[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_111 (Ins (None, None, 60)     120         conv1d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_220 (ELU)                   (None, None, 60)     0           instance_normalization_111[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, None, 60)     0           elu_220[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_222 (Conv1D)             (None, None, 60)     10860       dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_109 (TensorFl [(None, None, 60)]   0           elu_219[0][0]                    \n",
            "                                                                 conv1d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_221 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_109[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_223 (Conv1D)             (None, None, 60)     10860       elu_221[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_112 (Ins (None, None, 60)     120         conv1d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_222 (ELU)                   (None, None, 60)     0           instance_normalization_112[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, None, 60)     0           elu_222[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_224 (Conv1D)             (None, None, 60)     10860       dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_110 (TensorFl [(None, None, 60)]   0           elu_221[0][0]                    \n",
            "                                                                 conv1d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_223 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_110[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_225 (Conv1D)             (None, None, 60)     10860       elu_223[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_113 (Ins (None, None, 60)     120         conv1d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_224 (ELU)                   (None, None, 60)     0           instance_normalization_113[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, None, 60)     0           elu_224[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_226 (Conv1D)             (None, None, 60)     10860       dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_111 (TensorFl [(None, None, 60)]   0           elu_223[0][0]                    \n",
            "                                                                 conv1d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_225 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_111[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_227 (Conv1D)             (None, None, 60)     10860       elu_225[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_114 (Ins (None, None, 60)     120         conv1d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_226 (ELU)                   (None, None, 60)     0           instance_normalization_114[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, None, 60)     0           elu_226[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_228 (Conv1D)             (None, None, 60)     10860       dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_112 (TensorFl [(None, None, 60)]   0           elu_225[0][0]                    \n",
            "                                                                 conv1d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_227 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_112[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_229 (Conv1D)             (None, None, 60)     10860       elu_227[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_115 (Ins (None, None, 60)     120         conv1d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_228 (ELU)                   (None, None, 60)     0           instance_normalization_115[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, None, 60)     0           elu_228[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_230 (Conv1D)             (None, None, 60)     10860       dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_113 (TensorFl [(None, None, 60)]   0           elu_227[0][0]                    \n",
            "                                                                 conv1d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_229 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_113[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_231 (Conv1D)             (None, None, 60)     10860       elu_229[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_116 (Ins (None, None, 60)     120         conv1d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_230 (ELU)                   (None, None, 60)     0           instance_normalization_116[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, None, 60)     0           elu_230[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_232 (Conv1D)             (None, None, 60)     10860       dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_114 (TensorFl [(None, None, 60)]   0           elu_229[0][0]                    \n",
            "                                                                 conv1d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_231 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_114[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_233 (Conv1D)             (None, None, 60)     10860       elu_231[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_117 (Ins (None, None, 60)     120         conv1d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_232 (ELU)                   (None, None, 60)     0           instance_normalization_117[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, None, 60)     0           elu_232[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_234 (Conv1D)             (None, None, 60)     10860       dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_115 (TensorFl [(None, None, 60)]   0           elu_231[0][0]                    \n",
            "                                                                 conv1d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_233 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_115[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_235 (Conv1D)             (None, None, 60)     10860       elu_233[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_118 (Ins (None, None, 60)     120         conv1d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_234 (ELU)                   (None, None, 60)     0           instance_normalization_118[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_116 (Dropout)           (None, None, 60)     0           elu_234[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_236 (Conv1D)             (None, None, 60)     10860       dropout_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_116 (TensorFl [(None, None, 60)]   0           elu_233[0][0]                    \n",
            "                                                                 conv1d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_235 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_116[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_237 (Conv1D)             (None, None, 60)     10860       elu_235[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_119 (Ins (None, None, 60)     120         conv1d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_236 (ELU)                   (None, None, 60)     0           instance_normalization_119[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_117 (Dropout)           (None, None, 60)     0           elu_236[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_238 (Conv1D)             (None, None, 60)     10860       dropout_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_117 (TensorFl [(None, None, 60)]   0           elu_235[0][0]                    \n",
            "                                                                 conv1d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_237 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_117[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_239 (Conv1D)             (None, None, 60)     10860       elu_237[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_120 (Ins (None, None, 60)     120         conv1d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_238 (ELU)                   (None, None, 60)     0           instance_normalization_120[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_118 (Dropout)           (None, None, 60)     0           elu_238[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_240 (Conv1D)             (None, None, 60)     10860       dropout_118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_118 (TensorFl [(None, None, 60)]   0           elu_237[0][0]                    \n",
            "                                                                 conv1d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_239 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_118[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_241 (Conv1D)             (None, None, 60)     10860       elu_239[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_121 (Ins (None, None, 60)     120         conv1d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_240 (ELU)                   (None, None, 60)     0           instance_normalization_121[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, None, 60)     0           elu_240[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_242 (Conv1D)             (None, None, 60)     10860       dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_119 (TensorFl [(None, None, 60)]   0           elu_239[0][0]                    \n",
            "                                                                 conv1d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "elu_241 (ELU)                   (None, None, 60)     0           tf_op_layer_AddV2_119[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_243 (Conv1D)             (None, None, 8)      1448        elu_241[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Softmax_1 (TensorFl [(None, None, 8)]    0           conv1d_243[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,315,808\n",
            "Trainable params: 1,315,808\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZjdKEL9G7mA"
      },
      "source": [
        "#Masked loss\n",
        "\"\"\"\n",
        "'X' in the structure data corresponds to an unknown label at that position, which must be ignored in the loss\n",
        "\"\"\"\n",
        "def loss(mask_label):\n",
        "    mask_label = K.variable(mask_label)\n",
        "    def masked_cce(y_true, y_pred):\n",
        "        #print(y_true)\n",
        "        #print(y_pred)\n",
        "        mask = K.all(K.equal(y_true, mask_label), axis=-1)\n",
        "        mask = tf.math.logical_not(mask)\n",
        "        y_true = tf.boolean_mask(y_true, mask)\n",
        "        y_pred = tf.boolean_mask(y_pred, mask)\n",
        "        loss = K.categorical_crossentropy(y_true, y_pred)\n",
        "        mask = K.cast(mask, K.floatx())\n",
        "        #print(loss)\n",
        "        #print(mask)\n",
        "        #print(\"----------\")\n",
        "        #print(K.sum(loss)/K.sum(mask))\n",
        "        return K.sum(loss) / K.sum(mask)\n",
        "    return masked_cce\n",
        "\n",
        "masked_cce = loss(np.array([0, 0, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N5gJdJPSs_Y"
      },
      "source": [
        "#Q8 Accuracy (Masked accuracy)\n",
        "def get_accuracy(mask_label):\n",
        "  mask_label = K.variable(mask_label)\n",
        "  def accuracy_fun(y_true, y_pred):\n",
        "    mask = K.all(K.equal(y_true, mask_label), axis=-1)\n",
        "    mask = 1 - K.cast(mask, K.floatx())\n",
        "    m = tf.keras.metrics.CategoricalAccuracy()\n",
        "    m.reset_states()\n",
        "    m.update_state(y_true, y_pred, sample_weight=mask)\n",
        "    accuracy = m.result()\n",
        "    return accuracy\n",
        "  return accuracy_fun \n",
        "\n",
        "accuracy = get_accuracy(np.array([0, 0, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKh9hnb8PV_q"
      },
      "source": [
        "#Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=masked_cce,\n",
        "    metrics = [accuracy] #Comment this out when training to avoid eager mode slowdown,\n",
        ")\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JC1UQLClBks"
      },
      "source": [
        "#Initialize the data generators\n",
        "data_generator_train = DataGeneratorTrain(sequences=sequence_length_exclude, structures=structures[:len(sequence_length_exclude)], batch_size=1)\n",
        "data_generator_valid = DataGeneratorValidTest(sequences=sequences_valid, structures=structures_valid, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzl6ljmICMrn"
      },
      "source": [
        "print(data_generator_valid[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS2VbVwo0hau"
      },
      "source": [
        "#Create an early stopping callback and a model checkpoint callback\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=0)\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=CHECKPOINT_PATH,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKUCHYgTjjnp"
      },
      "source": [
        "#Load most recent checkpoint if applicable\n",
        "model.load_weights(CHECKPOINT_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brYYbThpVtNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91387ad1-090c-4689-845b-f89d7fc33fb8"
      },
      "source": [
        "#Train the model\n",
        "model.fit(\n",
        "    x=data_generator_train,\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    validation_data = data_generator_valid,\n",
        "    callbacks = [early_stopping_callback, model_checkpoint_callback]\n",
        "    )\n",
        "\n",
        "#Save the model\n",
        "model.save(MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "37460/39120 [===========================>..] - ETA: 2:25 - loss: 1.282026240\n",
            "1OVX_1_A\n",
            "[38, 76, 50, 60]\n",
            "37461/39120 [===========================>..] - ETA: 2:25 - loss: 1.281910074\n",
            "1ZGO_1_A\n",
            "[39, 83, 22, 31, 47]\n",
            "37462/39120 [===========================>..] - ETA: 2:25 - loss: 1.281930914\n",
            "1JER_1_A\n",
            "[25, 9, 6, 63, 85]\n",
            "37463/39120 [===========================>..] - ETA: 2:25 - loss: 1.281915780\n",
            "1NPS_1_A\n",
            "[82, 51, 87, 74]\n",
            "37464/39120 [===========================>..] - ETA: 2:25 - loss: 1.281933248\n",
            "2AZW_1_A\n",
            "[92, 90, 74, 31]\n",
            "37465/39120 [===========================>..] - ETA: 2:25 - loss: 1.281923735\n",
            "1R9C_1_A\n",
            "[51, 66, 87, 4]\n",
            "37466/39120 [===========================>..] - ETA: 2:25 - loss: 1.28197851\n",
            "1LJ2_1_A\n",
            "[2, 12, 6, 9]\n",
            "37467/39120 [===========================>..] - ETA: 2:25 - loss: 1.28191466\n",
            "2BZW_2_B\n",
            "[13, 10, 0, 8]\n",
            "37468/39120 [===========================>..] - ETA: 2:25 - loss: 1.281928310\n",
            "3U80_1_A\n",
            "[84, 92, 71, 46]\n",
            "37469/39120 [===========================>..] - ETA: 2:24 - loss: 1.281915934\n",
            "2KZ9_1_A\n",
            "[74, 23, 7, 93]\n",
            "37470/39120 [===========================>..] - ETA: 2:24 - loss: 1.281919156\n",
            "2P1M_d2p1ma2\n",
            "[7, 24, 32, 15]\n",
            "37471/39120 [===========================>..] - ETA: 2:24 - loss: 1.28191646\n",
            "4GY7_1_A\n",
            "[37, 8, 81, 71]\n",
            "37472/39120 [===========================>..] - ETA: 2:24 - loss: 1.281926431\n",
            "2KSL_1_A\n",
            "[0]\n",
            "37473/39120 [===========================>..] - ETA: 2:24 - loss: 1.28196143\n",
            "1K4T_d1k4ta1\n",
            "[11, 70, 95, 46]\n",
            "37474/39120 [===========================>..] - ETA: 2:24 - loss: 1.28196639\n",
            "4KUJ_1_A\n",
            "[51, 31, 57, 87]\n",
            "37475/39120 [===========================>..] - ETA: 2:24 - loss: 1.28194632\n",
            "1X2I_1_A\n",
            "[33, 4, 44, 27]\n",
            "37476/39120 [===========================>..] - ETA: 2:24 - loss: 1.281913539\n",
            "4ZAC_1_A\n",
            "[90, 82, 88, 79]\n",
            "37477/39120 [===========================>..] - ETA: 2:24 - loss: 1.281937972\n",
            "3EAB_2_G\n",
            "[78, 85, 98, 28]\n",
            "37478/39120 [===========================>..] - ETA: 2:24 - loss: 1.281931410\n",
            "2HY5_2_B\n",
            "[69, 89, 57, 27]\n",
            "37479/39120 [===========================>..] - ETA: 2:24 - loss: 1.281924290\n",
            "3FOC_1_A\n",
            "[24, 5, 13, 28]\n",
            "37480/39120 [===========================>..] - ETA: 2:23 - loss: 1.28196355\n",
            "1VP7_d1vp7b-\n",
            "[71, 85, 41, 23]\n",
            "37481/39120 [===========================>..] - ETA: 2:23 - loss: 1.281916499\n",
            "3TVJ_1_A\n",
            "[13, 34, 45, 73]\n",
            "37482/39120 [===========================>..] - ETA: 2:23 - loss: 1.281916855\n",
            "4WFB_5_C\n",
            "[54, 96, 89, 99]\n",
            "37483/39120 [===========================>..] - ETA: 2:23 - loss: 1.281917744\n",
            "3BO6_1_A\n",
            "[6, 23, 18, 7]\n",
            "37484/39120 [===========================>..] - ETA: 2:23 - loss: 1.281922724\n",
            "2ROR_1_A\n",
            "[75, 96, 19, 28]\n",
            "37485/39120 [===========================>..] - ETA: 2:23 - loss: 1.28193496\n",
            "3K9C_1_A\n",
            "[90, 63, 77, 85]\n",
            "37486/39120 [===========================>..] - ETA: 2:23 - loss: 1.281913736\n",
            "3ARX_1_A\n",
            "[27, 63, 94, 32]\n",
            "37487/39120 [===========================>..] - ETA: 2:23 - loss: 1.281928673\n",
            "3MDF_1_A\n",
            "[78, 75, 32, 79]\n",
            "37488/39120 [===========================>..] - ETA: 2:23 - loss: 1.281917924\n",
            "4GHU_1_A\n",
            "[94, 46, 65, 64]\n",
            "37489/39120 [===========================>..] - ETA: 2:23 - loss: 1.281925512\n",
            "2C6U_1_A\n",
            "[57, 66, 71, 19]\n",
            "37490/39120 [===========================>..] - ETA: 2:23 - loss: 1.282036759\n",
            "2Z0X_1_A\n",
            "[86, 46, 67, 12]\n",
            "37491/39120 [===========================>..] - ETA: 2:22 - loss: 1.282034\n",
            "2ZU6_d2zu6f2\n",
            "[38, 30, 48, 29]\n",
            "37492/39120 [===========================>..] - ETA: 2:22 - loss: 1.282024625\n",
            "1FVI_d1fvia1\n",
            "[78, 10, 63, 66]\n",
            "37493/39120 [===========================>..] - ETA: 2:22 - loss: 1.282012824\n",
            "2LPB_2_B\n",
            "[8, 25, 23, 30]\n",
            "37494/39120 [===========================>..] - ETA: 2:22 - loss: 1.282024156\n",
            "3ECQ_1_A\n",
            "3ECQ_1_A\n",
            "3ECQ_1_A\n",
            "[8, 59, 34, 50, 85, 63, 73, 75, 91, 6, 60]\n",
            "37495/39120 [===========================>..] - ETA: 2:22 - loss: 1.282021971\n",
            "2EBS_1_A\n",
            "[14, 5, 70, 6]\n",
            "37496/39120 [===========================>..] - ETA: 2:22 - loss: 1.282035212\n",
            "1GM6_1_A\n",
            "[90, 76, 82, 97]\n",
            "37497/39120 [===========================>..] - ETA: 2:22 - loss: 1.282038216\n",
            "1BMT_1_A\n",
            "[47, 95, 45, 4]\n",
            "37498/39120 [===========================>..] - ETA: 2:22 - loss: 1.282034614\n",
            "4E9J_1_A\n",
            "[97, 83, 24, 61]\n",
            "37499/39120 [===========================>..] - ETA: 2:22 - loss: 1.282031746\n",
            "1F9F_1_A\n",
            "[76, 78, 79, 4]\n",
            "37500/39120 [===========================>..] - ETA: 2:22 - loss: 1.282012978\n",
            "3U5W_1_A\n",
            "[81, 67, 49, 56]\n",
            "37501/39120 [===========================>..] - ETA: 2:22 - loss: 1.282016551\n",
            "4YC2_1_G\n",
            "[95, 72, 73, 76]\n",
            "37502/39120 [===========================>..] - ETA: 2:22 - loss: 1.28205108\n",
            "4P8S_1_A\n",
            "[25, 74, 1, 97]\n",
            "37503/39120 [===========================>..] - ETA: 2:21 - loss: 1.282033416\n",
            "1EA0_1_A\n",
            "[10, 3, 16, 49]\n",
            "37504/39120 [===========================>..] - ETA: 2:21 - loss: 1.282018943\n",
            "4UE1_1_A\n",
            "[50, 87, 37, 13]\n",
            "37505/39120 [===========================>..] - ETA: 2:21 - loss: 1.28203566\n",
            "3TWF_1_A\n",
            "[0]\n",
            "37506/39120 [===========================>..] - ETA: 2:21 - loss: 1.282034277\n",
            "3X27_1_A\n",
            "[83, 70, 15, 67]\n",
            "37507/39120 [===========================>..] - ETA: 2:21 - loss: 1.282035804\n",
            "3U3G_1_D\n",
            "[22, 41, 36, 63]\n",
            "37508/39120 [===========================>..] - ETA: 2:21 - loss: 1.282013233\n",
            "4NM3_2_B\n",
            "[3, 33, 0, 5]\n",
            "37509/39120 [===========================>..] - ETA: 2:21 - loss: 1.282010108\n",
            "1VQP_d1vqpe2\n",
            "[61, 92, 85, 15]\n",
            "37510/39120 [===========================>..] - ETA: 2:21 - loss: 1.282032470\n",
            "4EB7_2_C\n",
            "[36, 13, 27, 18]\n",
            "37511/39120 [===========================>..] - ETA: 2:21 - loss: 1.28202253\n",
            "3A35_1_A\n",
            "[31, 22, 44, 52]\n",
            "37512/39120 [===========================>..] - ETA: 2:21 - loss: 1.282038898\n",
            "2HFE_d2hfed1\n",
            "[58, 95, 43, 18]\n",
            "37513/39120 [===========================>..] - ETA: 2:21 - loss: 1.282036441\n",
            "4YBQ_1_A\n",
            "[26, 5, 72, 89]\n",
            "37514/39120 [===========================>..] - ETA: 2:20 - loss: 1.282035867\n",
            "2Q5X_1_A\n",
            "[26, 86, 40, 35]\n",
            "37515/39120 [===========================>..] - ETA: 2:20 - loss: 1.28209999\n",
            "3OXH_1_A\n",
            "[18, 12, 95, 88]\n",
            "37516/39120 [===========================>..] - ETA: 2:20 - loss: 1.282027324\n",
            "4WJ3_3_C\n",
            "[85, 92, 70, 33]\n",
            "37517/39120 [===========================>..] - ETA: 2:20 - loss: 1.282032\n",
            "3CZ7_1_A\n",
            "[75, 23, 93, 1]\n",
            "37518/39120 [===========================>..] - ETA: 2:20 - loss: 1.28209574\n",
            "1Q15_d1q15d2\n",
            "[4, 9, 62, 1]\n",
            "37519/39120 [===========================>..] - ETA: 2:20 - loss: 1.282011500\n",
            "2YN2_1_A\n",
            "[72, 82, 51, 83]\n",
            "37520/39120 [===========================>..] - ETA: 2:20 - loss: 1.282017730\n",
            "1G29_d1g2924\n",
            "[50, 41, 96, 98]\n",
            "37521/39120 [===========================>..] - ETA: 2:20 - loss: 1.28205302\n",
            "1GT0_4_D\n",
            "[65, 1, 34, 79]\n",
            "37522/39120 [===========================>..] - ETA: 2:20 - loss: 1.28206222\n",
            "1KWG_d1kwga1\n",
            "[22, 38, 87, 98]\n",
            "37523/39120 [===========================>..] - ETA: 2:20 - loss: 1.28202761\n",
            "1HPI_1_A\n",
            "[40, 13, 14, 67]\n",
            "37524/39120 [===========================>..] - ETA: 2:20 - loss: 1.28207003\n",
            "4CQB_1_A\n",
            "[72, 66, 51, 92]\n",
            "37525/39120 [===========================>..] - ETA: 2:19 - loss: 1.282017514\n",
            "4O1R_1_A\n",
            "[99, 75, 0, 39]\n",
            "37526/39120 [===========================>..] - ETA: 2:19 - loss: 1.28202113\n",
            "2PMV_1_A\n",
            "[26, 53, 57, 75]\n",
            "37527/39120 [===========================>..] - ETA: 2:19 - loss: 1.28203636\n",
            "3J9W_39_BH\n",
            "[74, 46, 30, 47]\n",
            "37528/39120 [===========================>..] - ETA: 2:19 - loss: 1.28207738\n",
            "2A1S_1_A\n",
            "[75, 99, 88, 13]\n",
            "37529/39120 [===========================>..] - ETA: 2:19 - loss: 1.282036740\n",
            "4AG7_1_A\n",
            "[60, 65, 75, 69]\n",
            "37530/39120 [===========================>..] - ETA: 2:19 - loss: 1.282022202\n",
            "2W2S_1_A\n",
            "[1, 2, 4, 3]\n",
            "37531/39120 [===========================>..] - ETA: 2:19 - loss: 1.282036119\n",
            "2C6R_1_A\n",
            "[21, 51, 99, 82]\n",
            "37532/39120 [===========================>..] - ETA: 2:19 - loss: 1.282023266\n",
            "2LUU_1_A\n",
            "[25, 30, 81, 31]\n",
            "37533/39120 [===========================>..] - ETA: 2:19 - loss: 1.282013545\n",
            "2M4N_1_A\n",
            "[36, 84, 1, 82]\n",
            "37534/39120 [===========================>..] - ETA: 2:19 - loss: 1.282016995\n",
            "5ICU_1_A\n",
            "[64, 78, 53, 0]\n",
            "37535/39120 [===========================>..] - ETA: 2:19 - loss: 1.282032363\n",
            "4LY4_1_A\n",
            "[17, 89, 36, 58]\n",
            "37536/39120 [===========================>..] - ETA: 2:19 - loss: 1.28206403\n",
            "1VBH_d1vbha2\n",
            "[33, 23, 86, 12]\n",
            "37537/39120 [===========================>..] - ETA: 2:18 - loss: 1.282028703\n",
            "3NCE_d3nceb2\n",
            "[67, 3, 8, 27]\n",
            "37538/39120 [===========================>..] - ETA: 2:18 - loss: 1.28209320\n",
            "1F5J_1_A\n",
            "[46, 2, 39, 96]\n",
            "37539/39120 [===========================>..] - ETA: 2:18 - loss: 1.282021656\n",
            "3H99_1_A\n",
            "[85, 44, 94, 64]\n",
            "37540/39120 [===========================>..] - ETA: 2:18 - loss: 1.282021131\n",
            "4D9B_1_A\n",
            "[86, 65, 77, 53, 79]\n",
            "37541/39120 [===========================>..] - ETA: 2:18 - loss: 1.282012213\n",
            "2MVN_1_A\n",
            "[30, 17, 85, 2]\n",
            "37542/39120 [===========================>..] - ETA: 2:18 - loss: 1.282018630\n",
            "1AVW_2_B\n",
            "[76, 68, 18, 22]\n",
            "37543/39120 [===========================>..] - ETA: 2:18 - loss: 1.282028080\n",
            "2NTX_1_A\n",
            "[55, 43, 56, 48]\n",
            "37544/39120 [===========================>..] - ETA: 2:18 - loss: 1.28207119\n",
            "4WZ9_1_A\n",
            "[31, 90, 58, 11]\n",
            "37545/39120 [===========================>..] - ETA: 2:18 - loss: 1.282033147\n",
            "1T6S_1_A\n",
            "[30, 5, 27, 87]\n",
            "37546/39120 [===========================>..] - ETA: 2:18 - loss: 1.282023515\n",
            "2YNY_1_A\n",
            "[53, 52, 80, 34]\n",
            "37547/39120 [===========================>..] - ETA: 2:18 - loss: 1.282038799\n",
            "2ZK9_1_X\n",
            "[21, 12, 34, 52]\n",
            "37548/39120 [===========================>..] - ETA: 2:17 - loss: 1.281928627\n",
            "2YVR_1_A\n",
            "[14, 64, 38, 66]\n",
            "37549/39120 [===========================>..] - ETA: 2:17 - loss: 1.282030474\n",
            "3MAJ_1_A\n",
            "[84, 81, 29, 9]\n",
            "37550/39120 [===========================>..] - ETA: 2:17 - loss: 1.282038339\n",
            "3FBY_1_A\n",
            "[68, 96, 92, 17]\n",
            "37551/39120 [===========================>..] - ETA: 2:17 - loss: 1.282011561\n",
            "3CHX_1_A\n",
            "[92, 51, 83, 11]\n",
            "37552/39120 [===========================>..] - ETA: 2:17 - loss: 1.282037302\n",
            "2FOK_1_A\n",
            "[17, 45, 53, 30, 12]\n",
            "37553/39120 [===========================>..] - ETA: 2:17 - loss: 1.282029696\n",
            "1W0H_1_A\n",
            "[91, 1, 80, 84]\n",
            "37554/39120 [===========================>..] - ETA: 2:17 - loss: 1.282019544\n",
            "4V3P_28_SN\n",
            "[23, 72, 47, 3]\n",
            "37555/39120 [===========================>..] - ETA: 2:17 - loss: 1.28202611\n",
            "1OEY_1_A\n",
            "[49, 60, 85, 63]\n",
            "37556/39120 [===========================>..] - ETA: 2:17 - loss: 1.282024496\n",
            "3CLW_1_A\n",
            "[87, 56, 31, 89]\n",
            "37557/39120 [===========================>..] - ETA: 2:17 - loss: 1.282026687\n",
            "1BCP_d1bcph2\n",
            "[3, 0, 1, 2]\n",
            "37558/39120 [===========================>..] - ETA: 2:17 - loss: 1.28202390\n",
            "1MSH_1_A\n",
            "[2, 8, 37, 11]\n",
            "37559/39120 [===========================>..] - ETA: 2:16 - loss: 1.282034564\n",
            "4MLP_d4mlpd2\n",
            "[8, 42, 94, 61]\n",
            "37560/39120 [===========================>..] - ETA: 2:16 - loss: 1.28201730\n",
            "2CIW_d2ciwa1\n",
            "[76, 93, 8, 86]\n",
            "37561/39120 [===========================>..] - ETA: 2:16 - loss: 1.282022381\n",
            "2EQK_1_A\n",
            "[35, 63, 72, 22]\n",
            "37562/39120 [===========================>..] - ETA: 2:16 - loss: 1.282019842\n",
            "3L84_1_A\n",
            "[7, 80, 0, 93]\n",
            "37563/39120 [===========================>..] - ETA: 2:16 - loss: 1.282024439\n",
            "4EZA_1_A\n",
            "[0, 59, 35, 92]\n",
            "37564/39120 [===========================>..] - ETA: 2:16 - loss: 1.282028049\n",
            "3SYX_1_A\n",
            "[42, 59, 93, 98]\n",
            "37565/39120 [===========================>..] - ETA: 2:16 - loss: 1.282014454\n",
            "1K1B_1_A\n",
            "[29, 84, 83, 9]\n",
            "37566/39120 [===========================>..] - ETA: 2:16 - loss: 1.282019198\n",
            "3C5K_1_A\n",
            "[16, 7, 92, 46]\n",
            "37567/39120 [===========================>..] - ETA: 2:16 - loss: 1.282035269\n",
            "1CQQ_1_A\n",
            "[69, 78, 13, 83]\n",
            "37568/39120 [===========================>..] - ETA: 2:16 - loss: 1.282010429\n",
            "4JRM_d4jrmc1\n",
            "[68, 2, 11, 63]\n",
            "37569/39120 [===========================>..] - ETA: 2:16 - loss: 1.282025693\n",
            "1EK9_1_A\n",
            "[84, 45, 52, 79]\n",
            "37570/39120 [===========================>..] - ETA: 2:16 - loss: 1.28204124\n",
            "2ODK_d2odkd2\n",
            "[78, 80, 56, 84]\n",
            "37571/39120 [===========================>..] - ETA: 2:15 - loss: 1.282022948\n",
            "4QQD_1_A\n",
            "[18, 1, 58, 4]\n",
            "37572/39120 [===========================>..] - ETA: 2:15 - loss: 1.282016010\n",
            "4Y28_14_4\n",
            "[61, 12, 4, 95]\n",
            "37573/39120 [===========================>..] - ETA: 2:15 - loss: 1.282038423\n",
            "3RM3_1_A\n",
            "[19, 41, 68, 10]\n",
            "37574/39120 [===========================>..] - ETA: 2:15 - loss: 1.282014519\n",
            "3H3H_1_A\n",
            "[91, 29, 20, 73]\n",
            "37575/39120 [===========================>..] - ETA: 2:15 - loss: 1.282015231\n",
            "4YGS_1_A\n",
            "[37, 75, 3, 16]\n",
            "37576/39120 [===========================>..] - ETA: 2:15 - loss: 1.28204046\n",
            "3NF2_1_A\n",
            "[88, 20, 49, 24]\n",
            "37577/39120 [===========================>..] - ETA: 2:15 - loss: 1.282025509\n",
            "4ZN1_1_A\n",
            "[98, 74, 64, 21]\n",
            "37578/39120 [===========================>..] - ETA: 2:15 - loss: 1.282016688\n",
            "2C1I_d2c1ia1\n",
            "[72, 27, 97, 91]\n",
            "37579/39120 [===========================>..] - ETA: 2:15 - loss: 1.28203878\n",
            "1LMJ_1_A\n",
            "[88, 74, 49, 81]\n",
            "37580/39120 [===========================>..] - ETA: 2:15 - loss: 1.282016939\n",
            "4WOD_1_A\n",
            "[37, 18, 70, 85, 80]\n",
            "37581/39120 [===========================>..] - ETA: 2:15 - loss: 1.282012262\n",
            "1GVH_d1gvha2\n",
            "[14, 41, 19, 62]\n",
            "37582/39120 [===========================>..] - ETA: 2:14 - loss: 1.28202348\n",
            "3F47_d3f47a2\n",
            "[28, 13, 15, 8]\n",
            "37583/39120 [===========================>..] - ETA: 2:14 - loss: 1.282014972\n",
            "1H6U_d1h6ua1\n",
            "[75, 80, 74, 65]\n",
            "37584/39120 [===========================>..] - ETA: 2:14 - loss: 1.282032299\n",
            "2BE3_1_A\n",
            "[16, 58, 43, 82]\n",
            "37585/39120 [===========================>..] - ETA: 2:14 - loss: 1.282021033\n",
            "2JD4_d2jd4a1\n",
            "[55, 49, 34, 78]\n",
            "37586/39120 [===========================>..] - ETA: 2:14 - loss: 1.282026670\n",
            "3RNS_d3rnsa2\n",
            "[51, 45, 9, 26]\n",
            "37587/39120 [===========================>..] - ETA: 2:14 - loss: 1.282035518\n",
            "4C8I_1_A\n",
            "[34, 78, 30, 83]\n",
            "37588/39120 [===========================>..] - ETA: 2:14 - loss: 1.282029378\n",
            "4M9D_1_A\n",
            "[30, 46, 43, 77]\n",
            "37589/39120 [===========================>..] - ETA: 2:14 - loss: 1.282031069\n",
            "3TJO_1_A\n",
            "[10, 83, 37, 65]\n",
            "37590/39120 [===========================>..] - ETA: 2:14 - loss: 1.282012599\n",
            "5AJ4_45_B9\n",
            "[50, 99, 98, 64]\n",
            "37591/39120 [===========================>..] - ETA: 2:14 - loss: 1.282035171\n",
            "2WSF_15_K\n",
            "[3, 73, 11, 6]\n",
            "37592/39120 [===========================>..] - ETA: 2:14 - loss: 1.28204795\n",
            "2EZL_1_A\n",
            "[21, 89, 70, 80]\n",
            "37593/39120 [===========================>..] - ETA: 2:13 - loss: 1.282010240\n",
            "4OU0_1_A\n",
            "[12, 81, 58, 40]\n",
            "37594/39120 [===========================>..] - ETA: 2:13 - loss: 1.28207748\n",
            "2VGA_1_A\n",
            "[16, 2, 8, 3]\n",
            "37595/39120 [===========================>..] - ETA: 2:13 - loss: 1.282034635\n",
            "3ZPN_1_A\n",
            "[89, 84, 42, 66]\n",
            "37596/39120 [===========================>..] - ETA: 2:13 - loss: 1.282030834\n",
            "3VQF_1_A\n",
            "[18, 74, 14, 31]\n",
            "37597/39120 [===========================>..] - ETA: 2:13 - loss: 1.282012007\n",
            "1UKW_d1ukwb1\n",
            "[59, 19, 88, 49]\n",
            "37598/39120 [===========================>..] - ETA: 2:13 - loss: 1.282023856\n",
            "1NF3_2_C\n",
            "[23, 12, 84, 42]\n",
            "37599/39120 [===========================>..] - ETA: 2:13 - loss: 1.282026917\n",
            "4F7A_1_A\n",
            "[4, 26, 8, 43]\n",
            "37600/39120 [===========================>..] - ETA: 2:13 - loss: 1.28208950\n",
            "3GVA_1_A\n",
            "[42, 86, 2, 23]\n",
            "37601/39120 [===========================>..] - ETA: 2:13 - loss: 1.282011662\n",
            "4F5V_d4f5va2\n",
            "[91, 68, 37, 0, 17]\n",
            "37602/39120 [===========================>..] - ETA: 2:13 - loss: 1.282031710\n",
            "1SGF_3_G\n",
            "[98, 16, 20, 33]\n",
            "37603/39120 [===========================>..] - ETA: 2:13 - loss: 1.28209666\n",
            "2IYA_1_A\n",
            "[97, 74, 26, 86]\n",
            "37604/39120 [===========================>..] - ETA: 2:13 - loss: 1.28206742\n",
            "1EWQ_d1ewqb3\n",
            "[17, 16, 92, 70]\n",
            "37605/39120 [===========================>..] - ETA: 2:12 - loss: 1.282027951\n",
            "4O6D_2_B\n",
            "[16, 81, 7, 55]\n",
            "37606/39120 [===========================>..] - ETA: 2:12 - loss: 1.282034599\n",
            "3LOF_1_A\n",
            "[25, 54, 3, 72]\n",
            "37607/39120 [===========================>..] - ETA: 2:12 - loss: 1.28202045\n",
            "4HST_2_B\n",
            "[2, 15, 10, 55]\n",
            "37608/39120 [===========================>..] - ETA: 2:12 - loss: 1.28207037\n",
            "1MRK_1_A\n",
            "[8, 56, 78, 11, 7]\n",
            "37609/39120 [===========================>..] - ETA: 2:12 - loss: 1.282030040\n",
            "4ESQ_1_A\n",
            "[91, 26, 15, 57]\n",
            "37610/39120 [===========================>..] - ETA: 2:12 - loss: 1.282025991\n",
            "2MW4_1_A\n",
            "[15, 12, 5, 2]\n",
            "37611/39120 [===========================>..] - ETA: 2:12 - loss: 1.282030963\n",
            "4P9F_1_A\n",
            "[76, 28, 39, 40]\n",
            "37612/39120 [===========================>..] - ETA: 2:12 - loss: 1.28201623\n",
            "1KW4_1_A\n",
            "[60, 93, 23, 75]\n",
            "37613/39120 [===========================>..] - ETA: 2:12 - loss: 1.282011848\n",
            "4H7M_1_A\n",
            "[96, 72, 33, 48]\n",
            "37614/39120 [===========================>..] - ETA: 2:12 - loss: 1.28203727\n",
            "1IMU_1_A\n",
            "[9, 53, 19, 82]\n",
            "37615/39120 [===========================>..] - ETA: 2:12 - loss: 1.282034508\n",
            "1V65_d1v65a1\n",
            "[98, 90, 93, 85]\n",
            "37616/39120 [===========================>..] - ETA: 2:11 - loss: 1.282014151\n",
            "2E31_1_A\n",
            "[15, 51, 48, 77]\n",
            "37617/39120 [===========================>..] - ETA: 2:11 - loss: 1.28209881\n",
            "2NZL_1_A\n",
            "[77, 49, 7, 85]\n",
            "37618/39120 [===========================>..] - ETA: 2:11 - loss: 1.282012232\n",
            "4V0W_2_B\n",
            "[5, 55, 39, 54]\n",
            "37619/39120 [===========================>..] - ETA: 2:11 - loss: 1.282031008\n",
            "4IH4_1_A\n",
            "[46, 10, 79, 82]\n",
            "37620/39120 [===========================>..] - ETA: 2:11 - loss: 1.282038224\n",
            "4MK6_1_A\n",
            "[66, 4, 56, 77, 49]\n",
            "37621/39120 [===========================>..] - ETA: 2:11 - loss: 1.282024094\n",
            "3RSJ_d3rsjd2\n",
            "[9, 5, 11, 15]\n",
            "37622/39120 [===========================>..] - ETA: 2:11 - loss: 1.282022979\n",
            "1VK6_1_A\n",
            "[35, 67, 72, 11]\n",
            "37623/39120 [===========================>..] - ETA: 2:11 - loss: 1.282018183\n",
            "1C8N_d1c8nc-\n",
            "[90, 27, 38, 74]\n",
            "37624/39120 [===========================>..] - ETA: 2:11 - loss: 1.282031652\n",
            "3QBY_1_A\n",
            "[69, 86, 51, 9]\n",
            "37625/39120 [===========================>..] - ETA: 2:11 - loss: 1.28203483\n",
            "3J92_47_1\n",
            "3J92_47_1\n",
            "3J92_47_1\n",
            "[64, 82, 53, 84, 62, 17, 73, 43, 94, 23, 13, 68, 80, 59, 58, 6, 70, 37, 72]\n",
            "37626/39120 [===========================>..] - ETA: 2:11 - loss: 1.282031703\n",
            "1PON_2_B\n",
            "[48, 16, 66, 82]\n",
            "37627/39120 [===========================>..] - ETA: 2:10 - loss: 1.282014317\n",
            "3KMV_1_A\n",
            "[59, 26, 8, 31]\n",
            "37628/39120 [===========================>..] - ETA: 2:10 - loss: 1.282017504\n",
            "1XOU_1_A\n",
            "[80, 61, 33, 59, 38]\n",
            "37629/39120 [===========================>..] - ETA: 2:10 - loss: 1.282022826\n",
            "2BO9_d2bo9d1\n",
            "[43, 14, 44, 31]\n",
            "37630/39120 [===========================>..] - ETA: 2:10 - loss: 1.281926761\n",
            "3RGB_1_A\n",
            "[89, 73, 32, 58]\n",
            "37631/39120 [===========================>..] - ETA: 2:10 - loss: 1.282037819\n",
            "4ZFH_1_A\n",
            "[52, 69, 54, 81]\n",
            "37632/39120 [===========================>..] - ETA: 2:10 - loss: 1.282032500\n",
            "2FQC_1_A\n",
            "[5, 0, 6, 3]\n",
            "37633/39120 [===========================>..] - ETA: 2:10 - loss: 1.28206743\n",
            "1EWQ_d1ewqb1\n",
            "[75, 65, 9, 67]\n",
            "37634/39120 [===========================>..] - ETA: 2:10 - loss: 1.282026196\n",
            "2D52_d2d52a1\n",
            "[91, 99, 13, 68]\n",
            "37635/39120 [===========================>..] - ETA: 2:10 - loss: 1.28203863\n",
            "2Z6D_1_A\n",
            "[88, 80, 55, 33]\n",
            "37636/39120 [===========================>..] - ETA: 2:10 - loss: 1.28201747\n",
            "4MO3_1_M\n",
            "[85, 37, 88, 71]\n",
            "37637/39120 [===========================>..] - ETA: 2:10 - loss: 1.282030625\n",
            "2VZS_d2vzsb1\n",
            "[99, 74, 59, 95]\n",
            "37638/39120 [===========================>..] - ETA: 2:10 - loss: 1.28205612\n",
            "1LKD_d1lkda1\n",
            "[19, 55, 36, 62]\n",
            "37639/39120 [===========================>..] - ETA: 2:09 - loss: 1.282028696\n",
            "4FD5_1_A\n",
            "[58, 31, 56, 9]\n",
            "37640/39120 [===========================>..] - ETA: 2:09 - loss: 1.282016951\n",
            "2MXT_1_A\n",
            "[77, 86, 7, 56]\n",
            "37641/39120 [===========================>..] - ETA: 2:09 - loss: 1.282035597\n",
            "5AJ4_82_Bq\n",
            "[19, 56, 39, 18]\n",
            "37642/39120 [===========================>..] - ETA: 2:09 - loss: 1.282037115\n",
            "1JER_d1jera-\n",
            "[51, 15, 11, 39]\n",
            "37643/39120 [===========================>..] - ETA: 2:09 - loss: 1.282030489\n",
            "5A6U_2_B\n",
            "[33, 94, 11, 59]\n",
            "37644/39120 [===========================>..] - ETA: 2:09 - loss: 1.28207381\n",
            "3M1X_1_A\n",
            "[62, 39, 18, 92]\n",
            "37645/39120 [===========================>..] - ETA: 2:09 - loss: 1.282093\n",
            "3N00_2_B\n",
            "[5, 7, 11, 4]\n",
            "37646/39120 [===========================>..] - ETA: 2:09 - loss: 1.282011660\n",
            "4U5W_1_A\n",
            "[27, 2, 38, 79]\n",
            "37647/39120 [===========================>..] - ETA: 2:09 - loss: 1.282034149\n",
            "1BF5_d1bf5a2\n",
            "[11, 38, 37, 87]\n",
            "37648/39120 [===========================>..] - ETA: 2:09 - loss: 1.28203345\n",
            "4KRX_1_A\n",
            "[87, 85, 15, 44]\n",
            "37649/39120 [===========================>..] - ETA: 2:09 - loss: 1.282021474\n",
            "1V2Z_1_A\n",
            "[6, 66, 55, 13]\n",
            "37650/39120 [===========================>..] - ETA: 2:08 - loss: 1.282027590\n",
            "2OSE_1_A\n",
            "[28, 46, 43, 86]\n",
            "37651/39120 [===========================>..] - ETA: 2:08 - loss: 1.282025077\n",
            "3UB1_1_A\n",
            "[64, 96, 52, 61]\n",
            "37652/39120 [===========================>..] - ETA: 2:08 - loss: 1.282026919\n",
            "2I00_d2i00f2\n",
            "[89, 51, 94, 0]\n",
            "37653/39120 [===========================>..] - ETA: 2:08 - loss: 1.282017152\n",
            "2LCQ_1_A\n",
            "[9, 0, 37, 50]\n",
            "37654/39120 [===========================>..] - ETA: 2:08 - loss: 1.28201349\n",
            "1F7U_2_A\n",
            "[14, 46, 96, 12]\n",
            "37655/39120 [===========================>..] - ETA: 2:08 - loss: 1.28204440\n",
            "3S6F_1_A\n",
            "[98, 89, 86, 41]\n",
            "37656/39120 [===========================>..] - ETA: 2:08 - loss: 1.282011840\n",
            "1ATI_1_A\n",
            "[75, 48, 43, 32]\n",
            "37657/39120 [===========================>..] - ETA: 2:08 - loss: 1.282017287\n",
            "1GGP_d1ggpb1\n",
            "[9, 29, 47, 49]\n",
            "37658/39120 [===========================>..] - ETA: 2:08 - loss: 1.282037785\n",
            "3LG8_1_A\n",
            "[97, 26, 41, 32]\n",
            "37659/39120 [===========================>..] - ETA: 2:08 - loss: 1.282030023\n",
            "2NRR_1_A\n",
            "[60, 27, 93, 96]\n",
            "37660/39120 [===========================>..] - ETA: 2:08 - loss: 1.28205564\n",
            "4AAI_1_A\n",
            "[69, 25, 0, 3]\n",
            "37661/39120 [===========================>..] - ETA: 2:08 - loss: 1.282010582\n",
            "3MKT_1_A\n",
            "[82, 44, 78, 2]\n",
            "37662/39120 [===========================>..] - ETA: 2:07 - loss: 1.282028124\n",
            "4Z31_1_A\n",
            "[29, 88, 5, 16]\n",
            "37663/39120 [===========================>..] - ETA: 2:07 - loss: 1.282017791\n",
            "1F52_d1f52l1\n",
            "[14, 86, 62, 4]\n",
            "37664/39120 [===========================>..] - ETA: 2:07 - loss: 1.282031599\n",
            "3I7D_1_A\n",
            "[83, 84, 17, 34]\n",
            "37665/39120 [===========================>..] - ETA: 2:07 - loss: 1.282017253\n",
            "5EWX_1_A\n",
            "[91, 93, 70, 24]\n",
            "37666/39120 [===========================>..] - ETA: 2:07 - loss: 1.282021657\n",
            "3CPG_1_A\n",
            "[22, 2, 26, 31]\n",
            "37667/39120 [===========================>..] - ETA: 2:07 - loss: 1.282012207\n",
            "2OHH_1_A\n",
            "[13, 43, 88, 41]\n",
            "37668/39120 [===========================>..] - ETA: 2:07 - loss: 1.282012489\n",
            "1EP3_d1ep3b1\n",
            "[13, 1, 46, 88]\n",
            "37669/39120 [===========================>..] - ETA: 2:07 - loss: 1.282010884\n",
            "1HA8_1_A\n",
            "[0]\n",
            "37670/39120 [===========================>..] - ETA: 2:07 - loss: 1.282025640\n",
            "4IW4_2_E\n",
            "[37, 43, 58, 84]\n",
            "37671/39120 [===========================>..] - ETA: 2:07 - loss: 1.282011357\n",
            "1K85_1_A\n",
            "[14, 53, 82, 46]\n",
            "37672/39120 [===========================>..] - ETA: 2:07 - loss: 1.282033615\n",
            "3S26_1_A\n",
            "[87, 62, 41, 15]\n",
            "37673/39120 [===========================>..] - ETA: 2:06 - loss: 1.282028379\n",
            "2QHF_1_A\n",
            "[95, 76, 22, 18]\n",
            "37674/39120 [===========================>..] - ETA: 2:06 - loss: 1.282024279\n",
            "2JF1_2_T\n",
            "[92, 22, 82, 59]\n",
            "37675/39120 [===========================>..] - ETA: 2:06 - loss: 1.282035130\n",
            "5FO9_3_C\n",
            "[4, 92, 23, 66, 73]\n",
            "37676/39120 [===========================>..] - ETA: 2:06 - loss: 1.282015500\n",
            "3JBP_66_AZ\n",
            "[30, 40, 17, 5]\n",
            "37677/39120 [===========================>..] - ETA: 2:06 - loss: 1.2820834\n",
            "1A21_d1a21b1\n",
            "[45, 48, 59, 31]\n",
            "37678/39120 [===========================>..] - ETA: 2:06 - loss: 1.28202718\n",
            "1TF7_d1tf7f2\n",
            "[33, 74, 12, 62]\n",
            "37679/39120 [===========================>..] - ETA: 2:06 - loss: 1.282030145\n",
            "3KA2_1_A\n",
            "[22, 12, 37, 95, 65, 86, 60, 62, 69]\n",
            "37680/39120 [===========================>..] - ETA: 2:06 - loss: 1.282013915\n",
            "2J5P_1_A\n",
            "[77, 84, 96, 89]\n",
            "37681/39120 [===========================>..] - ETA: 2:06 - loss: 1.282037995\n",
            "2DOC_1_A\n",
            "[0, 48, 33, 75]\n",
            "37682/39120 [===========================>..] - ETA: 2:06 - loss: 1.282017672\n",
            "1IV0_1_A\n",
            "[5, 26, 41, 18, 39]\n",
            "37683/39120 [===========================>..] - ETA: 2:06 - loss: 1.28204437\n",
            "4YZZ_1_A\n",
            "[45, 66, 41, 32]\n",
            "37684/39120 [===========================>..] - ETA: 2:05 - loss: 1.282036346\n",
            "1ETK_1_A\n",
            "[24, 11, 90, 32]\n",
            "37685/39120 [===========================>..] - ETA: 2:05 - loss: 1.282035932\n",
            "1GWM_1_A\n",
            "[36, 44, 78, 2]\n",
            "37686/39120 [===========================>..] - ETA: 2:05 - loss: 1.282035195\n",
            "4P1X_1_B\n",
            "[2, 14, 3, 90]\n",
            "37687/39120 [===========================>..] - ETA: 2:05 - loss: 1.282026929\n",
            "1N7D_d1n7da3\n",
            "[76, 88, 91, 64]\n",
            "37688/39120 [===========================>..] - ETA: 2:05 - loss: 1.282029827\n",
            "1R4V_1_A\n",
            "[0, 6, 46, 60]\n",
            "37689/39120 [===========================>..] - ETA: 2:05 - loss: 1.282030126\n",
            "1L3W_1_A\n",
            "[75, 60, 26, 3]\n",
            "37690/39120 [===========================>..] - ETA: 2:05 - loss: 1.282037449\n",
            "1FS1_d1fs1d2\n",
            "[78, 17, 8, 29]\n",
            "37691/39120 [===========================>..] - ETA: 2:05 - loss: 1.28209624\n",
            "4G56_1_A\n",
            "[34, 25, 93, 71]\n",
            "37692/39120 [===========================>..] - ETA: 2:05 - loss: 1.282010178\n",
            "1JSD_1_A\n",
            "1JSD_1_A\n",
            "[38, 39, 70, 37, 51]\n",
            "37693/39120 [===========================>..] - ETA: 2:05 - loss: 1.282015171\n",
            "3H4X_1_A\n",
            "[17, 35, 80, 49]\n",
            "37694/39120 [===========================>..] - ETA: 2:05 - loss: 1.282033230\n",
            "4UMA_1_A\n",
            "[26, 74, 50, 10]\n",
            "37695/39120 [===========================>..] - ETA: 2:05 - loss: 1.28208317\n",
            "2JUL_1_A\n",
            "[33, 70, 12, 62]\n",
            "37696/39120 [===========================>..] - ETA: 2:04 - loss: 1.282016883\n",
            "1Q1R_d1q1rb3\n",
            "[62, 66, 58, 37]\n",
            "37697/39120 [===========================>..] - ETA: 2:04 - loss: 1.282010930\n",
            "2V8O_d2v8oa1\n",
            "[59, 84, 19, 78]\n",
            "37698/39120 [===========================>..] - ETA: 2:04 - loss: 1.28209157\n",
            "3SLT_1_A\n",
            "[45, 28, 38, 6]\n",
            "37699/39120 [===========================>..] - ETA: 2:04 - loss: 1.28207227\n",
            "2HO2_1_A\n",
            "[93, 62, 5, 37]\n",
            "37700/39120 [===========================>..] - ETA: 2:04 - loss: 1.282035816\n",
            "2ID4_d2id4b2\n",
            "[86, 49, 90, 46]\n",
            "37701/39120 [===========================>..] - ETA: 2:04 - loss: 1.282025784\n",
            "1RY6_1_A\n",
            "[57, 32, 3, 40]\n",
            "37702/39120 [===========================>..] - ETA: 2:04 - loss: 1.28207482\n",
            "3TPD_1_A\n",
            "[66, 68, 11, 23]\n",
            "37703/39120 [===========================>..] - ETA: 2:04 - loss: 1.282028113\n",
            "3UDU_1_A\n",
            "[87, 91, 62, 53]\n",
            "37704/39120 [===========================>..] - ETA: 2:04 - loss: 1.282027665\n",
            "2MQK_1_A\n",
            "[60, 20, 77, 41]\n",
            "37705/39120 [===========================>..] - ETA: 2:04 - loss: 1.282010996\n",
            "2OTK_2_E\n",
            "[4, 20, 35, 42]\n",
            "37706/39120 [===========================>..] - ETA: 2:04 - loss: 1.282025511\n",
            "1J8C_1_A\n",
            "[54, 97, 63, 77]\n",
            "37707/39120 [===========================>..] - ETA: 2:03 - loss: 1.281923303\n",
            "1RFF_d1rffb1\n",
            "[90, 48, 25, 71]\n",
            "37708/39120 [===========================>..] - ETA: 2:03 - loss: 1.281914569\n",
            "4K0J_1_A\n",
            "[49, 51, 57, 3]\n",
            "37709/39120 [===========================>..] - ETA: 2:03 - loss: 1.282019154\n",
            "2VVR_1_A\n",
            "[36, 90, 75, 46, 92]\n",
            "37710/39120 [===========================>..] - ETA: 2:03 - loss: 1.282019505\n",
            "4CVR_1_A\n",
            "[40, 65, 18, 64]\n",
            "37711/39120 [===========================>..] - ETA: 2:03 - loss: 1.281911805\n",
            "3Q8G_d3q8ga1\n",
            "[75, 14, 54, 38]\n",
            "37712/39120 [===========================>..] - ETA: 2:03 - loss: 1.281932534\n",
            "1JB7_3_B\n",
            "[0, 2, 4, 8]\n",
            "37713/39120 [===========================>..] - ETA: 2:03 - loss: 1.28193959\n",
            "4UEI_1_A\n",
            "[32, 22, 79, 15]\n",
            "37714/39120 [===========================>..] - ETA: 2:03 - loss: 1.28196212\n",
            "2XQ1_1_A\n",
            "[7, 21, 14, 0]\n",
            "37715/39120 [===========================>..] - ETA: 2:03 - loss: 1.281929354\n",
            "3UEP_1_A\n",
            "[99, 21, 30, 91]\n",
            "37716/39120 [===========================>..] - ETA: 2:03 - loss: 1.281938174\n",
            "4EXT_2_B\n",
            "[8, 16, 2, 21]\n",
            "37717/39120 [===========================>..] - ETA: 2:03 - loss: 1.282030721\n",
            "4DOU_d4doua2\n",
            "[66, 10, 94, 34]\n",
            "37718/39120 [===========================>..] - ETA: 2:03 - loss: 1.28194595\n",
            "2PYT_1_A\n",
            "[2, 7, 27, 54]\n",
            "37719/39120 [===========================>..] - ETA: 2:02 - loss: 1.281914315\n",
            "5FMG_13_M\n",
            "[91, 43, 74, 75]\n",
            "37720/39120 [===========================>..] - ETA: 2:02 - loss: 1.281921609\n",
            "4K8X_1_A\n",
            "[3, 12, 87, 35]\n",
            "37721/39120 [===========================>..] - ETA: 2:02 - loss: 1.28194477\n",
            "4YXP_1_A\n",
            "[6, 7, 1, 30]\n",
            "37722/39120 [===========================>..] - ETA: 2:02 - loss: 1.281928259\n",
            "3M50_2_P\n",
            "[67, 43, 58, 24]\n",
            "37723/39120 [===========================>..] - ETA: 2:02 - loss: 1.28197771\n",
            "3NCX_d3ncxb2\n",
            "[17, 2, 7, 8]\n",
            "37724/39120 [===========================>..] - ETA: 2:02 - loss: 1.281938940\n",
            "4Z8E_1_A\n",
            "[5, 86, 61, 24]\n",
            "37725/39120 [===========================>..] - ETA: 2:02 - loss: 1.281935992\n",
            "2LSH_1_A\n",
            "[67, 78, 68, 29]\n",
            "37726/39120 [===========================>..] - ETA: 2:02 - loss: 1.28195467\n",
            "1Q0U_1_A\n",
            "[19, 56, 76, 38]\n",
            "37727/39120 [===========================>..] - ETA: 2:02 - loss: 1.28198527\n",
            "4N5F_d4n5fb1\n",
            "[88, 83, 31, 82]\n",
            "37728/39120 [===========================>..] - ETA: 2:02 - loss: 1.281934787\n",
            "4ZBG_1_A\n",
            "[57, 44, 49, 88]\n",
            "37729/39120 [===========================>..] - ETA: 2:02 - loss: 1.281934767\n",
            "3RPD_1_A\n",
            "[26, 41, 19, 44]\n",
            "37730/39120 [===========================>..] - ETA: 2:01 - loss: 1.281926546\n",
            "3SLR_1_A\n",
            "[68, 71, 58, 87]\n",
            "37731/39120 [===========================>..] - ETA: 2:01 - loss: 1.281919809\n",
            "3RK1_1_A\n",
            "[46, 64, 91, 45]\n",
            "37732/39120 [===========================>..] - ETA: 2:01 - loss: 1.28196154\n",
            "2PFD_1_A\n",
            "[74, 62, 25, 67]\n",
            "37733/39120 [===========================>..] - ETA: 2:01 - loss: 1.281936096\n",
            "1Z4R_1_A\n",
            "[60, 17, 77, 30]\n",
            "37734/39120 [===========================>..] - ETA: 2:01 - loss: 1.28191080\n",
            "1JB0_5_E\n",
            "[79, 45, 92, 14]\n",
            "37735/39120 [===========================>..] - ETA: 2:01 - loss: 1.281921638\n",
            "3LHQ_1_A\n",
            "[91, 26, 18, 70]\n",
            "37736/39120 [===========================>..] - ETA: 2:01 - loss: 1.281910799\n",
            "2NPS_1_A\n",
            "[90, 89, 4, 70]\n",
            "37737/39120 [===========================>..] - ETA: 2:01 - loss: 1.28191499\n",
            "1YQG_d1yqga1\n",
            "[17, 91, 57, 79]\n",
            "37738/39120 [===========================>..] - ETA: 2:01 - loss: 1.281922531\n",
            "4KK0_1_A\n",
            "[31, 99, 29, 54]\n",
            "37739/39120 [===========================>..] - ETA: 2:01 - loss: 1.281932309\n",
            "2UUR_1_A\n",
            "[49, 41, 81, 27]\n",
            "37740/39120 [===========================>..] - ETA: 2:01 - loss: 1.281916395\n",
            "2QT6_d2qt6b2\n",
            "[80, 32, 92, 73]\n",
            "37741/39120 [===========================>..] - ETA: 2:00 - loss: 1.281932106\n",
            "2WW8_1_A\n",
            "[30, 35, 29, 61]\n",
            "37742/39120 [===========================>..] - ETA: 2:00 - loss: 1.281928976\n",
            "3GO6_1_A\n",
            "[85, 13, 24, 88]\n",
            "37743/39120 [===========================>..] - ETA: 2:00 - loss: 1.281922204\n",
            "3AWK_d3awka2\n",
            "[78, 20, 1, 82]\n",
            "37744/39120 [===========================>..] - ETA: 2:00 - loss: 1.28199764\n",
            "2BJ8_d2bj8b1\n",
            "[77, 62, 63, 42]\n",
            "37745/39120 [===========================>..] - ETA: 2:00 - loss: 1.281938135\n",
            "3TVT_d3tvta2\n",
            "[43, 53, 50, 67]\n",
            "37746/39120 [===========================>..] - ETA: 2:00 - loss: 1.281937276\n",
            "3RD2_1_A\n",
            "[5, 61, 86, 55]\n",
            "37747/39120 [===========================>..] - ETA: 2:00 - loss: 1.281911601\n",
            "3ADR_1_A\n",
            "[93, 28, 3, 19]\n",
            "37748/39120 [===========================>..] - ETA: 2:00 - loss: 1.281936683\n",
            "3FS8_1_A\n",
            "[93, 26, 99, 32]\n",
            "37749/39120 [===========================>..] - ETA: 2:00 - loss: 1.281913050\n",
            "3ENW_1_A\n",
            "[76, 90, 26, 50]\n",
            "37750/39120 [===========================>..] - ETA: 2:00 - loss: 1.281929950\n",
            "3V7I_1_A\n",
            "[85, 4, 81, 36]\n",
            "37751/39120 [===========================>..] - ETA: 2:00 - loss: 1.281914683\n",
            "3J47_6_R\n",
            "[83, 50, 73, 0]\n",
            "37752/39120 [===========================>..] - ETA: 2:00 - loss: 1.281922686\n",
            "3K8P_2_D\n",
            "[44, 12, 9, 89]\n",
            "37753/39120 [===========================>..] - ETA: 1:59 - loss: 1.281910693\n",
            "4CRQ_1_A\n",
            "[8, 64, 70, 84]\n",
            "37754/39120 [===========================>..] - ETA: 1:59 - loss: 1.281829185\n",
            "2IKK_1_A\n",
            "[27, 38, 90, 96]\n",
            "37755/39120 [===========================>..] - ETA: 1:59 - loss: 1.281823458\n",
            "3IQ1_1_A\n",
            "[36, 19, 20, 45]\n",
            "37756/39120 [===========================>..] - ETA: 1:59 - loss: 1.281931254\n",
            "4I15_1_A\n",
            "[22, 98, 42, 89]\n",
            "37757/39120 [===========================>..] - ETA: 1:59 - loss: 1.28181556\n",
            "2V24_1_A\n",
            "[46, 24, 6, 93]\n",
            "37758/39120 [===========================>..] - ETA: 1:59 - loss: 1.281835604\n",
            "1ZIK_1_A\n",
            "[5, 27, 63, 54]\n",
            "37759/39120 [===========================>..] - ETA: 1:59 - loss: 1.281833500\n",
            "4RFL_1_A\n",
            "[31, 87, 68, 55]\n",
            "37760/39120 [===========================>..] - ETA: 1:59 - loss: 1.281819685\n",
            "2MES_2_B\n",
            "2MES_2_B\n",
            "2MES_2_B\n",
            "2MES_2_B\n",
            "[74, 42, 10, 83, 59, 6, 17, 41, 69, 92, 61, 67, 20, 28, 9, 63]\n",
            "37761/39120 [===========================>..] - ETA: 1:59 - loss: 1.28185223\n",
            "4FUW_1_A\n",
            "[9, 53, 31, 42]\n",
            "37762/39120 [===========================>..] - ETA: 1:59 - loss: 1.281818325\n",
            "3IYL_2_U\n",
            "[21, 11, 4, 20]\n",
            "37763/39120 [===========================>..] - ETA: 1:59 - loss: 1.281820791\n",
            "1Q7S_1_A\n",
            "[22, 18, 60, 87]\n",
            "37764/39120 [===========================>..] - ETA: 1:58 - loss: 1.281814162\n",
            "3OOO_1_A\n",
            "[96, 6, 86, 5]\n",
            "37765/39120 [===========================>..] - ETA: 1:58 - loss: 1.281818681\n",
            "3KDN_d3kdnj2\n",
            "[6, 93, 63, 18]\n",
            "37766/39120 [===========================>..] - ETA: 1:58 - loss: 1.281816913\n",
            "3JVB_1_A\n",
            "[18, 5, 7, 14, 2]\n",
            "37767/39120 [===========================>..] - ETA: 1:58 - loss: 1.281833619\n",
            "3MCQ_d3mcqa2\n",
            "[83, 54, 4, 3]\n",
            "37768/39120 [===========================>..] - ETA: 1:58 - loss: 1.281819781\n",
            "5FJA_2_B\n",
            "[69, 21, 72, 40]\n",
            "37769/39120 [===========================>..] - ETA: 1:58 - loss: 1.281835772\n",
            "2OLS_1_A\n",
            "[82, 76, 97, 10]\n",
            "37770/39120 [===========================>..] - ETA: 1:58 - loss: 1.281837475\n",
            "1LFW_1_A\n",
            "[19, 38, 42, 37]\n",
            "37771/39120 [===========================>..] - ETA: 1:58 - loss: 1.281927423\n",
            "4V8K_6_AB\n",
            "[3, 9, 63, 13]\n",
            "37772/39120 [===========================>..] - ETA: 1:58 - loss: 1.28192622\n",
            "4OCI_1_A\n",
            "[17, 94, 97, 74]\n",
            "37773/39120 [===========================>..] - ETA: 1:58 - loss: 1.281819559\n",
            "4BGL_1_A\n",
            "[73, 26, 63, 82]\n",
            "37774/39120 [===========================>..] - ETA: 1:58 - loss: 1.281812946\n",
            "2HQB_1_A\n",
            "[92, 19, 94, 90]\n",
            "37775/39120 [===========================>..] - ETA: 1:57 - loss: 1.281838729\n",
            "4EAH_2_A\n",
            "[97, 43, 5, 77]\n",
            "37776/39120 [===========================>..] - ETA: 1:57 - loss: 1.281816946\n",
            "3FRQ_1_A\n",
            "[92, 55, 6, 8]\n",
            "37777/39120 [===========================>..] - ETA: 1:57 - loss: 1.281812365\n",
            "4WY4_3_C\n",
            "[79, 77, 11, 7]\n",
            "37778/39120 [===========================>..] - ETA: 1:57 - loss: 1.28183593\n",
            "1ZOI_1_A\n",
            "[76, 84, 14, 93]\n",
            "37779/39120 [===========================>..] - ETA: 1:57 - loss: 1.281821716\n",
            "2GKO_1_A\n",
            "[82, 35, 80, 57]\n",
            "37780/39120 [===========================>..] - ETA: 1:57 - loss: 1.281834211\n",
            "3OT2_1_A\n",
            "[80, 65, 98, 6]\n",
            "37781/39120 [===========================>..] - ETA: 1:57 - loss: 1.28181231\n",
            "3L09_1_A\n",
            "[29, 90, 94, 88]\n",
            "37782/39120 [===========================>..] - ETA: 1:57 - loss: 1.281829373\n",
            "1RYU_1_A\n",
            "[9, 76, 75, 81]\n",
            "37783/39120 [===========================>..] - ETA: 1:57 - loss: 1.28186951\n",
            "4B6G_1_A\n",
            "[90, 50, 82, 32]\n",
            "37784/39120 [===========================>..] - ETA: 1:57 - loss: 1.281827084\n",
            "4C2M_3_3\n",
            "[60, 55, 8, 27]\n",
            "37785/39120 [===========================>..] - ETA: 1:57 - loss: 1.281822281\n",
            "2R5U_1_A\n",
            "[73, 64, 53, 59]\n",
            "37786/39120 [===========================>..] - ETA: 1:57 - loss: 1.281831249\n",
            "3OYR_1_A\n",
            "[70, 6, 77, 66]\n",
            "37787/39120 [===========================>..] - ETA: 1:56 - loss: 1.28183260\n",
            "1JO8_1_A\n",
            "[21, 50, 16, 86]\n",
            "37788/39120 [===========================>..] - ETA: 1:56 - loss: 1.2818663\n",
            "2CIA_1_A\n",
            "[89, 12, 22, 53]\n",
            "37789/39120 [===========================>..] - ETA: 1:56 - loss: 1.281834314\n",
            "3NVW_d3nvwb1\n",
            "[19, 99, 30, 97]\n",
            "37790/39120 [===========================>..] - ETA: 1:56 - loss: 1.281832373\n",
            "3G8L_1_A\n",
            "[75, 4, 89, 84]\n",
            "37791/39120 [===========================>..] - ETA: 1:56 - loss: 1.281827959\n",
            "4MN4_2_C\n",
            "[53, 35, 54, 62]\n",
            "37792/39120 [===========================>..] - ETA: 1:56 - loss: 1.281832842\n",
            "3HB2_d3hb2p1\n",
            "[98, 52, 21, 84]\n",
            "37793/39120 [===========================>..] - ETA: 1:56 - loss: 1.281820846\n",
            "4G9J_2_C\n",
            "[0]\n",
            "37794/39120 [===========================>..] - ETA: 1:56 - loss: 1.281829428\n",
            "4LOX_1_A\n",
            "[9, 54, 25, 22]\n",
            "37795/39120 [===========================>..] - ETA: 1:56 - loss: 1.28185855\n",
            "1NQZ_1_A\n",
            "[56, 44, 11, 23]\n",
            "37796/39120 [===========================>..] - ETA: 1:56 - loss: 1.281810956\n",
            "1DC1_2_A\n",
            "[40, 22, 17, 16]\n",
            "37797/39120 [===========================>..] - ETA: 1:56 - loss: 1.281838063\n",
            "1C56_1_A\n",
            "[83, 0, 70, 26]\n",
            "37798/39120 [===========================>..] - ETA: 1:55 - loss: 1.281822770\n",
            "2P2V_1_A\n",
            "[37, 85, 99, 7]\n",
            "37799/39120 [===========================>..] - ETA: 1:55 - loss: 1.281816082\n",
            "1KNY_1_A\n",
            "[79, 23, 99, 72]\n",
            "37800/39120 [===========================>..] - ETA: 1:55 - loss: 1.28185533\n",
            "2MQS_2_B\n",
            "[8, 37, 97, 48]\n",
            "37801/39120 [===========================>..] - ETA: 1:55 - loss: 1.281829632\n",
            "2W9X_1_A\n",
            "[3, 59, 64, 2]\n",
            "37802/39120 [===========================>..] - ETA: 1:55 - loss: 1.281833749\n",
            "4RC9_1_A\n",
            "[95, 73, 1, 52]\n",
            "37803/39120 [===========================>..] - ETA: 1:55 - loss: 1.281813889\n",
            "3E8V_1_A\n",
            "[52, 27, 12, 20]\n",
            "37804/39120 [===========================>..] - ETA: 1:55 - loss: 1.281823726\n",
            "3PL9_1_A\n",
            "[91, 60, 43, 7]\n",
            "37805/39120 [===========================>..] - ETA: 1:55 - loss: 1.281826934\n",
            "2XFA_1_A\n",
            "[9, 68, 97, 19]\n",
            "37806/39120 [===========================>..] - ETA: 1:55 - loss: 1.281810763\n",
            "1A7S_1_A\n",
            "[78, 77, 94, 38]\n",
            "37807/39120 [===========================>..] - ETA: 1:55 - loss: 1.28188135\n",
            "2P9X_1_A\n",
            "[8, 19, 17, 10]\n",
            "37808/39120 [===========================>..] - ETA: 1:55 - loss: 1.281831547\n",
            "3SRE_1_A\n",
            "[25, 74, 19, 73]\n",
            "37809/39120 [===========================>..] - ETA: 1:54 - loss: 1.28186197\n",
            "3AXG_1_A\n",
            "[11, 42, 30, 23]\n",
            "37810/39120 [===========================>..] - ETA: 1:54 - loss: 1.281827098\n",
            "3GON_1_A\n",
            "[73, 63, 31, 72]\n",
            "37811/39120 [===========================>..] - ETA: 1:54 - loss: 1.281832917\n",
            "3POM_1_A\n",
            "[74, 1, 28, 33]\n",
            "37812/39120 [===========================>..] - ETA: 1:54 - loss: 1.281835031\n",
            "4U0P_1_B\n",
            "[88, 58, 70, 19]\n",
            "37813/39120 [===========================>..] - ETA: 1:54 - loss: 1.281818177\n",
            "1VBI_1_A\n",
            "[48, 56, 0, 16]\n",
            "37814/39120 [===========================>..] - ETA: 1:54 - loss: 1.281812157\n",
            "2MFN_1_A\n",
            "[44, 35, 20, 50, 3]\n",
            "37815/39120 [===========================>..] - ETA: 1:54 - loss: 1.281827806\n",
            "4KTB_1_A\n",
            "[87, 21, 65, 53]\n",
            "37816/39120 [============================>.] - ETA: 1:54 - loss: 1.28184852\n",
            "2QSB_1_A\n",
            "[23, 98, 66, 16]\n",
            "37817/39120 [============================>.] - ETA: 1:54 - loss: 1.281819023\n",
            "5A4O_1_A\n",
            "[74, 98, 80, 17]\n",
            "37818/39120 [============================>.] - ETA: 1:54 - loss: 1.28184692\n",
            "4Q05_1_A\n",
            "[93, 49, 54, 21]\n",
            "37819/39120 [============================>.] - ETA: 1:54 - loss: 1.281861\n",
            "1QZR_d1qzra1\n",
            "[66, 78, 91, 33]\n",
            "37820/39120 [============================>.] - ETA: 1:54 - loss: 1.281826685\n",
            "4RWT_2_C\n",
            "[14, 88, 77, 12]\n",
            "37821/39120 [============================>.] - ETA: 1:53 - loss: 1.281812634\n",
            "3DIN_3_D\n",
            "[64, 58, 4, 23]\n",
            "37822/39120 [============================>.] - ETA: 1:53 - loss: 1.281828615\n",
            "1DGJ_d1dgja3\n",
            "[12, 38, 45, 81]\n",
            "37823/39120 [============================>.] - ETA: 1:53 - loss: 1.281835796\n",
            "1US7_2_B\n",
            "[3, 31, 41, 4]\n",
            "37824/39120 [============================>.] - ETA: 1:53 - loss: 1.281837020\n",
            "2EW9_d2ew9a2\n",
            "[76, 55, 32, 26]\n",
            "37825/39120 [============================>.] - ETA: 1:53 - loss: 1.281834538\n",
            "2M7G_1_A\n",
            "[58, 49, 64, 11]\n",
            "37826/39120 [============================>.] - ETA: 1:53 - loss: 1.281821250\n",
            "4RPA_1_A\n",
            "[9, 83, 42, 31]\n",
            "37827/39120 [============================>.] - ETA: 1:53 - loss: 1.281810474\n",
            "4DOX_1_A\n",
            "[20, 47, 71, 56]\n",
            "37828/39120 [============================>.] - ETA: 1:53 - loss: 1.281821138\n",
            "4YMX_1_A\n",
            "[62, 55, 76, 40]\n",
            "37829/39120 [============================>.] - ETA: 1:53 - loss: 1.281836609\n",
            "5HRA_1_A\n",
            "[23, 93, 62, 82]\n",
            "37830/39120 [============================>.] - ETA: 1:53 - loss: 1.281826898\n",
            "1U3E_d1u3em1\n",
            "[92, 7, 2, 20]\n",
            "37831/39120 [============================>.] - ETA: 1:53 - loss: 1.281810354\n",
            "1OYW_d1oywa1\n",
            "[75, 97, 93, 29]\n",
            "37832/39120 [============================>.] - ETA: 1:52 - loss: 1.281819329\n",
            "2XOL_1_A\n",
            "[74, 40, 47, 98]\n",
            "37833/39120 [============================>.] - ETA: 1:52 - loss: 1.281828242\n",
            "5E3R_1_A\n",
            "[36, 50, 21, 16]\n",
            "37834/39120 [============================>.] - ETA: 1:52 - loss: 1.28182833\n",
            "5CSI_2_C\n",
            "[90, 7, 76, 75]\n",
            "37835/39120 [============================>.] - ETA: 1:52 - loss: 1.281834421\n",
            "3SYY_1_A\n",
            "[64, 82, 66, 38]\n",
            "37836/39120 [============================>.] - ETA: 1:52 - loss: 1.281835955\n",
            "4V4B_25_BF\n",
            "[73, 2, 18, 54]\n",
            "37837/39120 [============================>.] - ETA: 1:52 - loss: 1.281823527\n",
            "2V0H_1_A\n",
            "[53, 35, 69, 97]\n",
            "37838/39120 [============================>.] - ETA: 1:52 - loss: 1.281816049\n",
            "3COP_1_A\n",
            "[56, 60, 67, 64]\n",
            "37839/39120 [============================>.] - ETA: 1:52 - loss: 1.281829536\n",
            "4GQ4_d4gq4a1\n",
            "[52, 23, 70, 14]\n",
            "37840/39120 [============================>.] - ETA: 1:52 - loss: 1.281835357\n",
            "2O5H_1_A\n",
            "[24, 94, 37, 49]\n",
            "37841/39120 [============================>.] - ETA: 1:52 - loss: 1.281819852\n",
            "4NZF_1_A\n",
            "[28, 3, 42, 37]\n",
            "37842/39120 [============================>.] - ETA: 1:52 - loss: 1.281823106\n",
            "4I9X_d4i9xd2\n",
            "[86, 60, 20, 68]\n",
            "37843/39120 [============================>.] - ETA: 1:52 - loss: 1.281828792\n",
            "3RUI_2_B\n",
            "[67, 84, 25, 97]\n",
            "37844/39120 [============================>.] - ETA: 1:51 - loss: 1.281911463\n",
            "1FCB_1_A\n",
            "[13, 41, 95, 94]\n",
            "37845/39120 [============================>.] - ETA: 1:51 - loss: 1.281914827\n",
            "2BL8_1_A\n",
            "[81, 55, 1, 96]\n",
            "37846/39120 [============================>.] - ETA: 1:51 - loss: 1.281927290\n",
            "1XZW_d1xzwb2\n",
            "[40, 45, 85, 55]\n",
            "37847/39120 [============================>.] - ETA: 1:51 - loss: 1.281926775\n",
            "5AG9_1_A\n",
            "[14, 40, 42, 33]\n",
            "37848/39120 [============================>.] - ETA: 1:51 - loss: 1.281927883\n",
            "4LS9_1_A\n",
            "[71, 3, 24, 35]\n",
            "37849/39120 [============================>.] - ETA: 1:51 - loss: 1.28193804\n",
            "1R8D_3_A\n",
            "[88, 63, 50, 66]\n",
            "37850/39120 [============================>.] - ETA: 1:51 - loss: 1.281927363\n",
            "2Y0N_1_A\n",
            "[4, 55, 63, 73]\n",
            "37851/39120 [============================>.] - ETA: 1:51 - loss: 1.281822455\n",
            "4MT8_1_A\n",
            "[90, 51, 94, 54]\n",
            "37852/39120 [============================>.] - ETA: 1:51 - loss: 1.281827839\n",
            "3FOK_1_A\n",
            "[89, 28, 12, 27]\n",
            "37853/39120 [============================>.] - ETA: 1:51 - loss: 1.28189635\n",
            "4PJ3_1_A\n",
            "[43, 53, 4, 8]\n",
            "37854/39120 [============================>.] - ETA: 1:51 - loss: 1.28181688\n",
            "3MKH_d3mkhd2\n",
            "[51, 96, 72, 20]\n",
            "37855/39120 [============================>.] - ETA: 1:50 - loss: 1.281810211\n",
            "1O6O_2_D\n",
            "[67, 85, 4, 29, 25]\n",
            "37856/39120 [============================>.] - ETA: 1:50 - loss: 1.281819473\n",
            "2BN6_1_A\n",
            "[25, 15, 53, 48]\n",
            "37857/39120 [============================>.] - ETA: 1:50 - loss: 1.281811702\n",
            "1PKP_1_A\n",
            "[64, 3, 23, 99]\n",
            "37858/39120 [============================>.] - ETA: 1:50 - loss: 1.281839056\n",
            "2LYW_1_A\n",
            "[25, 1, 15, 6]\n",
            "37859/39120 [============================>.] - ETA: 1:50 - loss: 1.28187356\n",
            "1A79_1_A\n",
            "[76, 22, 16, 85]\n",
            "37860/39120 [============================>.] - ETA: 1:50 - loss: 1.281826282\n",
            "4MNU_1_A\n",
            "[51, 66, 50, 45]\n",
            "37861/39120 [============================>.] - ETA: 1:50 - loss: 1.281831132\n",
            "3HL8_1_A\n",
            "[22, 45, 49, 68]\n",
            "37862/39120 [============================>.] - ETA: 1:50 - loss: 1.281836025\n",
            "2DRE_1_A\n",
            "[34, 69, 68, 95]\n",
            "37863/39120 [============================>.] - ETA: 1:50 - loss: 1.281827953\n",
            "1DZF_d1dzfa1\n",
            "[70, 71, 38, 36]\n",
            "37864/39120 [============================>.] - ETA: 1:50 - loss: 1.281823368\n",
            "4LG3_1_A\n",
            "[12, 3, 11, 6]\n",
            "37865/39120 [============================>.] - ETA: 1:50 - loss: 1.28184380\n",
            "3VK0_1_A\n",
            "[95, 71, 15, 78]\n",
            "37866/39120 [============================>.] - ETA: 1:49 - loss: 1.281827297\n",
            "3OYZ_1_A\n",
            "[47, 59, 34, 94]\n",
            "37867/39120 [============================>.] - ETA: 1:49 - loss: 1.281819729\n",
            "1OGO_d1ogox2\n",
            "[14, 50, 29, 76]\n",
            "37868/39120 [============================>.] - ETA: 1:49 - loss: 1.28183308\n",
            "3II9_d3ii9d2\n",
            "[7, 55, 5, 86]\n",
            "37869/39120 [============================>.] - ETA: 1:49 - loss: 1.281820296\n",
            "1SZ7_1_A\n",
            "[59, 24, 52, 11]\n",
            "37870/39120 [============================>.] - ETA: 1:49 - loss: 1.281824253\n",
            "3FOB_1_A\n",
            "[12, 93, 75, 84]\n",
            "37871/39120 [============================>.] - ETA: 1:49 - loss: 1.281838964\n",
            "1OFU_d1ofub2\n",
            "[19, 86, 94, 56]\n",
            "37872/39120 [============================>.] - ETA: 1:49 - loss: 1.28189304\n",
            "1VKU_1_A\n",
            "[97, 10, 59, 63]\n",
            "37873/39120 [============================>.] - ETA: 1:49 - loss: 1.2818332\n",
            "4WZA_3_E\n",
            "4WZA_3_E\n",
            "[40, 22, 98, 56, 21]\n",
            "37874/39120 [============================>.] - ETA: 1:49 - loss: 1.281815387\n",
            "3MLZ_3_P\n",
            "[65, 43, 13, 67]\n",
            "37875/39120 [============================>.] - ETA: 1:49 - loss: 1.28185700\n",
            "4AU1_1_A\n",
            "[69, 97, 50, 81]\n",
            "37876/39120 [============================>.] - ETA: 1:49 - loss: 1.281826497\n",
            "4CL2_1_A\n",
            "[45, 53, 89, 26]\n",
            "37877/39120 [============================>.] - ETA: 1:49 - loss: 1.281835098\n",
            "3UEB_1_A\n",
            "[56, 51, 13, 96]\n",
            "37878/39120 [============================>.] - ETA: 1:48 - loss: 1.28189012\n",
            "3B6H_1_A\n",
            "[68, 11, 71, 3]\n",
            "37879/39120 [============================>.] - ETA: 1:48 - loss: 1.281812905\n",
            "1A5J_1_A\n",
            "[34, 88, 31, 36]\n",
            "37880/39120 [============================>.] - ETA: 1:48 - loss: 1.281830654\n",
            "2J8A_1_A\n",
            "[9, 95, 8, 6]\n",
            "37881/39120 [============================>.] - ETA: 1:48 - loss: 1.281725592\n",
            "2E3X_3_C\n",
            "[36, 24, 30, 63]\n",
            "37882/39120 [============================>.] - ETA: 1:48 - loss: 1.281814883\n",
            "1GQE_1_A\n",
            "[62, 49, 77, 72]\n",
            "37883/39120 [============================>.] - ETA: 1:48 - loss: 1.281826118\n",
            "3GM5_1_A\n",
            "[17, 50, 56, 23]\n",
            "37884/39120 [============================>.] - ETA: 1:48 - loss: 1.281817336\n",
            "1P83_1_A\n",
            "[99, 89, 77, 88]\n",
            "37885/39120 [============================>.] - ETA: 1:48 - loss: 1.281814844\n",
            "1EGP_1_A\n",
            "[76, 86, 67, 35]\n",
            "37886/39120 [============================>.] - ETA: 1:48 - loss: 1.281818697\n",
            "1J6Y_1_A\n",
            "[49, 7, 10, 62]\n",
            "37887/39120 [============================>.] - ETA: 1:48 - loss: 1.281812089\n",
            "3HRT_1_A\n",
            "[16, 9, 45, 64]\n",
            "37888/39120 [============================>.] - ETA: 1:48 - loss: 1.281832938\n",
            "4KJM_d4kjmb2\n",
            "[3, 81, 54, 37]\n",
            "37889/39120 [============================>.] - ETA: 1:47 - loss: 1.2818423\n",
            "3TAW_1_A\n",
            "[45, 19, 85, 23]\n",
            "37890/39120 [============================>.] - ETA: 1:47 - loss: 1.281821565\n",
            "1H95_1_A\n",
            "[44, 69, 43, 56]\n",
            "37891/39120 [============================>.] - ETA: 1:47 - loss: 1.281816865\n",
            "5CS0_1_A\n",
            "[93, 98, 41, 92]\n",
            "37892/39120 [============================>.] - ETA: 1:47 - loss: 1.2818741\n",
            "2JG6_1_A\n",
            "[18, 64, 70, 99]\n",
            "37893/39120 [============================>.] - ETA: 1:47 - loss: 1.281823308\n",
            "3WEU_1_A\n",
            "[2, 69, 31, 55]\n",
            "37894/39120 [============================>.] - ETA: 1:47 - loss: 1.28189021\n",
            "1PV9_d1pv9b1\n",
            "[85, 78, 20, 79]\n",
            "37895/39120 [============================>.] - ETA: 1:47 - loss: 1.281826599\n",
            "2V6V_1_A\n",
            "[98, 16, 36, 87]\n",
            "37896/39120 [============================>.] - ETA: 1:47 - loss: 1.281816956\n",
            "1KSI_1_A\n",
            "[20, 83, 98, 38]\n",
            "37897/39120 [============================>.] - ETA: 1:47 - loss: 1.281827895\n",
            "3JU4_d3ju4a2\n",
            "[6, 5, 7, 0]\n",
            "37898/39120 [============================>.] - ETA: 1:47 - loss: 1.281836090\n",
            "1DZK_1_A\n",
            "[99, 76, 88, 64]\n",
            "37899/39120 [============================>.] - ETA: 1:47 - loss: 1.28182721\n",
            "2MGR_d2mgra1\n",
            "[16, 6, 26, 12]\n",
            "37900/39120 [============================>.] - ETA: 1:46 - loss: 1.281813481\n",
            "4KU0_2_D\n",
            "[57, 27, 46, 87]\n",
            "37901/39120 [============================>.] - ETA: 1:46 - loss: 1.281830050\n",
            "3JSY_1_A\n",
            "[83, 24, 51, 27]\n",
            "37902/39120 [============================>.] - ETA: 1:46 - loss: 1.281821439\n",
            "1JHJ_1_A\n",
            "[90, 92, 55, 94]\n",
            "37903/39120 [============================>.] - ETA: 1:46 - loss: 1.281836262\n",
            "2JQQ_1_A\n",
            "[7, 28, 0, 39]\n",
            "37904/39120 [============================>.] - ETA: 1:46 - loss: 1.28186812\n",
            "3F1B_1_A\n",
            "[99, 61, 15, 51]\n",
            "37905/39120 [============================>.] - ETA: 1:46 - loss: 1.281811139\n",
            "3SQZ_d3sqza2\n",
            "[31, 78, 49, 74]\n",
            "37906/39120 [============================>.] - ETA: 1:46 - loss: 1.281823641\n",
            "2WA0_1_A\n",
            "[5, 13, 31, 11]\n",
            "37907/39120 [============================>.] - ETA: 1:46 - loss: 1.281826957\n",
            "1R6T_1_A\n",
            "[29, 99, 72, 51]\n",
            "37908/39120 [============================>.] - ETA: 1:46 - loss: 1.28181781\n",
            "1H64_1_1\n",
            "[5, 46, 90, 36]\n",
            "37909/39120 [============================>.] - ETA: 1:46 - loss: 1.281825380\n",
            "5C39_1_A\n",
            "[70, 79, 4, 20]\n",
            "37910/39120 [============================>.] - ETA: 1:46 - loss: 1.281827671\n",
            "3DU1_1_X\n",
            "[80, 69, 41, 99]\n",
            "37911/39120 [============================>.] - ETA: 1:46 - loss: 1.281835404\n",
            "4JAQ_1_D\n",
            "[42, 77, 11, 53]\n",
            "37912/39120 [============================>.] - ETA: 1:45 - loss: 1.28183310\n",
            "2JMO_1_A\n",
            "[43, 71, 49, 78]\n",
            "37913/39120 [============================>.] - ETA: 1:45 - loss: 1.281832223\n",
            "2PV4_1_A\n",
            "[21, 7, 45, 17]\n",
            "37914/39120 [============================>.] - ETA: 1:45 - loss: 1.2818471\n",
            "2IAK_1_A\n",
            "[73, 53, 49, 89]\n",
            "37915/39120 [============================>.] - ETA: 1:45 - loss: 1.2818181\n",
            "3R24_1_A\n",
            "[69, 3, 4, 24]\n",
            "37916/39120 [============================>.] - ETA: 1:45 - loss: 1.281821725\n",
            "1BUZ_1_A\n",
            "[15, 19, 68, 25]\n",
            "37917/39120 [============================>.] - ETA: 1:45 - loss: 1.281832657\n",
            "1E6V_d1e6ve1\n",
            "[29, 76, 65, 16]\n",
            "37918/39120 [============================>.] - ETA: 1:45 - loss: 1.281828148\n",
            "1MXG_d1mxga1\n",
            "[48, 53, 98, 88]\n",
            "37919/39120 [============================>.] - ETA: 1:45 - loss: 1.281836705\n",
            "4D67_43_u\n",
            "[47, 60, 78, 94]\n",
            "37920/39120 [============================>.] - ETA: 1:45 - loss: 1.28184154\n",
            "4RHB_1_A\n",
            "[93, 80, 24, 98]\n",
            "37921/39120 [============================>.] - ETA: 1:45 - loss: 1.28181715\n",
            "1LCF_d1lcfa2\n",
            "[60, 9, 42, 54]\n",
            "37922/39120 [============================>.] - ETA: 1:45 - loss: 1.281813750\n",
            "3R84_1_A\n",
            "[0, 57, 6, 13]\n",
            "37923/39120 [============================>.] - ETA: 1:44 - loss: 1.281810255\n",
            "3DG6_d3dg6a1\n",
            "[35, 28, 42, 2]\n",
            "37924/39120 [============================>.] - ETA: 1:44 - loss: 1.28189220\n",
            "4CFH_3_C\n",
            "[54, 63, 1, 48]\n",
            "37925/39120 [============================>.] - ETA: 1:44 - loss: 1.28183692\n",
            "4CI2_2_B\n",
            "[20, 51, 0, 74]\n",
            "37926/39120 [============================>.] - ETA: 1:44 - loss: 1.281813842\n",
            "1FAK_4_I\n",
            "[72, 10, 71, 87]\n",
            "37927/39120 [============================>.] - ETA: 1:44 - loss: 1.2818295\n",
            "5FWZ_1_A\n",
            "[50, 67, 57, 84]\n",
            "37928/39120 [============================>.] - ETA: 1:44 - loss: 1.28183767\n",
            "4YKC_1_A\n",
            "[66, 73, 76, 72]\n",
            "37929/39120 [============================>.] - ETA: 1:44 - loss: 1.2818392\n",
            "4RI5_1_A\n",
            "[30, 87, 51, 97]\n",
            "37930/39120 [============================>.] - ETA: 1:44 - loss: 1.281827039\n",
            "2WBE_3_C\n",
            "[93, 44, 7, 26]\n",
            "37931/39120 [============================>.] - ETA: 1:44 - loss: 1.28187590\n",
            "3QAY_1_A\n",
            "[48, 98, 41, 68]\n",
            "37932/39120 [============================>.] - ETA: 1:44 - loss: 1.281814546\n",
            "4ZM8_1_A\n",
            "[36, 45, 23, 0]\n",
            "37933/39120 [============================>.] - ETA: 1:44 - loss: 1.281822426\n",
            "4GMX_3_C\n",
            "[38, 15, 95, 30]\n",
            "37934/39120 [============================>.] - ETA: 1:43 - loss: 1.281811518\n",
            "4BMO_1_A\n",
            "[73, 71, 2, 46]\n",
            "37935/39120 [============================>.] - ETA: 1:43 - loss: 1.281824765\n",
            "2DI3_1_A\n",
            "[83, 56, 38, 61]\n",
            "37936/39120 [============================>.] - ETA: 1:43 - loss: 1.281820334\n",
            "4IJY_1_A\n",
            "[4, 3, 0, 1]\n",
            "37937/39120 [============================>.] - ETA: 1:43 - loss: 1.28173657\n",
            "3SYS_1_A\n",
            "[56, 70, 19, 5]\n",
            "37938/39120 [============================>.] - ETA: 1:43 - loss: 1.28171170\n",
            "1ZOW_d1zowd2\n",
            "[70, 74, 85, 81]\n",
            "37939/39120 [============================>.] - ETA: 1:43 - loss: 1.281737506\n",
            "1IXR_1_A\n",
            "[34, 90, 86, 35]\n",
            "37940/39120 [============================>.] - ETA: 1:43 - loss: 1.281733864\n",
            "4DGW_2_B\n",
            "[6, 71, 32, 42]\n",
            "37941/39120 [============================>.] - ETA: 1:43 - loss: 1.281715873\n",
            "3WDD_1_A\n",
            "[67, 20, 21, 52]\n",
            "37942/39120 [============================>.] - ETA: 1:43 - loss: 1.28171983\n",
            "2ZYR_1_A\n",
            "[51, 52, 46, 80]\n",
            "37943/39120 [============================>.] - ETA: 1:43 - loss: 1.28178580\n",
            "2V0H_d2v0ha2\n",
            "[6, 83, 39, 61]\n",
            "37944/39120 [============================>.] - ETA: 1:43 - loss: 1.28175551\n",
            "4Z02_1_A\n",
            "[80, 21, 38, 20]\n",
            "37945/39120 [============================>.] - ETA: 1:43 - loss: 1.281736920\n",
            "5A53_2_B\n",
            "[99, 95, 61, 36]\n",
            "37946/39120 [============================>.] - ETA: 1:42 - loss: 1.281724202\n",
            "4FCZ_1_B\n",
            "[2, 68, 80, 15]\n",
            "37947/39120 [============================>.] - ETA: 1:42 - loss: 1.28171969\n",
            "3CDH_1_A\n",
            "[29, 53, 44, 19]\n",
            "37948/39120 [============================>.] - ETA: 1:42 - loss: 1.281737831\n",
            "3GU0_1_A\n",
            "[27, 84, 79, 82]\n",
            "37949/39120 [============================>.] - ETA: 1:42 - loss: 1.281710476\n",
            "3SBT_2_B\n",
            "[92, 76, 18, 28]\n",
            "37950/39120 [============================>.] - ETA: 1:42 - loss: 1.281739027\n",
            "1OBC_d1obca2\n",
            "[39, 95, 73, 32, 6]\n",
            "37951/39120 [============================>.] - ETA: 1:42 - loss: 1.281717356\n",
            "2KX2_1_A\n",
            "[20, 10, 18, 15]\n",
            "37952/39120 [============================>.] - ETA: 1:42 - loss: 1.28179409\n",
            "2AZE_3_C\n",
            "[0, 15, 4, 26]\n",
            "37953/39120 [============================>.] - ETA: 1:42 - loss: 1.28178729\n",
            "2P0G_1_A\n",
            "[92, 28, 33, 87]\n",
            "37954/39120 [============================>.] - ETA: 1:42 - loss: 1.281720179\n",
            "3EC9_1_A\n",
            "[18, 75, 56, 69]\n",
            "37955/39120 [============================>.] - ETA: 1:42 - loss: 1.28174677\n",
            "4Q2S_1_A\n",
            "[0, 2, 1, 3]\n",
            "37956/39120 [============================>.] - ETA: 1:42 - loss: 1.28172566\n",
            "3QRV_1_A\n",
            "[49, 90, 10, 63]\n",
            "37957/39120 [============================>.] - ETA: 1:41 - loss: 1.281730256\n",
            "1S7J_1_A\n",
            "[18, 73, 43, 46]\n",
            "37958/39120 [============================>.] - ETA: 1:41 - loss: 1.281722896\n",
            "5FP2_1_A\n",
            "[10, 78, 12, 21]\n",
            "37959/39120 [============================>.] - ETA: 1:41 - loss: 1.281714884\n",
            "1N11_1_A\n",
            "[12, 21, 94, 24]\n",
            "37960/39120 [============================>.] - ETA: 1:41 - loss: 1.281738003\n",
            "2FIT_1_A\n",
            "[10, 43, 72, 95]\n",
            "37961/39120 [============================>.] - ETA: 1:41 - loss: 1.281718134\n",
            "3CB7_1_A\n",
            "[72, 40, 67, 94]\n",
            "37962/39120 [============================>.] - ETA: 1:41 - loss: 1.281722599\n",
            "5AIH_1_A\n",
            "[22, 73, 49, 86]\n",
            "37963/39120 [============================>.] - ETA: 1:41 - loss: 1.281720373\n",
            "1GM5_d1gm5a3\n",
            "[27, 40, 99, 61]\n",
            "37964/39120 [============================>.] - ETA: 1:41 - loss: 1.281736317\n",
            "4DNS_1_A\n",
            "[52, 95, 62, 33]\n",
            "37965/39120 [============================>.] - ETA: 1:41 - loss: 1.281816663\n",
            "2FH0_1_A\n",
            "[45, 38, 58, 76]\n",
            "37966/39120 [============================>.] - ETA: 1:41 - loss: 1.281838365\n",
            "4DB2_1_A\n",
            "[75, 39, 34, 88]\n",
            "37967/39120 [============================>.] - ETA: 1:41 - loss: 1.28177233\n",
            "2Y96_d2y96a-\n",
            "[28, 48, 11, 39]\n",
            "37968/39120 [============================>.] - ETA: 1:41 - loss: 1.281736661\n",
            "4I9X_1_A\n",
            "[3, 11, 2, 6]\n",
            "37969/39120 [============================>.] - ETA: 1:40 - loss: 1.28175510\n",
            "2OGG_1_A\n",
            "[25, 88, 43, 78]\n",
            "37970/39120 [============================>.] - ETA: 1:40 - loss: 1.281718254\n",
            "3EKI_1_A\n",
            "[79, 16, 80, 21]\n",
            "37971/39120 [============================>.] - ETA: 1:40 - loss: 1.28175609\n",
            "1LKD_d1lkda2\n",
            "1LKD_d1lkda2\n",
            "[30, 29, 21, 64, 60]\n",
            "37972/39120 [============================>.] - ETA: 1:40 - loss: 1.281822556\n",
            "4Y42_d4y42j1\n",
            "[40, 54, 73, 71]\n",
            "37973/39120 [============================>.] - ETA: 1:40 - loss: 1.281836758\n",
            "2JR1_1_A\n",
            "[42, 64, 95, 58]\n",
            "37974/39120 [============================>.] - ETA: 1:40 - loss: 1.281720298\n",
            "3OHN_1_A\n",
            "[85, 95, 41, 59]\n",
            "37975/39120 [============================>.] - ETA: 1:40 - loss: 1.281734082\n",
            "2OZV_1_A\n",
            "[19, 46, 64, 52, 50]\n",
            "37976/39120 [============================>.] - ETA: 1:40 - loss: 1.281726674\n",
            "2DHM_1_A\n",
            "[51, 38, 79, 21]\n",
            "37977/39120 [============================>.] - ETA: 1:40 - loss: 1.28177873\n",
            "4DD5_d4dd5a2\n",
            "[69, 34, 12, 71]\n",
            "37978/39120 [============================>.] - ETA: 1:40 - loss: 1.281713845\n",
            "1UGL_1_A\n",
            "[45, 39, 75, 21]\n",
            "37979/39120 [============================>.] - ETA: 1:40 - loss: 1.2817744\n",
            "2O30_1_A\n",
            "[35, 8, 69, 25]\n",
            "37980/39120 [============================>.] - ETA: 1:39 - loss: 1.281837353\n",
            "2OBV_1_A\n",
            "[58, 15, 28, 62]\n",
            "37981/39120 [============================>.] - ETA: 1:39 - loss: 1.281815030\n",
            "3WEO_d3weoa1\n",
            "[6, 26, 72, 78]\n",
            "37982/39120 [============================>.] - ETA: 1:39 - loss: 1.28186744\n",
            "4RVC_1_A\n",
            "[49, 68, 32, 14]\n",
            "37983/39120 [============================>.] - ETA: 1:39 - loss: 1.281838681\n",
            "1TP4_1_A\n",
            "[17, 77, 50, 61]\n",
            "37984/39120 [============================>.] - ETA: 1:39 - loss: 1.281812142\n",
            "2Q73_d2q73b-\n",
            "[73, 60, 27, 0]\n",
            "37985/39120 [============================>.] - ETA: 1:39 - loss: 1.281732371\n",
            "2MF3_1_A\n",
            "[1]\n",
            "37986/39120 [============================>.] - ETA: 1:39 - loss: 1.28174221\n",
            "3ZIA_1_A\n",
            "[39, 83, 34, 11]\n",
            "37987/39120 [============================>.] - ETA: 1:39 - loss: 1.281721181\n",
            "1MKE_d1mkea1\n",
            "[22, 74, 73, 72]\n",
            "37988/39120 [============================>.] - ETA: 1:39 - loss: 1.281717690\n",
            "4K5Y_1_A\n",
            "4K5Y_1_A\n",
            "[56, 63, 44, 24, 98]\n",
            "37989/39120 [============================>.] - ETA: 1:39 - loss: 1.281730540\n",
            "4NQA_1_A\n",
            "[11, 68, 43, 65]\n",
            "37990/39120 [============================>.] - ETA: 1:39 - loss: 1.28172208\n",
            "3E39_1_A\n",
            "[33, 61, 94, 1]\n",
            "37991/39120 [============================>.] - ETA: 1:38 - loss: 1.281722374\n",
            "2ORY_1_A\n",
            "[3, 23, 40, 17]\n",
            "37992/39120 [============================>.] - ETA: 1:38 - loss: 1.281734950\n",
            "2E3H_1_A\n",
            "[96, 35, 65, 6]\n",
            "37993/39120 [============================>.] - ETA: 1:38 - loss: 1.2817230\n",
            "2WPX_1_A\n",
            "[46, 67, 6, 70]\n",
            "37994/39120 [============================>.] - ETA: 1:38 - loss: 1.28171526\n",
            "4X1O_1_A\n",
            "[39, 95, 31, 29]\n",
            "37995/39120 [============================>.] - ETA: 1:38 - loss: 1.281713832\n",
            "4ROC_1_A\n",
            "[3, 13, 54, 14]\n",
            "37996/39120 [============================>.] - ETA: 1:38 - loss: 1.281726351\n",
            "3HV0_1_A\n",
            "[56, 14, 4, 40]\n",
            "37997/39120 [============================>.] - ETA: 1:38 - loss: 1.281732601\n",
            "2BW8_1_A\n",
            "[92, 85, 61, 54]\n",
            "37998/39120 [============================>.] - ETA: 1:38 - loss: 1.28171513\n",
            "2M7A_1_A\n",
            "[36, 23, 37, 11]\n",
            "37999/39120 [============================>.] - ETA: 1:38 - loss: 1.281737219\n",
            "2KZ0_1_A\n",
            "[53, 94, 38, 20]\n",
            "38000/39120 [============================>.] - ETA: 1:38 - loss: 1.281717006\n",
            "3GWM_1_A\n",
            "[88, 45, 2, 61]\n",
            "38001/39120 [============================>.] - ETA: 1:38 - loss: 1.281712856\n",
            "3EY6_1_A\n",
            "[30, 61, 18, 79]\n",
            "38002/39120 [============================>.] - ETA: 1:38 - loss: 1.281733846\n",
            "2ZUB_d2zubb1\n",
            "[2, 55, 53, 7]\n",
            "38003/39120 [============================>.] - ETA: 1:37 - loss: 1.281817122\n",
            "2QJL_1_A\n",
            "[77, 19, 56, 34]\n",
            "38004/39120 [============================>.] - ETA: 1:37 - loss: 1.281737679\n",
            "3TCR_1_A\n",
            "[10, 46, 72, 6]\n",
            "38005/39120 [============================>.] - ETA: 1:37 - loss: 1.281730338\n",
            "2VSO_2_E\n",
            "[83, 84, 57, 74, 62]\n",
            "38006/39120 [============================>.] - ETA: 1:37 - loss: 1.281732301\n",
            "4N27_1_A\n",
            "[98, 64, 15, 5]\n",
            "38007/39120 [============================>.] - ETA: 1:37 - loss: 1.28178959\n",
            "2ROP_d2ropa1\n",
            "[25, 4, 77, 1]\n",
            "38008/39120 [============================>.] - ETA: 1:37 - loss: 1.281738007\n",
            "1JVA_1_A\n",
            "[84, 82, 32, 43]\n",
            "38009/39120 [============================>.] - ETA: 1:37 - loss: 1.28173050\n",
            "3D5N_1_A\n",
            "[27, 11, 28, 91]\n",
            "38010/39120 [============================>.] - ETA: 1:37 - loss: 1.28172465\n",
            "1YE9_1_A\n",
            "[41, 33, 48, 34]\n",
            "38011/39120 [============================>.] - ETA: 1:37 - loss: 1.281737400\n",
            "1YIS_1_A\n",
            "[85, 21, 42, 33]\n",
            "38012/39120 [============================>.] - ETA: 1:37 - loss: 1.28184591\n",
            "1QG3_d1qg3a1\n",
            "[27, 46, 43, 69]\n",
            "38013/39120 [============================>.] - ETA: 1:37 - loss: 1.28185337\n",
            "4CGB_1_A\n",
            "[76, 63, 86, 33]\n",
            "38014/39120 [============================>.] - ETA: 1:36 - loss: 1.281815198\n",
            "2L7N_1_A\n",
            "[71, 49, 23, 91]\n",
            "38015/39120 [============================>.] - ETA: 1:36 - loss: 1.281722827\n",
            "2BO9_d2bo9d2\n",
            "[62, 36, 39, 35]\n",
            "38016/39120 [============================>.] - ETA: 1:36 - loss: 1.281738197\n",
            "1IS8_1_A\n",
            "[60, 71, 67, 55]\n",
            "38017/39120 [============================>.] - ETA: 1:36 - loss: 1.281732899\n",
            "1WS8_1_A\n",
            "[67, 31, 37, 2]\n",
            "38018/39120 [============================>.] - ETA: 1:36 - loss: 1.281727135\n",
            "1WF9_1_A\n",
            "[96, 3, 34, 50]\n",
            "38019/39120 [============================>.] - ETA: 1:36 - loss: 1.2817514\n",
            "3WRB_1_A\n",
            "[82, 37, 9, 84]\n",
            "38020/39120 [============================>.] - ETA: 1:36 - loss: 1.281719784\n",
            "3B9W_1_A\n",
            "[93, 10, 4, 91]\n",
            "38021/39120 [============================>.] - ETA: 1:36 - loss: 1.281718228\n",
            "4DB1_d4db1b2\n",
            "[66, 21, 43, 0]\n",
            "38022/39120 [============================>.] - ETA: 1:36 - loss: 1.281716742\n",
            "2CUD_1_A\n",
            "[68, 96, 87, 94]\n",
            "38023/39120 [============================>.] - ETA: 1:36 - loss: 1.281713469\n",
            "1U0M_d1u0mb2\n",
            "[24, 27, 97, 79]\n",
            "38024/39120 [============================>.] - ETA: 1:36 - loss: 1.281719240\n",
            "2L3U_1_A\n",
            "[63, 42, 74, 1]\n",
            "38025/39120 [============================>.] - ETA: 1:36 - loss: 1.281711700\n",
            "2EAN_1_A\n",
            "[41, 69, 49, 25]\n",
            "38026/39120 [============================>.] - ETA: 1:35 - loss: 1.281729917\n",
            "4J7O_1_A\n",
            "[13, 35, 6, 31]\n",
            "38027/39120 [============================>.] - ETA: 1:35 - loss: 1.281717054\n",
            "3P9C_d3p9ca1\n",
            "[94, 50, 21, 65]\n",
            "38028/39120 [============================>.] - ETA: 1:35 - loss: 1.281716005\n",
            "3RPP_1_A\n",
            "[1, 27, 83, 13, 58]\n",
            "38029/39120 [============================>.] - ETA: 1:35 - loss: 1.281727587\n",
            "3R4K_1_A\n",
            "[77, 82, 89, 25]\n",
            "38030/39120 [============================>.] - ETA: 1:35 - loss: 1.281714627\n",
            "3KZG_1_A\n",
            "[19, 16, 0, 45]\n",
            "38031/39120 [============================>.] - ETA: 1:35 - loss: 1.281713343\n",
            "2OPT_1_A\n",
            "[32, 15, 67, 2]\n",
            "38032/39120 [============================>.] - ETA: 1:35 - loss: 1.28174600\n",
            "3DD6_1_A\n",
            "[27, 49, 44, 4]\n",
            "38033/39120 [============================>.] - ETA: 1:35 - loss: 1.28175525\n",
            "2BTO_d2btob1\n",
            "[21, 1, 81, 27]\n",
            "38034/39120 [============================>.] - ETA: 1:35 - loss: 1.281738569\n",
            "4WZ7_15_L\n",
            "[29, 72, 70, 57]\n",
            "38035/39120 [============================>.] - ETA: 1:35 - loss: 1.281724820\n",
            "2VIF_1_A\n",
            "[99, 59, 44, 16]\n",
            "38036/39120 [============================>.] - ETA: 1:35 - loss: 1.281710095\n",
            "1JLT_1_A\n",
            "[52, 60, 59, 94]\n",
            "38037/39120 [============================>.] - ETA: 1:34 - loss: 1.281720148\n",
            "2V51_2_E\n",
            "[61, 47, 25, 62]\n",
            "38038/39120 [============================>.] - ETA: 1:34 - loss: 1.281716981\n",
            "2JYN_1_A\n",
            "[78, 27, 63, 45]\n",
            "38039/39120 [============================>.] - ETA: 1:34 - loss: 1.281734939\n",
            "5AGQ_1_A\n",
            "[92, 79, 83, 52]\n",
            "38040/39120 [============================>.] - ETA: 1:34 - loss: 1.28171907\n",
            "1SVX_1_A\n",
            "[23, 32, 85, 59]\n",
            "38041/39120 [============================>.] - ETA: 1:34 - loss: 1.28177585\n",
            "3T20_1_A\n",
            "[73, 55, 32, 99]\n",
            "38042/39120 [============================>.] - ETA: 1:34 - loss: 1.281725318\n",
            "1K20_1_A\n",
            "[11, 65, 32, 6]\n",
            "38043/39120 [============================>.] - ETA: 1:34 - loss: 1.28173916\n",
            "2ZW2_1_A\n",
            "[62, 83, 46, 51]\n",
            "38044/39120 [============================>.] - ETA: 1:34 - loss: 1.281718899\n",
            "4WYT_d4wyta1\n",
            "[66, 99, 64, 68]\n",
            "38045/39120 [============================>.] - ETA: 1:34 - loss: 1.281728333\n",
            "1E9S_1_A\n",
            "[51, 53, 90, 92]\n",
            "38046/39120 [============================>.] - ETA: 1:34 - loss: 1.28174624\n",
            "2VPQ_d2vpqb1\n",
            "[65, 97, 37, 31]\n",
            "38047/39120 [============================>.] - ETA: 1:34 - loss: 1.28173008\n",
            "2CRM_1_A\n",
            "[55, 84, 97, 5]\n",
            "38048/39120 [============================>.] - ETA: 1:33 - loss: 1.2817441\n",
            "3LY5_1_A\n",
            "[19, 85, 84, 89]\n",
            "38049/39120 [============================>.] - ETA: 1:33 - loss: 1.281731224\n",
            "2F49_2_C\n",
            "[0]\n",
            "38050/39120 [============================>.] - ETA: 1:33 - loss: 1.281724244\n",
            "3NYB_1_A\n",
            "[58, 25, 17, 98]\n",
            "38051/39120 [============================>.] - ETA: 1:33 - loss: 1.281730282\n",
            "3RFZ_2_B\n",
            "[92, 81, 33, 58]\n",
            "38052/39120 [============================>.] - ETA: 1:33 - loss: 1.28172639\n",
            "2C31_1_A\n",
            "[90, 52, 66, 38]\n",
            "38053/39120 [============================>.] - ETA: 1:33 - loss: 1.281717157\n",
            "4AXI_1_A\n",
            "[36, 69, 25, 28]\n",
            "38054/39120 [============================>.] - ETA: 1:33 - loss: 1.281738713\n",
            "3HIM_1_A\n",
            "[47, 77, 19, 3]\n",
            "38055/39120 [============================>.] - ETA: 1:33 - loss: 1.281738860\n",
            "2K4B_1_A\n",
            "[32, 19, 22, 33]\n",
            "38056/39120 [============================>.] - ETA: 1:33 - loss: 1.281732087\n",
            "3ODH_1_A\n",
            "[32, 93, 62, 54]\n",
            "38057/39120 [============================>.] - ETA: 1:33 - loss: 1.2817793\n",
            "3A7R_d3a7ra2\n",
            "[71, 91, 75, 33]\n",
            "38058/39120 [============================>.] - ETA: 1:33 - loss: 1.281727751\n",
            "4KT0_5_E\n",
            "[73, 78, 5, 19]\n",
            "38059/39120 [============================>.] - ETA: 1:33 - loss: 1.28175191\n",
            "2WAU_1_A\n",
            "[80, 76, 98, 11]\n",
            "38060/39120 [============================>.] - ETA: 1:32 - loss: 1.281715370\n",
            "3CEI_d3ceib1\n",
            "[43, 30, 26, 34]\n",
            "38061/39120 [============================>.] - ETA: 1:32 - loss: 1.281723813\n",
            "4JHV_1_A\n",
            "[36, 92, 24, 73]\n",
            "38062/39120 [============================>.] - ETA: 1:32 - loss: 1.28176370\n",
            "2LZF_1_A\n",
            "[21, 8, 20, 5]\n",
            "38063/39120 [============================>.] - ETA: 1:32 - loss: 1.281717759\n",
            "2LBZ_1_A\n",
            "[1, 0]\n",
            "38064/39120 [============================>.] - ETA: 1:32 - loss: 1.281721765\n",
            "2J5Y_1_A\n",
            "[17, 34, 2, 40]\n",
            "38065/39120 [============================>.] - ETA: 1:32 - loss: 1.281737398\n",
            "3PZS_1_A\n",
            "[71, 77, 99, 19]\n",
            "38066/39120 [============================>.] - ETA: 1:32 - loss: 1.28178180\n",
            "3KQ5_1_A\n",
            "[45, 54, 74, 50]\n",
            "38067/39120 [============================>.] - ETA: 1:32 - loss: 1.281731330\n",
            "3H4M_1_A\n",
            "[76, 46, 4, 27]\n",
            "38068/39120 [============================>.] - ETA: 1:32 - loss: 1.281735170\n",
            "4OOA_1_A\n",
            "[98, 72, 75, 38]\n",
            "38069/39120 [============================>.] - ETA: 1:32 - loss: 1.28177012\n",
            "2YWW_d2ywwb2\n",
            "[84, 2, 28, 5]\n",
            "38070/39120 [============================>.] - ETA: 1:32 - loss: 1.281711798\n",
            "3ZQO_1_A\n",
            "[25, 1, 92, 64]\n",
            "38071/39120 [============================>.] - ETA: 1:31 - loss: 1.281810328\n",
            "2LNI_1_A\n",
            "[18, 34, 83, 19, 29]\n",
            "38072/39120 [============================>.] - ETA: 1:31 - loss: 1.28189860\n",
            "3N79_d3n79a2\n",
            "[71, 0, 30, 85]\n",
            "38073/39120 [============================>.] - ETA: 1:31 - loss: 1.281734084\n",
            "4CHD_1_A\n",
            "[2, 5, 6, 0]\n",
            "38074/39120 [============================>.] - ETA: 1:31 - loss: 1.281726622\n",
            "1VE4_1_A\n",
            "[23, 46, 69, 65]\n",
            "38075/39120 [============================>.] - ETA: 1:31 - loss: 1.28174530\n",
            "3T57_1_A\n",
            "[57, 85, 52, 73]\n",
            "38076/39120 [============================>.] - ETA: 1:31 - loss: 1.281714991\n",
            "1JET_1_A\n",
            "[32, 82, 22, 87]\n",
            "38077/39120 [============================>.] - ETA: 1:31 - loss: 1.28176836\n",
            "3GQB_1_A\n",
            "[4, 86, 20, 32]\n",
            "38078/39120 [============================>.] - ETA: 1:31 - loss: 1.281732339\n",
            "1MZG_1_A\n",
            "[84, 96, 60, 4]\n",
            "38079/39120 [============================>.] - ETA: 1:31 - loss: 1.28172679\n",
            "1YII_1_A\n",
            "[61, 19, 78, 21]\n",
            "38080/39120 [============================>.] - ETA: 1:31 - loss: 1.281724538\n",
            "3EEV_1_A\n",
            "[69, 50, 88, 27]\n",
            "38081/39120 [============================>.] - ETA: 1:31 - loss: 1.281726662\n",
            "4F0T_2_B\n",
            "[43, 16, 56, 22]\n",
            "38082/39120 [============================>.] - ETA: 1:31 - loss: 1.281736482\n",
            "4JGT_1_A\n",
            "[82, 38, 62, 56]\n",
            "38083/39120 [============================>.] - ETA: 1:30 - loss: 1.28172223\n",
            "4V3P_15_SS\n",
            "[75, 61, 0, 10]\n",
            "38084/39120 [============================>.] - ETA: 1:30 - loss: 1.281716565\n",
            "1WKR_1_A\n",
            "[13, 45, 86, 2]\n",
            "38085/39120 [============================>.] - ETA: 1:30 - loss: 1.281726232\n",
            "2QGO_1_A\n",
            "[41, 24, 44, 96]\n",
            "38086/39120 [============================>.] - ETA: 1:30 - loss: 1.281726154\n",
            "1FHF_1_A\n",
            "[72, 57, 30, 48]\n",
            "38087/39120 [============================>.] - ETA: 1:30 - loss: 1.281726145\n",
            "3TSA_1_A\n",
            "[98, 69, 63, 39]\n",
            "38088/39120 [============================>.] - ETA: 1:30 - loss: 1.281727796\n",
            "5HKO_1_A\n",
            "[49, 0, 25, 21]\n",
            "38089/39120 [============================>.] - ETA: 1:30 - loss: 1.28176790\n",
            "4IS7_1_A\n",
            "[84, 17, 14, 6]\n",
            "38090/39120 [============================>.] - ETA: 1:30 - loss: 1.28172867\n",
            "3AV4_1_A\n",
            "[63, 89, 67, 93]\n",
            "38091/39120 [============================>.] - ETA: 1:30 - loss: 1.281730861\n",
            "5C1M_1_A\n",
            "[13, 38, 70, 35]\n",
            "38092/39120 [============================>.] - ETA: 1:30 - loss: 1.281720472\n",
            "3HZJ_1_A\n",
            "[42, 56, 66, 76]\n",
            "38093/39120 [============================>.] - ETA: 1:30 - loss: 1.28179653\n",
            "5CYV_1_A\n",
            "[70, 19, 32, 28]\n",
            "38094/39120 [============================>.] - ETA: 1:29 - loss: 1.281729447\n",
            "2QE6_1_A\n",
            "[98, 75, 65, 54]\n",
            "38095/39120 [============================>.] - ETA: 1:29 - loss: 1.281726610\n",
            "3WJA_d3wjab1\n",
            "[86, 4, 10, 8]\n",
            "38096/39120 [============================>.] - ETA: 1:29 - loss: 1.281719502\n",
            "4J0Q_d4j0qe3\n",
            "[84, 75, 33, 13]\n",
            "38097/39120 [============================>.] - ETA: 1:29 - loss: 1.281729007\n",
            "3NTL_1_A\n",
            "[24, 44, 98, 89]\n",
            "38098/39120 [============================>.] - ETA: 1:29 - loss: 1.281717874\n",
            "1EOV_1_A\n",
            "[55, 3, 15, 30]\n",
            "38099/39120 [============================>.] - ETA: 1:29 - loss: 1.281710360\n",
            "5FU7_1_A\n",
            "[61, 94, 59, 21]\n",
            "38100/39120 [============================>.] - ETA: 1:29 - loss: 1.281727894\n",
            "3IML_d3imlb2\n",
            "[28, 26, 2, 35]\n",
            "38101/39120 [============================>.] - ETA: 1:29 - loss: 1.281724518\n",
            "1JYM_1_A\n",
            "[16, 25, 48, 42]\n",
            "38102/39120 [============================>.] - ETA: 1:29 - loss: 1.281713809\n",
            "1Y7P_d1y7pb2\n",
            "[9, 20, 38, 51]\n",
            "38103/39120 [============================>.] - ETA: 1:29 - loss: 1.281731624\n",
            "5IJX_1_A\n",
            "[86, 21, 31, 23]\n",
            "38104/39120 [============================>.] - ETA: 1:29 - loss: 1.281726275\n",
            "2BOP_2_A\n",
            "[80, 21, 87, 1]\n",
            "38105/39120 [============================>.] - ETA: 1:28 - loss: 1.281733078\n",
            "3J1O_2_I\n",
            "[53, 82, 22, 28]\n",
            "38106/39120 [============================>.] - ETA: 1:28 - loss: 1.281727436\n",
            "3FGX_1_A\n",
            "[35, 52, 5, 17]\n",
            "38107/39120 [============================>.] - ETA: 1:28 - loss: 1.281726013\n",
            "4RVQ_1_A\n",
            "[49, 60, 68, 63]\n",
            "38108/39120 [============================>.] - ETA: 1:28 - loss: 1.281722749\n",
            "4V6U_53_BD\n",
            "[58, 1, 15, 97]\n",
            "38109/39120 [============================>.] - ETA: 1:28 - loss: 1.28175706\n",
            "1PYL_1_A\n",
            "[37, 85, 68, 36]\n",
            "38110/39120 [============================>.] - ETA: 1:28 - loss: 1.28176218\n",
            "2WWO_1_A\n",
            "[26, 96, 47, 84]\n",
            "38111/39120 [============================>.] - ETA: 1:28 - loss: 1.28175724\n",
            "3TC1_1_A\n",
            "[61, 14, 52, 30]\n",
            "38112/39120 [============================>.] - ETA: 1:28 - loss: 1.281714801\n",
            "1JY2_1_N\n",
            "[27, 8, 4, 6]\n",
            "38113/39120 [============================>.] - ETA: 1:28 - loss: 1.281716681\n",
            "3O14_1_A\n",
            "[93, 80, 94, 32]\n",
            "38114/39120 [============================>.] - ETA: 1:28 - loss: 1.281734799\n",
            "3MN7_2_S\n",
            "[77, 33, 8, 55]\n",
            "38115/39120 [============================>.] - ETA: 1:28 - loss: 1.281722471\n",
            "2VVE_1_A\n",
            "[1, 3, 0, 2]\n",
            "38116/39120 [============================>.] - ETA: 1:28 - loss: 1.281715994\n",
            "1VS0_1_A\n",
            "[99, 50, 40, 87]\n",
            "38117/39120 [============================>.] - ETA: 1:27 - loss: 1.281713583\n",
            "3AG3_10_J\n",
            "[9, 27, 95, 97]\n",
            "38118/39120 [============================>.] - ETA: 1:27 - loss: 1.28175620\n",
            "4WXW_1_A\n",
            "[34, 84, 17, 33]\n",
            "38119/39120 [============================>.] - ETA: 1:27 - loss: 1.281723838\n",
            "3EQU_d3equb2\n",
            "[15, 21, 44, 68]\n",
            "38120/39120 [============================>.] - ETA: 1:27 - loss: 1.281736802\n",
            "2BV1_1_A\n",
            "[21, 72, 90, 4]\n",
            "38121/39120 [============================>.] - ETA: 1:27 - loss: 1.28173972\n",
            "3DBJ_1_A\n",
            "[15, 72, 30, 75]\n",
            "38122/39120 [============================>.] - ETA: 1:27 - loss: 1.281725955\n",
            "4NUR_1_A\n",
            "[11, 76, 30, 43]\n",
            "38123/39120 [============================>.] - ETA: 1:27 - loss: 1.28178571\n",
            "4AJY_4_V\n",
            "[19, 81, 43, 47]\n",
            "38124/39120 [============================>.] - ETA: 1:27 - loss: 1.281729513\n",
            "5DOK_1_A\n",
            "[0]\n",
            "38125/39120 [============================>.] - ETA: 1:27 - loss: 1.281738750\n",
            "1O70_d1o70a1\n",
            "[18, 53, 91, 1]\n",
            "38126/39120 [============================>.] - ETA: 1:27 - loss: 1.281711610\n",
            "2EJQ_1_A\n",
            "[70, 69, 75, 54]\n",
            "38127/39120 [============================>.] - ETA: 1:27 - loss: 1.281710576\n",
            "1Z2T_1_A\n",
            "[0]\n",
            "38128/39120 [============================>.] - ETA: 1:26 - loss: 1.281730531\n",
            "3U4K_1_A\n",
            "[40, 67, 90, 59]\n",
            "38129/39120 [============================>.] - ETA: 1:26 - loss: 1.281720135\n",
            "4YUU_14_T1\n",
            "[18, 3, 77, 11]\n",
            "38130/39120 [============================>.] - ETA: 1:26 - loss: 1.281735104\n",
            "3HD7_1_A\n",
            "[86, 7, 95, 82]\n",
            "38131/39120 [============================>.] - ETA: 1:26 - loss: 1.281717691\n",
            "2DRH_1_A\n",
            "[90, 11, 13, 35]\n",
            "38132/39120 [============================>.] - ETA: 1:26 - loss: 1.281631954\n",
            "2FVK_d2fvkd2\n",
            "[79, 58, 64, 19, 56]\n",
            "38133/39120 [============================>.] - ETA: 1:26 - loss: 1.281627447\n",
            "12AS_1_A\n",
            "[29, 23, 77, 98]\n",
            "38134/39120 [============================>.] - ETA: 1:26 - loss: 1.281632058\n",
            "3NYB_2_B\n",
            "[82, 24, 31, 73]\n",
            "38135/39120 [============================>.] - ETA: 1:26 - loss: 1.28167163\n",
            "2NS7_d2ns7a2\n",
            "[3, 4, 88, 70]\n",
            "38136/39120 [============================>.] - ETA: 1:26 - loss: 1.28176024\n",
            "2HEJ_1_A\n",
            "[45, 5, 99, 79]\n",
            "38137/39120 [============================>.] - ETA: 1:26 - loss: 1.281732960\n",
            "2CIU_1_A\n",
            "[45, 33, 64, 19]\n",
            "38138/39120 [============================>.] - ETA: 1:26 - loss: 1.281718072\n",
            "4MJF_1_A\n",
            "[97, 93, 31, 82]\n",
            "38139/39120 [============================>.] - ETA: 1:25 - loss: 1.281617775\n",
            "1KCN_1_A\n",
            "[0]\n",
            "38140/39120 [============================>.] - ETA: 1:25 - loss: 1.281717618\n",
            "4LHM_d4lhma1\n",
            "[95, 71, 58, 3]\n",
            "38141/39120 [============================>.] - ETA: 1:25 - loss: 1.28172719\n",
            "1ACF_1_A\n",
            "[44, 46, 78, 10]\n",
            "38142/39120 [============================>.] - ETA: 1:25 - loss: 1.28168337\n",
            "2AUV_1_A\n",
            "[12, 32, 40, 46]\n",
            "38143/39120 [============================>.] - ETA: 1:25 - loss: 1.28164687\n",
            "1YHF_1_A\n",
            "[50, 20, 13, 95]\n",
            "38144/39120 [============================>.] - ETA: 1:25 - loss: 1.281737109\n",
            "4OHS_1_A\n",
            "[15, 89, 49, 86]\n",
            "38145/39120 [============================>.] - ETA: 1:25 - loss: 1.28176450\n",
            "3FD9_1_A\n",
            "[25, 15, 11, 12]\n",
            "38146/39120 [============================>.] - ETA: 1:25 - loss: 1.2817573\n",
            "2L55_1_A\n",
            "[71, 33, 75, 82]\n",
            "38147/39120 [============================>.] - ETA: 1:25 - loss: 1.281617623\n",
            "3FED_1_A\n",
            "[26, 73, 94, 43]\n",
            "38148/39120 [============================>.] - ETA: 1:25 - loss: 1.281610586\n",
            "1T35_1_A\n",
            "[32, 7, 86, 40]\n",
            "38149/39120 [============================>.] - ETA: 1:25 - loss: 1.281634999\n",
            "3CL3_2_D\n",
            "[68, 69, 54, 43]\n",
            "38150/39120 [============================>.] - ETA: 1:25 - loss: 1.28161604\n",
            "1DKG_d1dkgd2\n",
            "[89, 58, 93, 52]\n",
            "38151/39120 [============================>.] - ETA: 1:24 - loss: 1.28166379\n",
            "3O3M_2_B\n",
            "[5, 66, 59, 42]\n",
            "38152/39120 [============================>.] - ETA: 1:24 - loss: 1.28163725\n",
            "4BY7_16_X\n",
            "[0, 10, 94, 71]\n",
            "38153/39120 [============================>.] - ETA: 1:24 - loss: 1.28162766\n",
            "1XIP_1_A\n",
            "[69, 10, 18, 86]\n",
            "38154/39120 [============================>.] - ETA: 1:24 - loss: 1.281619843\n",
            "2FIP_1_A\n",
            "[2, 1, 3, 4]\n",
            "38155/39120 [============================>.] - ETA: 1:24 - loss: 1.28161387\n",
            "1CFF_2_B\n",
            "[83, 38, 91, 88]\n",
            "38156/39120 [============================>.] - ETA: 1:24 - loss: 1.281612402\n",
            "2AEN_1_A\n",
            "[97, 69, 86, 23]\n",
            "38157/39120 [============================>.] - ETA: 1:24 - loss: 1.281617075\n",
            "1ZYB_1_A\n",
            "[36, 20, 62, 3]\n",
            "38158/39120 [============================>.] - ETA: 1:24 - loss: 1.28163288\n",
            "5D66_1_A\n",
            "[91, 1, 29, 66]\n",
            "38159/39120 [============================>.] - ETA: 1:24 - loss: 1.281610659\n",
            "3RIP_1_A\n",
            "[89, 29, 24, 88]\n",
            "38160/39120 [============================>.] - ETA: 1:24 - loss: 1.281632850\n",
            "2Q5E_1_A\n",
            "[39, 81, 90, 61]\n",
            "38161/39120 [============================>.] - ETA: 1:24 - loss: 1.281627075\n",
            "2XQC_1_A\n",
            "[99, 62, 70, 35]\n",
            "38162/39120 [============================>.] - ETA: 1:23 - loss: 1.28168553\n",
            "1WVT_1_A\n",
            "[25, 55, 82, 89]\n",
            "38163/39120 [============================>.] - ETA: 1:23 - loss: 1.281636390\n",
            "2EDE_1_A\n",
            "[2, 13, 17, 1]\n",
            "38164/39120 [============================>.] - ETA: 1:23 - loss: 1.281626312\n",
            "4ES6_1_A\n",
            "[25, 57, 31, 58]\n",
            "38165/39120 [============================>.] - ETA: 1:23 - loss: 1.281629034\n",
            "1TEZ_d1tezd2\n",
            "[6, 19, 66, 32]\n",
            "38166/39120 [============================>.] - ETA: 1:23 - loss: 1.281627456\n",
            "3HCJ_1_A\n",
            "[22, 92, 21, 9]\n",
            "38167/39120 [============================>.] - ETA: 1:23 - loss: 1.281635055\n",
            "1PX9_1_A\n",
            "[3, 7, 6, 2]\n",
            "38168/39120 [============================>.] - ETA: 1:23 - loss: 1.28169137\n",
            "5EG7_1_A\n",
            "[8, 1, 9, 5]\n",
            "38169/39120 [============================>.] - ETA: 1:23 - loss: 1.281619346\n",
            "2J1N_1_A\n",
            "[47, 21, 1, 33]\n",
            "38170/39120 [============================>.] - ETA: 1:23 - loss: 1.281625804\n",
            "3RE2_1_A\n",
            "[68, 39, 97, 87]\n",
            "38171/39120 [============================>.] - ETA: 1:23 - loss: 1.28169110\n",
            "1WWY_1_A\n",
            "[59, 99, 81, 12]\n",
            "38172/39120 [============================>.] - ETA: 1:23 - loss: 1.281612893\n",
            "4E2J_1_A\n",
            "[40, 13, 99, 79]\n",
            "38173/39120 [============================>.] - ETA: 1:23 - loss: 1.281614312\n",
            "5AJ8_1_A\n",
            "[76, 0, 97, 16]\n",
            "38174/39120 [============================>.] - ETA: 1:22 - loss: 1.281624070\n",
            "2LG1_1_A\n",
            "[13, 82, 79, 63]\n",
            "38175/39120 [============================>.] - ETA: 1:22 - loss: 1.281610937\n",
            "4HAT_2_B\n",
            "[64, 50, 92, 2]\n",
            "38176/39120 [============================>.] - ETA: 1:22 - loss: 1.281719893\n",
            "2HTD_1_A\n",
            "[13, 97, 69, 2]\n",
            "38177/39120 [============================>.] - ETA: 1:22 - loss: 1.2817213\n",
            "4WBQ_1_A\n",
            "[85, 61, 67, 30]\n",
            "38178/39120 [============================>.] - ETA: 1:22 - loss: 1.28179209\n",
            "5C6D_2_C\n",
            "[0]\n",
            "38179/39120 [============================>.] - ETA: 1:22 - loss: 1.281717293\n",
            "1WT9_1_A\n",
            "[19, 15, 34, 87]\n",
            "38180/39120 [============================>.] - ETA: 1:22 - loss: 1.28163818\n",
            "2J8C_2_L\n",
            "[51, 0, 31, 15]\n",
            "38181/39120 [============================>.] - ETA: 1:22 - loss: 1.281733000\n",
            "1VHF_1_A\n",
            "[20, 96, 97, 9]\n",
            "38182/39120 [============================>.] - ETA: 1:22 - loss: 1.281727917\n",
            "2NUT_3_C\n",
            "[2, 67, 66, 0]\n",
            "38183/39120 [============================>.] - ETA: 1:22 - loss: 1.28165441\n",
            "1BKB_1_A\n",
            "[28, 24, 92, 93]\n",
            "38184/39120 [============================>.] - ETA: 1:22 - loss: 1.28164146\n",
            "1RZ4_d1rz4a1\n",
            "[75, 72, 89, 87]\n",
            "38185/39120 [============================>.] - ETA: 1:21 - loss: 1.281627003\n",
            "4BOE_1_A\n",
            "[70, 0, 44, 65]\n",
            "38186/39120 [============================>.] - ETA: 1:21 - loss: 1.28168273\n",
            "3BC9_1_A\n",
            "[11, 46, 21, 44]\n",
            "38187/39120 [============================>.] - ETA: 1:21 - loss: 1.281620891\n",
            "2PKE_1_A\n",
            "[19, 54, 56, 91]\n",
            "38188/39120 [============================>.] - ETA: 1:21 - loss: 1.281623164\n",
            "3DJC_d3djcf2\n",
            "[31, 43, 10, 23]\n",
            "38189/39120 [============================>.] - ETA: 1:21 - loss: 1.281726026\n",
            "2CXI_1_A\n",
            "[10, 66, 40, 65]\n",
            "38190/39120 [============================>.] - ETA: 1:21 - loss: 1.281710351\n",
            "1TY0_d1ty0c1\n",
            "[51, 24, 9, 25]\n",
            "38191/39120 [============================>.] - ETA: 1:21 - loss: 1.281715097\n",
            "1BWY_1_A\n",
            "[36, 96, 19, 2]\n",
            "38192/39120 [============================>.] - ETA: 1:21 - loss: 1.281713309\n",
            "2M6P_1_A\n",
            "[39, 94, 91, 82]\n",
            "38193/39120 [============================>.] - ETA: 1:21 - loss: 1.281712677\n",
            "2GL9_1_A\n",
            "[73, 42, 60, 82]\n",
            "38194/39120 [============================>.] - ETA: 1:21 - loss: 1.281711175\n",
            "4CA9_1_A\n",
            "[54, 9, 42, 27]\n",
            "38195/39120 [============================>.] - ETA: 1:21 - loss: 1.281717728\n",
            "2EV0_d2ev0b2\n",
            "[97, 7, 36, 57]\n",
            "38196/39120 [============================>.] - ETA: 1:20 - loss: 1.281737257\n",
            "3P6J_1_A\n",
            "[27, 79, 74, 58]\n",
            "38197/39120 [============================>.] - ETA: 1:20 - loss: 1.281614804\n",
            "3BRO_1_A\n",
            "[71, 85, 49, 36]\n",
            "38198/39120 [============================>.] - ETA: 1:20 - loss: 1.28173083\n",
            "3A4U_2_B\n",
            "[54, 41, 84, 44]\n",
            "38199/39120 [============================>.] - ETA: 1:20 - loss: 1.281713494\n",
            "2WY8_1_A\n",
            "[42, 66, 10, 44]\n",
            "38200/39120 [============================>.] - ETA: 1:20 - loss: 1.281720378\n",
            "2CU7_1_A\n",
            "[18, 26, 9, 51]\n",
            "38201/39120 [============================>.] - ETA: 1:20 - loss: 1.281620236\n",
            "3LYS_1_A\n",
            "[47, 95, 55, 59]\n",
            "38202/39120 [============================>.] - ETA: 1:20 - loss: 1.281612736\n",
            "2I4K_1_A\n",
            "[56, 34, 38, 12]\n",
            "38203/39120 [============================>.] - ETA: 1:20 - loss: 1.281615021\n",
            "4CAY_3_C\n",
            "[4, 6, 7, 2]\n",
            "38204/39120 [============================>.] - ETA: 1:20 - loss: 1.281633291\n",
            "2E6I_1_A\n",
            "[73, 47, 46, 1]\n",
            "38205/39120 [============================>.] - ETA: 1:20 - loss: 1.281625013\n",
            "4JHS_d4jhsa1\n",
            "[80, 5, 23, 20]\n",
            "38206/39120 [============================>.] - ETA: 1:20 - loss: 1.28179242\n",
            "2VUN_1_A\n",
            "[43, 20, 64, 92]\n",
            "38207/39120 [============================>.] - ETA: 1:20 - loss: 1.281730722\n",
            "1KJQ_d1kjqb1\n",
            "[79, 11, 21, 5]\n",
            "38208/39120 [============================>.] - ETA: 1:19 - loss: 1.281726297\n",
            "3I4S_1_A\n",
            "[57, 77, 72, 1]\n",
            "38209/39120 [============================>.] - ETA: 1:19 - loss: 1.281727635\n",
            "1EO1_1_A\n",
            "[34, 13, 29, 86]\n",
            "38210/39120 [============================>.] - ETA: 1:19 - loss: 1.281738047\n",
            "3LS3_1_A\n",
            "[6, 85, 26, 93]\n",
            "38211/39120 [============================>.] - ETA: 1:19 - loss: 1.281712015\n",
            "2D7C_2_C\n",
            "[36, 60, 19, 27]\n",
            "38212/39120 [============================>.] - ETA: 1:19 - loss: 1.281729922\n",
            "4AOR_2_D\n",
            "[9, 0, 4, 1]\n",
            "38213/39120 [============================>.] - ETA: 1:19 - loss: 1.281720712\n",
            "4QAF_1_A\n",
            "[75, 55, 13, 99]\n",
            "38214/39120 [============================>.] - ETA: 1:19 - loss: 1.281716780\n",
            "1EUW_1_A\n",
            "[39, 77, 19, 4]\n",
            "38215/39120 [============================>.] - ETA: 1:19 - loss: 1.28172908\n",
            "1VQQ_d1vqqb3\n",
            "[93, 2, 40, 25]\n",
            "38216/39120 [============================>.] - ETA: 1:19 - loss: 1.28171839\n",
            "1XOP_1_A\n",
            "[3, 0, 14, 8]\n",
            "38217/39120 [============================>.] - ETA: 1:19 - loss: 1.281713605\n",
            "2RAE_1_A\n",
            "[49, 5, 32, 4]\n",
            "38218/39120 [============================>.] - ETA: 1:19 - loss: 1.281725114\n",
            "4V0H_1_A\n",
            "[7, 23, 94, 87]\n",
            "38219/39120 [============================>.] - ETA: 1:18 - loss: 1.281721737\n",
            "3P3V_1_A\n",
            "[73, 9, 94, 90]\n",
            "38220/39120 [============================>.] - ETA: 1:18 - loss: 1.281716161\n",
            "4LQ4_1_A\n",
            "[29, 7, 41, 25]\n",
            "38221/39120 [============================>.] - ETA: 1:18 - loss: 1.281716285\n",
            "2C5K_1_P\n",
            "[11, 1, 19, 17]\n",
            "38222/39120 [============================>.] - ETA: 1:18 - loss: 1.281731759\n",
            "3TR3_1_A\n",
            "[56, 45, 17, 78]\n",
            "38223/39120 [============================>.] - ETA: 1:18 - loss: 1.281618149\n",
            "4FIX_1_A\n",
            "[63, 59, 12, 86]\n",
            "38224/39120 [============================>.] - ETA: 1:18 - loss: 1.281716509\n",
            "4L9U_1_A\n",
            "[2, 5, 7, 11]\n",
            "38225/39120 [============================>.] - ETA: 1:18 - loss: 1.281720079\n",
            "5BNZ_d5bnzb2\n",
            "[18, 1, 92, 31]\n",
            "38226/39120 [============================>.] - ETA: 1:18 - loss: 1.281636610\n",
            "4AXN_1_A\n",
            "[67, 99, 18, 7]\n",
            "38227/39120 [============================>.] - ETA: 1:18 - loss: 1.281638737\n",
            "4I5S_1_A\n",
            "[36, 87, 94, 90]\n",
            "38228/39120 [============================>.] - ETA: 1:18 - loss: 1.281722454\n",
            "1YHT_1_A\n",
            "[30, 36, 50, 6]\n",
            "38229/39120 [============================>.] - ETA: 1:18 - loss: 1.281730467\n",
            "2JN4_d2jn4a1\n",
            "[22, 23, 94, 70]\n",
            "38230/39120 [============================>.] - ETA: 1:18 - loss: 1.281721540\n",
            "2QXV_2_B\n",
            "[4, 12, 1, 2]\n",
            "38231/39120 [============================>.] - ETA: 1:17 - loss: 1.281721072\n",
            "1L0S_1_A\n",
            "[6, 4, 1, 13]\n",
            "38232/39120 [============================>.] - ETA: 1:17 - loss: 1.281618991\n",
            "2VV6_1_A\n",
            "[22, 27, 59, 29]\n",
            "38233/39120 [============================>.] - ETA: 1:17 - loss: 1.281636527\n",
            "4BY2_1_A\n",
            "[55, 2, 29, 10]\n",
            "38234/39120 [============================>.] - ETA: 1:17 - loss: 1.281614906\n",
            "5BYP_1_A\n",
            "[50, 0, 75, 21]\n",
            "38235/39120 [============================>.] - ETA: 1:17 - loss: 1.281620818\n",
            "3U7Q_2_B\n",
            "[8, 76, 98, 69]\n",
            "38236/39120 [============================>.] - ETA: 1:17 - loss: 1.281614767\n",
            "3R6M_1_A\n",
            "[69, 33, 99, 39]\n",
            "38237/39120 [============================>.] - ETA: 1:17 - loss: 1.281628345\n",
            "2K3V_1_A\n",
            "[34, 11, 71, 29]\n",
            "38238/39120 [============================>.] - ETA: 1:17 - loss: 1.281611341\n",
            "2LV7_1_A\n",
            "[78, 63, 30, 9]\n",
            "38239/39120 [============================>.] - ETA: 1:17 - loss: 1.281731512\n",
            "3LAY_1_A\n",
            "[11, 68, 23, 89]\n",
            "38240/39120 [============================>.] - ETA: 1:17 - loss: 1.281622069\n",
            "3IYL_3_W\n",
            "[13, 11, 22, 26]\n",
            "38241/39120 [============================>.] - ETA: 1:17 - loss: 1.281629801\n",
            "2PZ1_1_A\n",
            "[74, 36, 37, 92]\n",
            "38242/39120 [============================>.] - ETA: 1:16 - loss: 1.281628599\n",
            "4V9F_19_Q\n",
            "[74, 26, 21, 34]\n",
            "38243/39120 [============================>.] - ETA: 1:16 - loss: 1.281628652\n",
            "1GES_d1gesb3\n",
            "[51, 26, 96, 4]\n",
            "38244/39120 [============================>.] - ETA: 1:16 - loss: 1.281637607\n",
            "2KSN_1_A\n",
            "[51, 96, 40, 59]\n",
            "38245/39120 [============================>.] - ETA: 1:16 - loss: 1.28168310\n",
            "4BTS_32_AV\n",
            "[16, 4, 71, 63]\n",
            "38246/39120 [============================>.] - ETA: 1:16 - loss: 1.28167599\n",
            "2RB7_1_A\n",
            "[66, 81, 26, 80]\n",
            "38247/39120 [============================>.] - ETA: 1:16 - loss: 1.281621242\n",
            "2H5C_1_A\n",
            "[94, 9, 5, 8]\n",
            "38248/39120 [============================>.] - ETA: 1:16 - loss: 1.281624842\n",
            "2MUI_1_A\n",
            "[1, 90, 17, 83]\n",
            "38249/39120 [============================>.] - ETA: 1:16 - loss: 1.281632551\n",
            "2AOZ_1_A\n",
            "[74, 72, 80, 84]\n",
            "38250/39120 [============================>.] - ETA: 1:16 - loss: 1.281635739\n",
            "2L95_1_A\n",
            "[82, 61, 93, 54]\n",
            "38251/39120 [============================>.] - ETA: 1:16 - loss: 1.281631743\n",
            "4LZD_d4lzda2\n",
            "[66, 47, 7, 6]\n",
            "38252/39120 [============================>.] - ETA: 1:16 - loss: 1.28164807\n",
            "2FWR_1_A\n",
            "[26, 83, 98, 0]\n",
            "38253/39120 [============================>.] - ETA: 1:15 - loss: 1.281628224\n",
            "2GFO_1_A\n",
            "[56, 23, 24, 44]\n",
            "38254/39120 [============================>.] - ETA: 1:15 - loss: 1.281630231\n",
            "4O9A_d4o9ad1\n",
            "[50, 9, 48, 57]\n",
            "38255/39120 [============================>.] - ETA: 1:15 - loss: 1.281617811\n",
            "4Z8A_1_A\n",
            "[16, 39, 38, 1]\n",
            "38256/39120 [============================>.] - ETA: 1:15 - loss: 1.28162730\n",
            "2MOB_d2moba-\n",
            "[50, 15, 96, 52]\n",
            "38257/39120 [============================>.] - ETA: 1:15 - loss: 1.281610640\n",
            "1RHY_1_A\n",
            "[16, 92, 88, 47]\n",
            "38258/39120 [============================>.] - ETA: 1:15 - loss: 1.281729679\n",
            "1E5D_d1e5db1\n",
            "[64, 60, 85, 69]\n",
            "38259/39120 [============================>.] - ETA: 1:15 - loss: 1.281634380\n",
            "3UF7_1_A\n",
            "[36, 60, 85, 99]\n",
            "38260/39120 [============================>.] - ETA: 1:15 - loss: 1.28165646\n",
            "1OOA_2_A\n",
            "[34, 21, 24, 17]\n",
            "38261/39120 [============================>.] - ETA: 1:15 - loss: 1.281619479\n",
            "2BMB_1_A\n",
            "[2, 60, 56, 21]\n",
            "38262/39120 [============================>.] - ETA: 1:15 - loss: 1.281619790\n",
            "3Q87_1_A\n",
            "[19, 48, 98, 52]\n",
            "38263/39120 [============================>.] - ETA: 1:15 - loss: 1.281622306\n",
            "2I10_d2i10b2\n",
            "[14, 97, 70, 44]\n",
            "38264/39120 [============================>.] - ETA: 1:15 - loss: 1.281638624\n",
            "2VQ2_1_A\n",
            "[79, 91, 61, 95]\n",
            "38265/39120 [============================>.] - ETA: 1:14 - loss: 1.28166523\n",
            "3PT5_1_A\n",
            "[95, 73, 31, 1, 61]\n",
            "38266/39120 [============================>.] - ETA: 1:14 - loss: 1.281617078\n",
            "4JG5_1_A\n",
            "[6, 35, 29, 2]\n",
            "38267/39120 [============================>.] - ETA: 1:14 - loss: 1.28167583\n",
            "1IQP_d1iqpf1\n",
            "[64, 50, 87, 85]\n",
            "38268/39120 [============================>.] - ETA: 1:14 - loss: 1.281632997\n",
            "2A1U_d2a1ua1\n",
            "[23, 51, 60, 37]\n",
            "38269/39120 [============================>.] - ETA: 1:14 - loss: 1.281611715\n",
            "4HTP_1_A\n",
            "[14, 51, 12, 48]\n",
            "38270/39120 [============================>.] - ETA: 1:14 - loss: 1.281631892\n",
            "4EMO_1_A\n",
            "[17, 47, 16, 38]\n",
            "38271/39120 [============================>.] - ETA: 1:14 - loss: 1.281619345\n",
            "3LV4_1_A\n",
            "[67, 45, 57, 0]\n",
            "38272/39120 [============================>.] - ETA: 1:14 - loss: 1.281633293\n",
            "3GQ4_d3gq4a1\n",
            "[28, 26, 71, 82]\n",
            "38273/39120 [============================>.] - ETA: 1:14 - loss: 1.281623010\n",
            "3JCR_19_3\n",
            "[27, 69, 34, 80]\n",
            "38274/39120 [============================>.] - ETA: 1:14 - loss: 1.281616698\n",
            "1RKL_1_A\n",
            "[63, 9, 79, 65]\n",
            "38275/39120 [============================>.] - ETA: 1:14 - loss: 1.281615004\n",
            "2IBJ_1_A\n",
            "[61, 22, 63, 14]\n",
            "38276/39120 [============================>.] - ETA: 1:13 - loss: 1.28166518\n",
            "4JO7_2_E\n",
            "[4, 59, 41, 89]\n",
            "38277/39120 [============================>.] - ETA: 1:13 - loss: 1.281637584\n",
            "3P48_1_A\n",
            "[61, 43, 1, 87]\n",
            "38278/39120 [============================>.] - ETA: 1:13 - loss: 1.281618694\n",
            "3CWZ_2_B\n",
            "[10, 87, 54, 16]\n",
            "38279/39120 [============================>.] - ETA: 1:13 - loss: 1.281636099\n",
            "2HYJ_d2hyja2\n",
            "[52, 63, 14, 45]\n",
            "38280/39120 [============================>.] - ETA: 1:13 - loss: 1.281634699\n",
            "4BZ4_1_A\n",
            "[7, 10, 0, 6]\n",
            "38281/39120 [============================>.] - ETA: 1:13 - loss: 1.28163795\n",
            "1XVI_1_A\n",
            "[10, 30, 32, 69]\n",
            "38282/39120 [============================>.] - ETA: 1:13 - loss: 1.28167029\n",
            "4HBQ_d4hbqb2\n",
            "[17, 33, 20, 22]\n",
            "38283/39120 [============================>.] - ETA: 1:13 - loss: 1.281618616\n",
            "3GRD_1_A\n",
            "[66, 1, 24, 51]\n",
            "38284/39120 [============================>.] - ETA: 1:13 - loss: 1.281614723\n",
            "2GI3_1_A\n",
            "[81, 49, 51, 27]\n",
            "38285/39120 [============================>.] - ETA: 1:13 - loss: 1.281622\n",
            "1KW6_1_B\n",
            "[72, 78, 1, 31]\n",
            "38286/39120 [============================>.] - ETA: 1:13 - loss: 1.28163806\n",
            "4RY1_1_A\n",
            "[89, 92, 67, 37]\n",
            "38287/39120 [============================>.] - ETA: 1:13 - loss: 1.281632710\n",
            "3EL6_1_A\n",
            "[98, 59, 37, 31]\n",
            "38288/39120 [============================>.] - ETA: 1:12 - loss: 1.281610458\n",
            "4FCE_d4fcea2\n",
            "[30, 24, 84, 12]\n",
            "38289/39120 [============================>.] - ETA: 1:12 - loss: 1.281623408\n",
            "3PMS_d3pmsa1\n",
            "[37, 90, 20, 82]\n",
            "38290/39120 [============================>.] - ETA: 1:12 - loss: 1.281626447\n",
            "3U7E_1_B\n",
            "[69, 31, 0, 33]\n",
            "38291/39120 [============================>.] - ETA: 1:12 - loss: 1.2816656\n",
            "3F1C_1_A\n",
            "[49, 32, 3, 16]\n",
            "38292/39120 [============================>.] - ETA: 1:12 - loss: 1.2816772\n",
            "4UQX_1_A\n",
            "[66, 15, 41, 53]\n",
            "38293/39120 [============================>.] - ETA: 1:12 - loss: 1.281631200\n",
            "3WMQ_1_A\n",
            "[99, 47, 68, 52]\n",
            "38294/39120 [============================>.] - ETA: 1:12 - loss: 1.281637213\n",
            "3O6Z_1_A\n",
            "[3, 57, 42, 91]\n",
            "38295/39120 [============================>.] - ETA: 1:12 - loss: 1.281633600\n",
            "3NUZ_1_A\n",
            "[74, 95, 40, 7]\n",
            "38296/39120 [============================>.] - ETA: 1:12 - loss: 1.281633567\n",
            "3QWX_1_X\n",
            "[3, 93, 75, 15]\n",
            "38297/39120 [============================>.] - ETA: 1:12 - loss: 1.281636062\n",
            "2N8H_1_A\n",
            "[19, 15, 56, 17]\n",
            "38298/39120 [============================>.] - ETA: 1:12 - loss: 1.281619661\n",
            "1WMT_1_A\n",
            "[70, 8, 35, 50]\n",
            "38299/39120 [============================>.] - ETA: 1:11 - loss: 1.281712765\n",
            "1ZSQ_d1zsqa2\n",
            "[31, 71, 14, 98]\n",
            "38300/39120 [============================>.] - ETA: 1:11 - loss: 1.281738238\n",
            "4LWP_1_B\n",
            "[71, 93, 0, 15]\n",
            "38301/39120 [============================>.] - ETA: 1:11 - loss: 1.281712570\n",
            "2H3G_1_X\n",
            "[70, 30, 12, 32]\n",
            "38302/39120 [============================>.] - ETA: 1:11 - loss: 1.281720040\n",
            "4UU9_3_C\n",
            "[19, 1, 95, 70]\n",
            "38303/39120 [============================>.] - ETA: 1:11 - loss: 1.281738150\n",
            "4LNI_d4lnil2\n",
            "[26, 5, 22, 67, 15]\n",
            "38304/39120 [============================>.] - ETA: 1:11 - loss: 1.281714823\n",
            "3KDP_3_G\n",
            "[42, 40, 53, 21]\n",
            "38305/39120 [============================>.] - ETA: 1:11 - loss: 1.281733785\n",
            "2CQE_1_A\n",
            "[44, 68, 93, 95]\n",
            "38306/39120 [============================>.] - ETA: 1:11 - loss: 1.281736616\n",
            "3AFK_1_A\n",
            "[83, 62, 28, 22]\n",
            "38307/39120 [============================>.] - ETA: 1:11 - loss: 1.281721681\n",
            "4OMB_1_A\n",
            "[22, 71, 50, 2]\n",
            "38308/39120 [============================>.] - ETA: 1:11 - loss: 1.281733112\n",
            "1BZG_1_A\n",
            "[13, 10, 43, 24]\n",
            "38309/39120 [============================>.] - ETA: 1:11 - loss: 1.281734863\n",
            "3X1T_4_C\n",
            "[3, 56, 21, 74]\n",
            "38310/39120 [============================>.] - ETA: 1:10 - loss: 1.281718346\n",
            "4JN6_d4jn6c2\n",
            "[45, 40, 73, 61]\n",
            "38311/39120 [============================>.] - ETA: 1:10 - loss: 1.281732437\n",
            "4ACI_1_A\n",
            "[8, 77, 45, 37]\n",
            "38312/39120 [============================>.] - ETA: 1:10 - loss: 1.281715617\n",
            "4IKD_1_A\n",
            "[53, 31, 28, 39]\n",
            "38313/39120 [============================>.] - ETA: 1:10 - loss: 1.281613579\n",
            "3MQH_1_A\n",
            "[52, 68, 66, 26]\n",
            "38314/39120 [============================>.] - ETA: 1:10 - loss: 1.281635648\n",
            "2JGB_1_A\n",
            "[63, 8, 20, 28]\n",
            "38315/39120 [============================>.] - ETA: 1:10 - loss: 1.281725470\n",
            "3P9N_1_A\n",
            "3P9N_1_A\n",
            "[97, 27, 90, 98, 88]\n",
            "38316/39120 [============================>.] - ETA: 1:10 - loss: 1.281738067\n",
            "4IGL_2_B\n",
            "[31, 6, 48, 94]\n",
            "38317/39120 [============================>.] - ETA: 1:10 - loss: 1.281737979\n",
            "4KP4_1_A\n",
            "[18, 5, 21, 73]\n",
            "38318/39120 [============================>.] - ETA: 1:10 - loss: 1.281636804\n",
            "1JM0_1_A\n",
            "[50, 89, 87, 84]\n",
            "38319/39120 [============================>.] - ETA: 1:10 - loss: 1.281630629\n",
            "3HKZ_13_Y\n",
            "[2, 5, 8, 0]\n",
            "38320/39120 [============================>.] - ETA: 1:10 - loss: 1.2816616\n",
            "3PRY_1_A\n",
            "[7, 69, 73, 47]\n",
            "38321/39120 [============================>.] - ETA: 1:10 - loss: 1.2816218\n",
            "3BB0_1_A\n",
            "[3, 76, 10, 0]\n",
            "38322/39120 [============================>.] - ETA: 1:09 - loss: 1.28166248\n",
            "4U6F_43_L6\n",
            "[36, 42, 89, 76]\n",
            "38323/39120 [============================>.] - ETA: 1:09 - loss: 1.281618893\n",
            "4I4J_1_A\n",
            "[43, 56, 39, 34]\n",
            "38324/39120 [============================>.] - ETA: 1:09 - loss: 1.281615011\n",
            "2P7O_1_A\n",
            "[93, 35, 27, 8]\n",
            "38325/39120 [============================>.] - ETA: 1:09 - loss: 1.281632553\n",
            "4V6U_15_AE\n",
            "[0, 46, 97, 84]\n",
            "38326/39120 [============================>.] - ETA: 1:09 - loss: 1.28164674\n",
            "1OYS_d1oysa2\n",
            "[10, 5, 33, 84]\n",
            "38327/39120 [============================>.] - ETA: 1:09 - loss: 1.281634611\n",
            "3W5N_1_A\n",
            "[22, 45, 59, 44]\n",
            "38328/39120 [============================>.] - ETA: 1:09 - loss: 1.281633609\n",
            "1L1L_1_A\n",
            "[49, 36, 56, 72]\n",
            "38329/39120 [============================>.] - ETA: 1:09 - loss: 1.281619531\n",
            "1L6J_d1l6ja5\n",
            "[38, 0, 5, 7]\n",
            "38330/39120 [============================>.] - ETA: 1:09 - loss: 1.28169963\n",
            "3ZYR_1_A\n",
            "[52, 4, 63, 47]\n",
            "38331/39120 [============================>.] - ETA: 1:09 - loss: 1.281633966\n",
            "3GTT_1_A\n",
            "[4, 13, 11, 25]\n",
            "38332/39120 [============================>.] - ETA: 1:09 - loss: 1.28169682\n",
            "4TTL_1_A\n",
            "[19, 46, 22, 77]\n",
            "38333/39120 [============================>.] - ETA: 1:08 - loss: 1.28168102\n",
            "2X7L_3_M\n",
            "[10, 7, 90, 74]\n",
            "38334/39120 [============================>.] - ETA: 1:08 - loss: 1.28177170\n",
            "1KMH_d1kmha2\n",
            "[59, 84, 33, 61]\n",
            "38335/39120 [============================>.] - ETA: 1:08 - loss: 1.281723523\n",
            "4X8Q_1_A\n",
            "[21, 34, 17, 35]\n",
            "38336/39120 [============================>.] - ETA: 1:08 - loss: 1.281726377\n",
            "2C00_d2c00b3\n",
            "[50, 15, 36, 75]\n",
            "38337/39120 [============================>.] - ETA: 1:08 - loss: 1.281719429\n",
            "5AOQ_2_L\n",
            "[18, 43, 7, 72]\n",
            "38338/39120 [============================>.] - ETA: 1:08 - loss: 1.281718474\n",
            "3R84_2_B\n",
            "[27, 92, 2, 31]\n",
            "38339/39120 [============================>.] - ETA: 1:08 - loss: 1.281712495\n",
            "4QAJ_1_A\n",
            "[19, 13, 12, 20]\n",
            "38340/39120 [============================>.] - ETA: 1:08 - loss: 1.281728992\n",
            "1JJG_1_A\n",
            "[9, 12, 7, 11]\n",
            "38341/39120 [============================>.] - ETA: 1:08 - loss: 1.281715029\n",
            "3WEO_d3weoa3\n",
            "[33, 73, 51, 54]\n",
            "38342/39120 [============================>.] - ETA: 1:08 - loss: 1.281718349\n",
            "3AGR_1_A\n",
            "[21, 59, 42, 43]\n",
            "38343/39120 [============================>.] - ETA: 1:08 - loss: 1.281727378\n",
            "1IIB_1_A\n",
            "[7, 78, 35, 13]\n",
            "38344/39120 [============================>.] - ETA: 1:08 - loss: 1.281719138\n",
            "2WQ7_1_A\n",
            "[4, 11, 96, 33]\n",
            "38345/39120 [============================>.] - ETA: 1:07 - loss: 1.281738032\n",
            "5FNP_1_A\n",
            "[85, 14, 1, 53]\n",
            "38346/39120 [============================>.] - ETA: 1:07 - loss: 1.28177346\n",
            "4XWM_1_A\n",
            "[13, 88, 69, 58]\n",
            "38347/39120 [============================>.] - ETA: 1:07 - loss: 1.28169753\n",
            "3PLU_1_A\n",
            "[43, 72, 53, 57]\n",
            "38348/39120 [============================>.] - ETA: 1:07 - loss: 1.281724203\n",
            "4D0N_2_B\n",
            "[16, 47, 11, 75]\n",
            "38349/39120 [============================>.] - ETA: 1:07 - loss: 1.281724907\n",
            "5EZV_2_B\n",
            "[11, 85, 21, 87]\n",
            "38350/39120 [============================>.] - ETA: 1:07 - loss: 1.281631154\n",
            "5IUC_1_A\n",
            "[1, 0]\n",
            "38351/39120 [============================>.] - ETA: 1:07 - loss: 1.281612424\n",
            "1C7S_d1c7sa2\n",
            "[88, 69, 73, 52]\n",
            "38352/39120 [============================>.] - ETA: 1:07 - loss: 1.281717375\n",
            "3AGX_d3agxb2\n",
            "[66, 5, 23, 25]\n",
            "38353/39120 [============================>.] - ETA: 1:07 - loss: 1.281718365\n",
            "4YSX_3_C\n",
            "[17, 9, 69, 80]\n",
            "38354/39120 [============================>.] - ETA: 1:07 - loss: 1.281718638\n",
            "2XDP_1_A\n",
            "[89, 46, 63, 31]\n",
            "38355/39120 [============================>.] - ETA: 1:07 - loss: 1.281613038\n",
            "2CFO_1_A\n",
            "[19, 75, 12, 80]\n",
            "38356/39120 [============================>.] - ETA: 1:06 - loss: 1.281636957\n",
            "4EB2_2_B\n",
            "[93, 12, 36, 76]\n",
            "38357/39120 [============================>.] - ETA: 1:06 - loss: 1.281615172\n",
            "2OJL_1_A\n",
            "[74, 45, 13, 6]\n",
            "38358/39120 [============================>.] - ETA: 1:06 - loss: 1.281624086\n",
            "2LFC_1_A\n",
            "[6, 69, 82, 46]\n",
            "38359/39120 [============================>.] - ETA: 1:06 - loss: 1.281710525\n",
            "1V8C_d1v8cd1\n",
            "[62, 20, 53, 19]\n",
            "38360/39120 [============================>.] - ETA: 1:06 - loss: 1.281719173\n",
            "2FSW_1_A\n",
            "[99, 50, 28, 91]\n",
            "38361/39120 [============================>.] - ETA: 1:06 - loss: 1.281720789\n",
            "4CW5_1_A\n",
            "[61, 97, 85, 99]\n",
            "38362/39120 [============================>.] - ETA: 1:06 - loss: 1.281721384\n",
            "4OYU_1_A\n",
            "[4, 98, 78, 67]\n",
            "38363/39120 [============================>.] - ETA: 1:06 - loss: 1.2817147\n",
            "5IJO_6_H\n",
            "[46, 69, 86, 33]\n",
            "38364/39120 [============================>.] - ETA: 1:06 - loss: 1.281712649\n",
            "2M97_1_A\n",
            "[86, 11, 4, 78]\n",
            "38365/39120 [============================>.] - ETA: 1:06 - loss: 1.2817141\n",
            "1GYT_d1gytl1\n",
            "[92, 49, 5, 8]\n",
            "38366/39120 [============================>.] - ETA: 1:06 - loss: 1.28165300\n",
            "2OJ6_d2oj6c1\n",
            "[4, 3, 0, 2]\n",
            "38367/39120 [============================>.] - ETA: 1:05 - loss: 1.281636755\n",
            "2HKU_d2hkua1\n",
            "[73, 95, 77, 15]\n",
            "38368/39120 [============================>.] - ETA: 1:05 - loss: 1.281719994\n",
            "1VK6_d1vk6a3\n",
            "[45, 85, 59, 80]\n",
            "38369/39120 [============================>.] - ETA: 1:05 - loss: 1.281628732\n",
            "1WLF_d1wlfa1\n",
            "[18, 17, 11, 82]\n",
            "38370/39120 [============================>.] - ETA: 1:05 - loss: 1.28165247\n",
            "2X5H_1_A\n",
            "[6, 1, 2, 7]\n",
            "38371/39120 [============================>.] - ETA: 1:05 - loss: 1.28164327\n",
            "2AXO_1_A\n",
            "[65, 63, 35, 24]\n",
            "38372/39120 [============================>.] - ETA: 1:05 - loss: 1.281630103\n",
            "1O7D_3_C\n",
            "[91, 20, 70, 38]\n",
            "38373/39120 [============================>.] - ETA: 1:05 - loss: 1.281630224\n",
            "4V6U_55_Bh\n",
            "[31, 38, 29, 10]\n",
            "38374/39120 [============================>.] - ETA: 1:05 - loss: 1.281638802\n",
            "3MVG_1_A\n",
            "[80, 77, 73, 13]\n",
            "38375/39120 [============================>.] - ETA: 1:05 - loss: 1.281638160\n",
            "1J0W_1_A\n",
            "[4, 99, 17, 72]\n",
            "38376/39120 [============================>.] - ETA: 1:05 - loss: 1.281613047\n",
            "2CRG_1_A\n",
            "[54, 37, 35, 44]\n",
            "38377/39120 [============================>.] - ETA: 1:05 - loss: 1.281616983\n",
            "4DY5_1_A\n",
            "[0, 81, 65, 86]\n",
            "38378/39120 [============================>.] - ETA: 1:05 - loss: 1.281628722\n",
            "2FMB_1_A\n",
            "[30, 57, 52, 6, 12, 92, 86]\n",
            "38379/39120 [============================>.] - ETA: 1:04 - loss: 1.28162329\n",
            "4OOP_1_A\n",
            "[50, 46, 20, 54]\n",
            "38380/39120 [============================>.] - ETA: 1:04 - loss: 1.281613172\n",
            "1I2H_d1i2ha1\n",
            "[12, 68, 50, 78]\n",
            "38381/39120 [============================>.] - ETA: 1:04 - loss: 1.281610496\n",
            "3CVE_1_A\n",
            "[26, 71, 81, 93]\n",
            "38382/39120 [============================>.] - ETA: 1:04 - loss: 1.28166323\n",
            "2R8W_1_A\n",
            "[21, 4, 65, 83]\n",
            "38383/39120 [============================>.] - ETA: 1:04 - loss: 1.28163891\n",
            "4G6Z_1_A\n",
            "[29, 91, 31, 35]\n",
            "38384/39120 [============================>.] - ETA: 1:04 - loss: 1.281629443\n",
            "3BPJ_1_A\n",
            "[61, 41, 49, 24]\n",
            "38385/39120 [============================>.] - ETA: 1:04 - loss: 1.281696\n",
            "3K8W_1_A\n",
            "[19, 88, 92, 26]\n",
            "38386/39120 [============================>.] - ETA: 1:04 - loss: 1.281622197\n",
            "4Q57_2_B\n",
            "[64, 44, 84, 67]\n",
            "38387/39120 [============================>.] - ETA: 1:04 - loss: 1.281632396\n",
            "1TQY_2_B\n",
            "[57, 64, 80, 1]\n",
            "38388/39120 [============================>.] - ETA: 1:04 - loss: 1.28168234\n",
            "4FDG_1_B\n",
            "[10, 68, 80, 1]\n",
            "38389/39120 [============================>.] - ETA: 1:04 - loss: 1.281620290\n",
            "1Z65_1_A\n",
            "[15, 16, 14, 17]\n",
            "38390/39120 [============================>.] - ETA: 1:03 - loss: 1.28162956\n",
            "1I8L_d1i8lb2\n",
            "[86, 12, 13, 80]\n",
            "38391/39120 [============================>.] - ETA: 1:03 - loss: 1.28163667\n",
            "1PGL_3_2\n",
            "[12, 10, 5, 2]\n",
            "38392/39120 [============================>.] - ETA: 1:03 - loss: 1.281622276\n",
            "4KZT_1_A\n",
            "[80, 26, 63, 85]\n",
            "38393/39120 [============================>.] - ETA: 1:03 - loss: 1.281618053\n",
            "3WD8_d3wd8d2\n",
            "[12, 95, 88, 87]\n",
            "38394/39120 [============================>.] - ETA: 1:03 - loss: 1.281631528\n",
            "4IGK_1_A\n",
            "[58, 86, 66, 2]\n",
            "38395/39120 [============================>.] - ETA: 1:03 - loss: 1.281610755\n",
            "2F6H_1_X\n",
            "[72, 15, 36, 67]\n",
            "38396/39120 [============================>.] - ETA: 1:03 - loss: 1.281615155\n",
            "1RWH_d1rwha3\n",
            "[82, 20, 2, 60]\n",
            "38397/39120 [============================>.] - ETA: 1:03 - loss: 1.28162137\n",
            "3QU3_1_A\n",
            "[57, 29, 25, 16]\n",
            "38398/39120 [============================>.] - ETA: 1:03 - loss: 1.281627130\n",
            "4PW2_1_A\n",
            "[74, 53, 34, 77]\n",
            "38399/39120 [============================>.] - ETA: 1:03 - loss: 1.281629995\n",
            "1XZO_1_A\n",
            "[45, 48, 76, 27]\n",
            "38400/39120 [============================>.] - ETA: 1:03 - loss: 1.28166089\n",
            "3EYX_1_A\n",
            "[87, 80, 86, 60]\n",
            "38401/39120 [============================>.] - ETA: 1:03 - loss: 1.281635433\n",
            "3J2W_4_E\n",
            "[13, 29, 3, 22]\n",
            "38402/39120 [============================>.] - ETA: 1:02 - loss: 1.281637520\n",
            "3CCZ_1_A\n",
            "[78, 45, 9, 25]\n",
            "38403/39120 [============================>.] - ETA: 1:02 - loss: 1.281634780\n",
            "1FJR_1_A\n",
            "[54, 61, 85, 7]\n",
            "38404/39120 [============================>.] - ETA: 1:02 - loss: 1.281616591\n",
            "4R17_5_E\n",
            "[61, 1, 92, 44]\n",
            "38405/39120 [============================>.] - ETA: 1:02 - loss: 1.28167930\n",
            "2KI7_1_A\n",
            "[92, 36, 10, 32]\n",
            "38406/39120 [============================>.] - ETA: 1:02 - loss: 1.28165193\n",
            "1EYE_1_A\n",
            "[19, 52, 49, 55]\n",
            "38407/39120 [============================>.] - ETA: 1:02 - loss: 1.28162936\n",
            "1G29_d1g2923\n",
            "[15, 8, 10, 55]\n",
            "38408/39120 [============================>.] - ETA: 1:02 - loss: 1.28161634\n",
            "1XK8_1_A\n",
            "[57, 88, 95, 58]\n",
            "38409/39120 [============================>.] - ETA: 1:02 - loss: 1.281616074\n",
            "1ZXJ_1_A\n",
            "[39, 30, 77, 99]\n",
            "38410/39120 [============================>.] - ETA: 1:02 - loss: 1.281616977\n",
            "2OG5_1_A\n",
            "[79, 98, 44, 51]\n",
            "38411/39120 [============================>.] - ETA: 1:02 - loss: 1.281619692\n",
            "4S2Q_3_D\n",
            "[20, 85, 96, 76]\n",
            "38412/39120 [============================>.] - ETA: 1:02 - loss: 1.281618244\n",
            "4PZV_1_A\n",
            "[62, 49, 87, 68]\n",
            "38413/39120 [============================>.] - ETA: 1:01 - loss: 1.281621269\n",
            "1UVQ_d1uvqa2\n",
            "[88, 93, 7, 38]\n",
            "38414/39120 [============================>.] - ETA: 1:01 - loss: 1.281610015\n",
            "4XD9_2_B\n",
            "[17, 57, 48, 94]\n",
            "38415/39120 [============================>.] - ETA: 1:01 - loss: 1.281627763\n",
            "5CTQ_1_A\n",
            "[19, 46, 3, 84]\n",
            "38416/39120 [============================>.] - ETA: 1:01 - loss: 1.281619651\n",
            "1T60_d1t60i1\n",
            "[58, 68, 1, 62]\n",
            "38417/39120 [============================>.] - ETA: 1:01 - loss: 1.281521420\n",
            "3N5K_d3n5kb4\n",
            "[66, 71, 62, 35]\n",
            "38418/39120 [============================>.] - ETA: 1:01 - loss: 1.28167711\n",
            "4WAT_1_A\n",
            "[1, 65, 55, 66]\n",
            "38419/39120 [============================>.] - ETA: 1:01 - loss: 1.281622107\n",
            "2ZAD_d2zadd1\n",
            "[61, 11, 81, 27]\n",
            "38420/39120 [============================>.] - ETA: 1:01 - loss: 1.281623615\n",
            "2JDW_1_A\n",
            "[42, 73, 76, 71]\n",
            "38421/39120 [============================>.] - ETA: 1:01 - loss: 1.281628507\n",
            "2MBF_1_A\n",
            "[71, 1, 0, 92]\n",
            "38422/39120 [============================>.] - ETA: 1:01 - loss: 1.28166500\n",
            "3RTY_1_A\n",
            "[57, 0, 71, 88]\n",
            "38423/39120 [============================>.] - ETA: 1:01 - loss: 1.28165027\n",
            "2DBS_1_A\n",
            "[5, 6, 1, 2]\n",
            "38424/39120 [============================>.] - ETA: 1:00 - loss: 1.281623214\n",
            "3TX2_1_A\n",
            "[60, 35, 13, 78]\n",
            "38425/39120 [============================>.] - ETA: 1:00 - loss: 1.28165993\n",
            "2ROW_1_A\n",
            "[17, 93, 21, 70]\n",
            "38426/39120 [============================>.] - ETA: 1:00 - loss: 1.281633541\n",
            "2QTQ_1_A\n",
            "[16, 38, 52, 36]\n",
            "38427/39120 [============================>.] - ETA: 1:00 - loss: 1.281622971\n",
            "3N6O_1_A\n",
            "[33, 65, 58, 1]\n",
            "38428/39120 [============================>.] - ETA: 1:00 - loss: 1.281622869\n",
            "2MBR_d2mbra2\n",
            "[3, 5, 18, 35]\n",
            "38429/39120 [============================>.] - ETA: 1:00 - loss: 1.281635486\n",
            "2RRI_1_A\n",
            "[44, 65, 60, 89]\n",
            "38430/39120 [============================>.] - ETA: 1:00 - loss: 1.28167954\n",
            "1QHP_d1qhpa2\n",
            "[65, 63, 78, 39]\n",
            "38431/39120 [============================>.] - ETA: 1:00 - loss: 1.28159362\n",
            "3NFI_1_A\n",
            "3NFI_1_A\n",
            "[69, 20, 23, 94, 7]\n",
            "38432/39120 [============================>.] - ETA: 1:00 - loss: 1.281518351\n",
            "4U6F_26_D4\n",
            "[69, 85, 75, 6]\n",
            "38433/39120 [============================>.] - ETA: 1:00 - loss: 1.28154364\n",
            "1X6Z_1_A\n",
            "[1, 87, 32, 82]\n",
            "38434/39120 [============================>.] - ETA: 1:00 - loss: 1.281525595\n",
            "3T3P_2_B\n",
            "[90, 71, 67, 7]\n",
            "38435/39120 [============================>.] - ETA: 1:00 - loss: 1.281629460\n",
            "2M9H_1_A\n",
            "[36, 84, 48, 11]\n",
            "38436/39120 [============================>.] - ETA: 59s - loss: 1.2816 35167\n",
            "1KSI_d1ksib3\n",
            "[43, 44, 86, 75]\n",
            "38437/39120 [============================>.] - ETA: 59s - loss: 1.281623018\n",
            "1X4K_d1x4ka1\n",
            "[94, 13, 5, 30]\n",
            "38438/39120 [============================>.] - ETA: 59s - loss: 1.28163398\n",
            "2AYI_1_A\n",
            "[81, 46, 45, 77]\n",
            "38439/39120 [============================>.] - ETA: 59s - loss: 1.28163438\n",
            "2L0T_2_B\n",
            "[12, 15, 87, 86]\n",
            "38440/39120 [============================>.] - ETA: 59s - loss: 1.28167553\n",
            "3GSD_1_A\n",
            "[17, 73, 61, 98]\n",
            "38441/39120 [============================>.] - ETA: 59s - loss: 1.281633684\n",
            "2JFR_1_A\n",
            "[31, 52, 58, 83]\n",
            "38442/39120 [============================>.] - ETA: 59s - loss: 1.281636230\n",
            "1YKW_1_A\n",
            "[7, 50, 40, 19]\n",
            "38443/39120 [============================>.] - ETA: 59s - loss: 1.281614700\n",
            "1VJK_1_A\n",
            "[59, 0, 33, 12]\n",
            "38444/39120 [============================>.] - ETA: 59s - loss: 1.28166857\n",
            "4ZBL_1_A\n",
            "[50, 67, 61, 40]\n",
            "38445/39120 [============================>.] - ETA: 59s - loss: 1.281635791\n",
            "1FNG_d1fngd2\n",
            "[73, 75, 93, 18]\n",
            "38446/39120 [============================>.] - ETA: 59s - loss: 1.28161375\n",
            "2SNI_2_I\n",
            "[63, 72, 73, 24]\n",
            "38447/39120 [============================>.] - ETA: 58s - loss: 1.281623492\n",
            "5EO4_1_A\n",
            "[44, 68, 40, 2]\n",
            "38448/39120 [============================>.] - ETA: 58s - loss: 1.28168443\n",
            "4EHC_1_A\n",
            "[88, 4, 10, 81]\n",
            "38449/39120 [============================>.] - ETA: 58s - loss: 1.28166282\n",
            "2VG1_1_A\n",
            "[51, 57, 1, 55]\n",
            "38450/39120 [============================>.] - ETA: 58s - loss: 1.281621604\n",
            "3ETP_1_A\n",
            "[47, 6, 63, 59]\n",
            "38451/39120 [============================>.] - ETA: 58s - loss: 1.281620870\n",
            "4Z7C_1_A\n",
            "[96, 89, 50, 17]\n",
            "38452/39120 [============================>.] - ETA: 58s - loss: 1.281636053\n",
            "1PCS_1_A\n",
            "[46, 34, 66, 12]\n",
            "38453/39120 [============================>.] - ETA: 58s - loss: 1.28166844\n",
            "2WJV_2_D\n",
            "[78, 16, 63, 10]\n",
            "38454/39120 [============================>.] - ETA: 58s - loss: 1.281610787\n",
            "4Q2L_1_A\n",
            "[19, 29, 64, 79]\n",
            "38455/39120 [============================>.] - ETA: 58s - loss: 1.28166194\n",
            "1YSJ_1_A\n",
            "[0, 60, 73, 52]\n",
            "38456/39120 [============================>.] - ETA: 58s - loss: 1.281629949\n",
            "2VLA_1_A\n",
            "[35, 28, 20, 42]\n",
            "38457/39120 [============================>.] - ETA: 58s - loss: 1.281628883\n",
            "2EYW_1_A\n",
            "[91, 48, 70, 40]\n",
            "38458/39120 [============================>.] - ETA: 58s - loss: 1.281721467\n",
            "3F7X_1_A\n",
            "[15, 63, 49, 73]\n",
            "38459/39120 [============================>.] - ETA: 57s - loss: 1.2817265\n",
            "2BAY_1_A\n",
            "[43, 1, 71, 88]\n",
            "38460/39120 [============================>.] - ETA: 57s - loss: 1.281731049\n",
            "1YDO_1_A\n",
            "[62, 9, 19, 26]\n",
            "38461/39120 [============================>.] - ETA: 57s - loss: 1.281711828\n",
            "1RF8_2_B\n",
            "[13, 60, 39, 22]\n",
            "38462/39120 [============================>.] - ETA: 57s - loss: 1.281734704\n",
            "4BD9_d4bd9b3\n",
            "[49, 35, 42, 70]\n",
            "38463/39120 [============================>.] - ETA: 57s - loss: 1.281724542\n",
            "4X8I_1_A\n",
            "[11, 38, 31, 20]\n",
            "38464/39120 [============================>.] - ETA: 57s - loss: 1.281737753\n",
            "4V8M_29_AV\n",
            "[45, 19, 52, 79]\n",
            "38465/39120 [============================>.] - ETA: 57s - loss: 1.281713206\n",
            "2D4P_1_A\n",
            "[57, 12, 84, 40]\n",
            "38466/39120 [============================>.] - ETA: 57s - loss: 1.281730600\n",
            "5E9T_1_A\n",
            "[35, 12, 42, 49]\n",
            "38467/39120 [============================>.] - ETA: 57s - loss: 1.281719044\n",
            "2ZR1_2_B\n",
            "[31, 30, 25, 94]\n",
            "38468/39120 [============================>.] - ETA: 57s - loss: 1.281729991\n",
            "1WN0_1_A\n",
            "[67, 50, 69, 88]\n",
            "38469/39120 [============================>.] - ETA: 57s - loss: 1.281738976\n",
            "2CVL_1_A\n",
            "[6, 33, 1, 56]\n",
            "38470/39120 [============================>.] - ETA: 56s - loss: 1.281710610\n",
            "4WO7_1_A\n",
            "[53, 67, 13, 66]\n",
            "38471/39120 [============================>.] - ETA: 56s - loss: 1.28171385\n",
            "3KZU_1_A\n",
            "[98, 63, 92, 71]\n",
            "38472/39120 [============================>.] - ETA: 56s - loss: 1.281718891\n",
            "2L7Q_1_A\n",
            "[76, 28, 2, 62]\n",
            "38473/39120 [============================>.] - ETA: 56s - loss: 1.281730127\n",
            "3JAQ_42_m\n",
            "[43, 47, 50, 16]\n",
            "38474/39120 [============================>.] - ETA: 56s - loss: 1.281715242\n",
            "5GAM_6_e\n",
            "[51, 7, 52, 24]\n",
            "38475/39120 [============================>.] - ETA: 56s - loss: 1.281719435\n",
            "3VJ6_1_A\n",
            "[90, 52, 79, 96]\n",
            "38476/39120 [============================>.] - ETA: 56s - loss: 1.281739010\n",
            "3DB0_1_A\n",
            "[65, 2, 36, 50]\n",
            "38477/39120 [============================>.] - ETA: 56s - loss: 1.281725704\n",
            "1TVF_d1tvfb2\n",
            "[86, 22, 70, 77]\n",
            "38478/39120 [============================>.] - ETA: 56s - loss: 1.28171975\n",
            "5FMG_4_D\n",
            "[93, 13, 90, 58]\n",
            "38479/39120 [============================>.] - ETA: 56s - loss: 1.281714045\n",
            "1WLJ_1_A\n",
            "[63, 8, 87, 80]\n",
            "38480/39120 [============================>.] - ETA: 56s - loss: 1.28174253\n",
            "2R8O_d2r8ob1\n",
            "[19, 29, 45, 58]\n",
            "38481/39120 [============================>.] - ETA: 55s - loss: 1.281734193\n",
            "3K7N_1_A\n",
            "[38, 61, 8, 62]\n",
            "38482/39120 [============================>.] - ETA: 55s - loss: 1.281730509\n",
            "1QQH_1_A\n",
            "[34, 19, 43, 69]\n",
            "38483/39120 [============================>.] - ETA: 55s - loss: 1.281728867\n",
            "3GNJ_1_A\n",
            "[25, 80, 98, 36]\n",
            "38484/39120 [============================>.] - ETA: 55s - loss: 1.281735855\n",
            "1L3G_1_A\n",
            "[44, 62, 84, 88]\n",
            "38485/39120 [============================>.] - ETA: 55s - loss: 1.281715832\n",
            "4CD5_1_A\n",
            "[50, 55, 32, 97]\n",
            "38486/39120 [============================>.] - ETA: 55s - loss: 1.281710526\n",
            "4BDX_1_A\n",
            "[9, 23, 61, 92]\n",
            "38487/39120 [============================>.] - ETA: 55s - loss: 1.281719926\n",
            "2JU0_1_A\n",
            "[66, 64, 75, 37]\n",
            "38488/39120 [============================>.] - ETA: 55s - loss: 1.28178173\n",
            "2MJ9_1_A\n",
            "[24, 35, 97, 58]\n",
            "38489/39120 [============================>.] - ETA: 55s - loss: 1.281713640\n",
            "4YIP_d4yipd2\n",
            "[42, 28, 12, 29]\n",
            "38490/39120 [============================>.] - ETA: 55s - loss: 1.281715396\n",
            "1G99_d1g99b2\n",
            "[55, 7, 22, 45]\n",
            "38491/39120 [============================>.] - ETA: 55s - loss: 1.281711030\n",
            "1RIL_1_A\n",
            "[20, 96, 16, 15]\n",
            "38492/39120 [============================>.] - ETA: 55s - loss: 1.281733679\n",
            "2OGK_1_A\n",
            "[5, 90, 52, 82]\n",
            "38493/39120 [============================>.] - ETA: 54s - loss: 1.281738885\n",
            "1WDK_2_C\n",
            "[85, 24, 39, 20]\n",
            "38494/39120 [============================>.] - ETA: 54s - loss: 1.28177011\n",
            "1SQW_d1sqwa1\n",
            "[79, 24, 12, 11]\n",
            "38495/39120 [============================>.] - ETA: 54s - loss: 1.281716061\n",
            "3DRF_1_A\n",
            "[23, 72, 80, 70]\n",
            "38496/39120 [============================>.] - ETA: 54s - loss: 1.281714878\n",
            "3LPW_1_A\n",
            "[34, 5, 37, 86]\n",
            "38497/39120 [============================>.] - ETA: 54s - loss: 1.281710301\n",
            "2HUR_1_A\n",
            "[18, 98, 99, 97]\n",
            "38498/39120 [============================>.] - ETA: 54s - loss: 1.281720798\n",
            "1QB7_1_A\n",
            "[1, 87, 70, 33]\n",
            "38499/39120 [============================>.] - ETA: 54s - loss: 1.2817583\n",
            "4K3C_1_A\n",
            "[24, 82, 89, 31]\n",
            "38500/39120 [============================>.] - ETA: 54s - loss: 1.281719640\n",
            "2EIG_1_A\n",
            "[40, 80, 59, 3]\n",
            "38501/39120 [============================>.] - ETA: 54s - loss: 1.281711156\n",
            "5FYK_1_B\n",
            "[86, 30, 7, 43]\n",
            "38502/39120 [============================>.] - ETA: 54s - loss: 1.281736137\n",
            "2DNX_1_A\n",
            "[61, 80, 25, 73]\n",
            "38503/39120 [============================>.] - ETA: 54s - loss: 1.281722409\n",
            "2IF4_d2if4a2\n",
            "[44, 86, 99, 66]\n",
            "38504/39120 [============================>.] - ETA: 53s - loss: 1.281712055\n",
            "3I4I_1_A\n",
            "[91, 52, 85, 5]\n",
            "38505/39120 [============================>.] - ETA: 53s - loss: 1.281736585\n",
            "1DSQ_1_A\n",
            "[40, 97, 12, 67]\n",
            "38506/39120 [============================>.] - ETA: 53s - loss: 1.281710468\n",
            "3DJL_1_A\n",
            "[33, 21, 40, 6]\n",
            "38507/39120 [============================>.] - ETA: 53s - loss: 1.2817735\n",
            "3D03_1_A\n",
            "[36, 30, 91, 9]\n",
            "38508/39120 [============================>.] - ETA: 53s - loss: 1.281728669\n",
            "2JP3_1_A\n",
            "[27, 8, 70, 80]\n",
            "38509/39120 [============================>.] - ETA: 53s - loss: 1.281737605\n",
            "1OBO_1_A\n",
            "[65, 64, 8, 27]\n",
            "38510/39120 [============================>.] - ETA: 53s - loss: 1.281726380\n",
            "4JCP_1_A\n",
            "[49, 80, 43, 78]\n",
            "38511/39120 [============================>.] - ETA: 53s - loss: 1.281728023\n",
            "1A8L_d1a8la2\n",
            "[89, 68, 76, 5]\n",
            "38512/39120 [============================>.] - ETA: 53s - loss: 1.281735712\n",
            "1G92_1_A\n",
            "[0]\n",
            "38513/39120 [============================>.] - ETA: 53s - loss: 1.281733043\n",
            "5EUH_1_A\n",
            "[63, 77, 24, 69]\n",
            "38514/39120 [============================>.] - ETA: 53s - loss: 1.28173447\n",
            "3NY4_1_A\n",
            "[93, 57, 6, 74]\n",
            "38515/39120 [============================>.] - ETA: 53s - loss: 1.281718387\n",
            "1GAI_1_A\n",
            "[88, 79, 59, 28]\n",
            "38516/39120 [============================>.] - ETA: 52s - loss: 1.281717571\n",
            "2PBF_1_A\n",
            "[66, 92, 46, 45]\n",
            "38517/39120 [============================>.] - ETA: 52s - loss: 1.281714285\n",
            "2C43_1_A\n",
            "[77, 2, 67, 88]\n",
            "38518/39120 [============================>.] - ETA: 52s - loss: 1.281735448\n",
            "2NN6_d2nn6d2\n",
            "[43, 97, 13, 57]\n",
            "38519/39120 [============================>.] - ETA: 52s - loss: 1.28178390\n",
            "3U43_2_B\n",
            "[57, 9, 77, 35]\n",
            "38520/39120 [============================>.] - ETA: 52s - loss: 1.281716151\n",
            "5CUK_1_A\n",
            "[12, 0, 11, 32]\n",
            "38521/39120 [============================>.] - ETA: 52s - loss: 1.281719246\n",
            "2A0L_1_A\n",
            "[91, 56, 98, 41]\n",
            "38522/39120 [============================>.] - ETA: 52s - loss: 1.281726452\n",
            "1CKN_d1cknb1\n",
            "[98, 37, 69, 92]\n",
            "38523/39120 [============================>.] - ETA: 52s - loss: 1.28178648\n",
            "3FE4_1_A\n",
            "[20, 0, 55, 56]\n",
            "38524/39120 [============================>.] - ETA: 52s - loss: 1.281722216\n",
            "3VX4_1_A\n",
            "[6, 42, 34, 84]\n",
            "38525/39120 [============================>.] - ETA: 52s - loss: 1.281714069\n",
            "5C7O_1_O\n",
            "[5, 89, 87, 3]\n",
            "38526/39120 [============================>.] - ETA: 52s - loss: 1.281722589\n",
            "1UWY_d1uwya2\n",
            "[86, 29, 49, 18]\n",
            "38527/39120 [============================>.] - ETA: 51s - loss: 1.281712053\n",
            "3WV6_1_A\n",
            "[68, 74, 3, 85]\n",
            "38528/39120 [============================>.] - ETA: 51s - loss: 1.2817227\n",
            "3HMS_1_A\n",
            "[27, 15, 48, 59]\n",
            "38529/39120 [============================>.] - ETA: 51s - loss: 1.281718352\n",
            "2YZK_1_A\n",
            "[62, 1, 30, 13]\n",
            "38530/39120 [============================>.] - ETA: 51s - loss: 1.281732621\n",
            "1YLO_1_A\n",
            "[34, 25, 95, 2]\n",
            "38531/39120 [============================>.] - ETA: 51s - loss: 1.281718565\n",
            "2HF5_d2hf5a1\n",
            "[6, 29, 36, 18]\n",
            "38532/39120 [============================>.] - ETA: 51s - loss: 1.281714005\n",
            "1WGX_1_A\n",
            "[63, 83, 19, 38]\n",
            "38533/39120 [============================>.] - ETA: 51s - loss: 1.281739003\n",
            "3K4H_1_A\n",
            "[17, 80, 86, 3]\n",
            "38534/39120 [============================>.] - ETA: 51s - loss: 1.281716219\n",
            "3SJQ_2_C\n",
            "[74, 90, 9, 26]\n",
            "38535/39120 [============================>.] - ETA: 51s - loss: 1.281726961\n",
            "4H62_2_V\n",
            "[1, 0]\n",
            "38536/39120 [============================>.] - ETA: 51s - loss: 1.281720426\n",
            "2BCW_3_C\n",
            "[95, 27, 74, 7]\n",
            "38537/39120 [============================>.] - ETA: 51s - loss: 1.2817394\n",
            "2Y3C_1_A\n",
            "[73, 49, 84, 7]\n",
            "38538/39120 [============================>.] - ETA: 50s - loss: 1.281728763\n",
            "2BHG_1_A\n",
            "[54, 90, 38, 97]\n",
            "38539/39120 [============================>.] - ETA: 50s - loss: 1.281715196\n",
            "4YN1_1_A\n",
            "[50, 59, 2, 90]\n",
            "38540/39120 [============================>.] - ETA: 50s - loss: 1.281729191\n",
            "3OUT_1_A\n",
            "[35, 6, 84, 78]\n",
            "38541/39120 [============================>.] - ETA: 50s - loss: 1.281736231\n",
            "4DVQ_1_A\n",
            "[49, 2, 36, 75]\n",
            "38542/39120 [============================>.] - ETA: 50s - loss: 1.281728564\n",
            "3USH_1_A\n",
            "[13, 36, 79, 66]\n",
            "38543/39120 [============================>.] - ETA: 50s - loss: 1.281711918\n",
            "3J7Q_41_m\n",
            "[95, 57, 89, 79, 29, 37, 66, 22, 76, 41, 73, 7, 4, 30, 90, 99, 84, 26, 23]\n",
            "38544/39120 [============================>.] - ETA: 50s - loss: 1.281722322\n",
            "4WW8_1_A\n",
            "[45, 30, 23, 38]\n",
            "38545/39120 [============================>.] - ETA: 50s - loss: 1.281717711\n",
            "4V8P_18_AU\n",
            "[86, 6, 84, 42]\n",
            "38546/39120 [============================>.] - ETA: 50s - loss: 1.281734499\n",
            "1BY6_1_A\n",
            "[17, 10, 31, 40]\n",
            "38547/39120 [============================>.] - ETA: 50s - loss: 1.281710264\n",
            "2K2D_1_A\n",
            "[20, 32, 85, 5]\n",
            "38548/39120 [============================>.] - ETA: 50s - loss: 1.281810935\n",
            "4PQ9_1_A\n",
            "[49, 27, 72, 16]\n",
            "38549/39120 [============================>.] - ETA: 50s - loss: 1.281834757\n",
            "4PYR_1_A\n",
            "[45, 58, 80, 12]\n",
            "38550/39120 [============================>.] - ETA: 49s - loss: 1.281839071\n",
            "3D3B_2_J\n",
            "[54, 53, 82, 24]\n",
            "38551/39120 [============================>.] - ETA: 49s - loss: 1.28183\n",
            "2ZPO_1_A\n",
            "[29, 37, 28, 6, 21]\n",
            "38552/39120 [============================>.] - ETA: 49s - loss: 1.281818747\n",
            "1VE3_1_A\n",
            "[66, 71, 96, 13]\n",
            "38553/39120 [============================>.] - ETA: 49s - loss: 1.281815695\n",
            "5CJ4_1_A\n",
            "[84, 23, 45, 52]\n",
            "38554/39120 [============================>.] - ETA: 49s - loss: 1.281815902\n",
            "1CY9_1_A\n",
            "[2, 39, 4, 12]\n",
            "38555/39120 [============================>.] - ETA: 49s - loss: 1.281822347\n",
            "3B85_1_A\n",
            "[83, 28, 37, 15]\n",
            "38556/39120 [============================>.] - ETA: 49s - loss: 1.28184548\n",
            "4I66_1_A\n",
            "[80, 29, 8, 94]\n",
            "38557/39120 [============================>.] - ETA: 49s - loss: 1.281811207\n",
            "1OLP_1_A\n",
            "[85, 11, 42, 48]\n",
            "38558/39120 [============================>.] - ETA: 49s - loss: 1.281811114\n",
            "2ZJ8_1_A\n",
            "[27, 70, 78, 93]\n",
            "38559/39120 [============================>.] - ETA: 49s - loss: 1.281822530\n",
            "1SQG_d1sqga1\n",
            "[10, 70, 89, 38]\n",
            "38560/39120 [============================>.] - ETA: 49s - loss: 1.281830954\n",
            "1Q0V_1_A\n",
            "[55, 47, 10, 95]\n",
            "38561/39120 [============================>.] - ETA: 48s - loss: 1.281838989\n",
            "3NRW_1_A\n",
            "[69, 81, 36, 99]\n",
            "38562/39120 [============================>.] - ETA: 48s - loss: 1.28185273\n",
            "4MRS_1_A\n",
            "[36, 60, 66, 45]\n",
            "38563/39120 [============================>.] - ETA: 48s - loss: 1.28177471\n",
            "3NOH_1_A\n",
            "[1, 2, 6, 4]\n",
            "38564/39120 [============================>.] - ETA: 48s - loss: 1.281819734\n",
            "2P9T_1_A\n",
            "[34, 61, 26, 30]\n",
            "38565/39120 [============================>.] - ETA: 48s - loss: 1.28181309\n",
            "4K6R_d4k6ra1\n",
            "[75, 38, 3, 71]\n",
            "38566/39120 [============================>.] - ETA: 48s - loss: 1.281812038\n",
            "1SLM_d1slma1\n",
            "[97, 71, 16, 34]\n",
            "38567/39120 [============================>.] - ETA: 48s - loss: 1.281817419\n",
            "2Q0Z_d2q0zx2\n",
            "[76, 72, 7, 91]\n",
            "38568/39120 [============================>.] - ETA: 48s - loss: 1.281711217\n",
            "3AS8_1_A\n",
            "[52, 1, 98, 11]\n",
            "38569/39120 [============================>.] - ETA: 48s - loss: 1.281720483\n",
            "2BYK_2_B\n",
            "[17, 0, 19, 85]\n",
            "38570/39120 [============================>.] - ETA: 48s - loss: 1.281734941\n",
            "3B0K_1_A\n",
            "[87, 90, 74, 64]\n",
            "38571/39120 [============================>.] - ETA: 48s - loss: 1.28177671\n",
            "1V9S_1_A\n",
            "[37, 97, 72, 35]\n",
            "38572/39120 [============================>.] - ETA: 48s - loss: 1.281722392\n",
            "4IRN_1_A\n",
            "[89, 6, 21, 63]\n",
            "38573/39120 [============================>.] - ETA: 47s - loss: 1.28177039\n",
            "4I6N_1_A\n",
            "[97, 87, 13, 57]\n",
            "38574/39120 [============================>.] - ETA: 47s - loss: 1.281721263\n",
            "2Y69_6_F\n",
            "[14, 4, 69, 66]\n",
            "38575/39120 [============================>.] - ETA: 47s - loss: 1.281731740\n",
            "2LYY_1_A\n",
            "[49, 10, 78, 9]\n",
            "38576/39120 [============================>.] - ETA: 47s - loss: 1.281730156\n",
            "3W6S_1_A\n",
            "[10, 90, 79, 31]\n",
            "38577/39120 [============================>.] - ETA: 47s - loss: 1.281731305\n",
            "4YN0_1_A\n",
            "[95, 46, 25, 7]\n",
            "38578/39120 [============================>.] - ETA: 47s - loss: 1.281726342\n",
            "1KGE_1_A\n",
            "[90, 48, 72, 78]\n",
            "38579/39120 [============================>.] - ETA: 47s - loss: 1.28172514\n",
            "1D2L_1_A\n",
            "[63, 99, 21, 70]\n",
            "38580/39120 [============================>.] - ETA: 47s - loss: 1.281721027\n",
            "1PJ3_d1pj3d2\n",
            "[15, 1, 51, 22]\n",
            "38581/39120 [============================>.] - ETA: 47s - loss: 1.281720648\n",
            "1P4U_1_A\n",
            "[53, 98, 40, 59]\n",
            "38582/39120 [============================>.] - ETA: 47s - loss: 1.281824880\n",
            "4MUQ_1_A\n",
            "[46, 91, 7, 59]\n",
            "38583/39120 [============================>.] - ETA: 47s - loss: 1.281836006\n",
            "4O93_2_B\n",
            "[46, 82, 5, 6]\n",
            "38584/39120 [============================>.] - ETA: 46s - loss: 1.28186117\n",
            "4IRX_1_A\n",
            "[88, 29, 67, 80]\n",
            "38585/39120 [============================>.] - ETA: 46s - loss: 1.281836122\n",
            "5HB3_1_A\n",
            "[74, 95, 6, 39]\n",
            "38586/39120 [============================>.] - ETA: 46s - loss: 1.281728628\n",
            "1Q42_1_A\n",
            "[14, 53, 49, 89]\n",
            "38587/39120 [============================>.] - ETA: 46s - loss: 1.281718156\n",
            "3GXV_1_A\n",
            "[51, 99, 39, 91]\n",
            "38588/39120 [============================>.] - ETA: 46s - loss: 1.281734621\n",
            "2ENM_1_A\n",
            "[40, 54, 89, 19]\n",
            "38589/39120 [============================>.] - ETA: 46s - loss: 1.281724612\n",
            "1M3W_1_A\n",
            "[0]\n",
            "38590/39120 [============================>.] - ETA: 46s - loss: 1.2817822\n",
            "1Q8D_1_A\n",
            "[40, 59, 16, 56]\n",
            "38591/39120 [============================>.] - ETA: 46s - loss: 1.28172907\n",
            "4GEH_1_A\n",
            "[1, 3, 44, 82]\n",
            "38592/39120 [============================>.] - ETA: 46s - loss: 1.281731424\n",
            "2YSB_d2ysba2\n",
            "[8, 61, 55, 35]\n",
            "38593/39120 [============================>.] - ETA: 46s - loss: 1.281728563\n",
            "1C0P_d1c0pa2\n",
            "[33, 91, 48, 80]\n",
            "38594/39120 [============================>.] - ETA: 46s - loss: 1.28173461\n",
            "3FWX_1_A\n",
            "[0, 83, 94, 50]\n",
            "38595/39120 [============================>.] - ETA: 45s - loss: 1.281734887\n",
            "1Y7L_1_A\n",
            "[78, 54, 98, 8]\n",
            "38596/39120 [============================>.] - ETA: 45s - loss: 1.281725385\n",
            "3MW4_1_A\n",
            "[36, 17, 37, 20]\n",
            "38597/39120 [============================>.] - ETA: 45s - loss: 1.2817910\n",
            "1T3W_1_A\n",
            "[65, 63, 94, 0]\n",
            "38598/39120 [============================>.] - ETA: 45s - loss: 1.281728776\n",
            "3OUV_1_A\n",
            "[65, 77, 88, 37]\n",
            "38599/39120 [============================>.] - ETA: 45s - loss: 1.281723093\n",
            "3K5M_d3k5ma1\n",
            "[11, 53, 19, 85]\n",
            "38600/39120 [============================>.] - ETA: 45s - loss: 1.281729058\n",
            "3NVI_1_A\n",
            "[41, 88, 95, 39]\n",
            "38601/39120 [============================>.] - ETA: 45s - loss: 1.281715675\n",
            "1H4V_d1h4vb1\n",
            "[30, 35, 49, 70]\n",
            "38602/39120 [============================>.] - ETA: 45s - loss: 1.28177181\n",
            "3SQF_1_A\n",
            "[46, 90, 70, 84, 64]\n",
            "38603/39120 [============================>.] - ETA: 45s - loss: 1.281734042\n",
            "4HF7_1_A\n",
            "[89, 1, 10, 47]\n",
            "38604/39120 [============================>.] - ETA: 45s - loss: 1.281712682\n",
            "1OEF_1_A\n",
            "[18, 9, 4, 35]\n",
            "38605/39120 [============================>.] - ETA: 45s - loss: 1.281729068\n",
            "1HTN_1_A\n",
            "[15, 5, 43, 2]\n",
            "38606/39120 [============================>.] - ETA: 45s - loss: 1.281733566\n",
            "4BML_1_A\n",
            "[45, 15, 31, 37]\n",
            "38607/39120 [============================>.] - ETA: 44s - loss: 1.281736316\n",
            "2RMC_1_A\n",
            "[24, 44, 2, 53]\n",
            "38608/39120 [============================>.] - ETA: 44s - loss: 1.281725483\n",
            "2HZY_d2hzyb2\n",
            "[49, 71, 22, 67]\n",
            "38609/39120 [============================>.] - ETA: 44s - loss: 1.2817836\n",
            "2FMD_1_A\n",
            "[67, 58, 79, 30]\n",
            "38610/39120 [============================>.] - ETA: 44s - loss: 1.281724545\n",
            "3ZUV_2_B\n",
            "[6, 55, 58, 65]\n",
            "38611/39120 [============================>.] - ETA: 44s - loss: 1.281710971\n",
            "3ONO_1_A\n",
            "[33, 21, 54, 1]\n",
            "38612/39120 [============================>.] - ETA: 44s - loss: 1.28173003\n",
            "4U6F_50_M4\n",
            "[49, 9, 73, 29]\n",
            "38613/39120 [============================>.] - ETA: 44s - loss: 1.281726453\n",
            "3IEE_1_A\n",
            "[63, 35, 43, 24]\n",
            "38614/39120 [============================>.] - ETA: 44s - loss: 1.28172057\n",
            "2X27_1_X\n",
            "[63, 58, 33, 68]\n",
            "38615/39120 [============================>.] - ETA: 44s - loss: 1.281732568\n",
            "1K3I_d1k3ia3\n",
            "[15, 83, 81, 70]\n",
            "38616/39120 [============================>.] - ETA: 44s - loss: 1.281734860\n",
            "1QFH_1_A\n",
            "[59, 95, 99, 68]\n",
            "38617/39120 [============================>.] - ETA: 44s - loss: 1.28175524\n",
            "2BTO_d2btob2\n",
            "[70, 72, 87, 48]\n",
            "38618/39120 [============================>.] - ETA: 43s - loss: 1.2817289\n",
            "3CUE_2_B\n",
            "[85, 42, 17, 55]\n",
            "38619/39120 [============================>.] - ETA: 43s - loss: 1.281715252\n",
            "2ATR_1_A\n",
            "[34, 26, 81, 16]\n",
            "38620/39120 [============================>.] - ETA: 43s - loss: 1.281727433\n",
            "2QSK_1_A\n",
            "[27, 26, 12, 0]\n",
            "38621/39120 [============================>.] - ETA: 43s - loss: 1.28175566\n",
            "1WR8_1_A\n",
            "[82, 29, 98, 23]\n",
            "38622/39120 [============================>.] - ETA: 43s - loss: 1.28177531\n",
            "6PAX_d6paxa2\n",
            "[62, 69, 63, 73]\n",
            "38623/39120 [============================>.] - ETA: 43s - loss: 1.281735293\n",
            "2HO1_1_A\n",
            "[2, 40, 59, 4]\n",
            "38624/39120 [============================>.] - ETA: 43s - loss: 1.281721937\n",
            "3HOL_d3hola4\n",
            "[46, 52, 58, 26]\n",
            "38625/39120 [============================>.] - ETA: 43s - loss: 1.28178633\n",
            "3ZVS_1_A\n",
            "[8, 46, 32, 9]\n",
            "38626/39120 [============================>.] - ETA: 43s - loss: 1.28178241\n",
            "1L2U_1_A\n",
            "[81, 45, 67, 56]\n",
            "38627/39120 [============================>.] - ETA: 43s - loss: 1.28172317\n",
            "1XP4_d1xp4d1\n",
            "[20, 76, 0, 23]\n",
            "38628/39120 [============================>.] - ETA: 43s - loss: 1.28179451\n",
            "3C9X_1_A\n",
            "[51, 48, 66, 67]\n",
            "38629/39120 [============================>.] - ETA: 43s - loss: 1.281734487\n",
            "1KQP_1_A\n",
            "[37, 95, 34, 17]\n",
            "38630/39120 [============================>.] - ETA: 42s - loss: 1.281720121\n",
            "3DDR_1_A\n",
            "[79, 1, 13, 44]\n",
            "38631/39120 [============================>.] - ETA: 42s - loss: 1.281728550\n",
            "1IML_d1imla2\n",
            "[70, 23, 98, 28]\n",
            "38632/39120 [============================>.] - ETA: 42s - loss: 1.281721383\n",
            "2ATC_1_A\n",
            "[73, 20, 50, 47, 80]\n",
            "38633/39120 [============================>.] - ETA: 42s - loss: 1.28173889\n",
            "2GDL_1_A\n",
            "[0, 2, 3, 4]\n",
            "38634/39120 [============================>.] - ETA: 42s - loss: 1.2817478\n",
            "4DJK_1_A\n",
            "[64, 4, 77, 52]\n",
            "38635/39120 [============================>.] - ETA: 42s - loss: 1.28178402\n",
            "1WB9_d1wb9a3\n",
            "[52, 14, 73, 28]\n",
            "38636/39120 [============================>.] - ETA: 42s - loss: 1.281725316\n",
            "2JFN_1_A\n",
            "[65, 64, 91, 36]\n",
            "38637/39120 [============================>.] - ETA: 42s - loss: 1.281726624\n",
            "1G57_1_A\n",
            "[17, 32, 19, 22]\n",
            "38638/39120 [============================>.] - ETA: 42s - loss: 1.281716964\n",
            "1SH7_1_A\n",
            "[69, 60, 55, 83]\n",
            "38639/39120 [============================>.] - ETA: 42s - loss: 1.281737518\n",
            "3K7D_1_A\n",
            "[94, 52, 59, 37]\n",
            "38640/39120 [============================>.] - ETA: 42s - loss: 1.281732170\n",
            "3I0U_1_A\n",
            "[6, 9, 66, 67]\n",
            "38641/39120 [============================>.] - ETA: 41s - loss: 1.281734467\n",
            "3HRY_1_A\n",
            "[17, 86, 24, 94]\n",
            "38642/39120 [============================>.] - ETA: 41s - loss: 1.28172231\n",
            "1A81_d1a81i2\n",
            "[76, 93, 43, 53]\n",
            "38643/39120 [============================>.] - ETA: 41s - loss: 1.281737882\n",
            "2AJO_1_A\n",
            "[13, 35, 23, 32]\n",
            "38644/39120 [============================>.] - ETA: 41s - loss: 1.28175209\n",
            "2EC6_1_A\n",
            "[58, 35, 54, 51]\n",
            "38645/39120 [============================>.] - ETA: 41s - loss: 1.281727250\n",
            "2D8C_1_A\n",
            "[43, 76, 39, 94]\n",
            "38646/39120 [============================>.] - ETA: 41s - loss: 1.281733391\n",
            "3SJA_2_C\n",
            "[42, 53, 65, 5]\n",
            "38647/39120 [============================>.] - ETA: 41s - loss: 1.281719957\n",
            "1WB8_d1wb8b2\n",
            "[45, 47, 56, 12]\n",
            "38648/39120 [============================>.] - ETA: 41s - loss: 1.281735927\n",
            "1YLR_1_A\n",
            "[89, 16, 49, 92]\n",
            "38649/39120 [============================>.] - ETA: 41s - loss: 1.28174905\n",
            "2Z1A_d2z1aa2\n",
            "[58, 95, 30, 45]\n",
            "38650/39120 [============================>.] - ETA: 41s - loss: 1.281733671\n",
            "3MI9_3_C\n",
            "3MI9_3_C\n",
            "[82, 88, 8, 66, 12, 71]\n",
            "38651/39120 [============================>.] - ETA: 41s - loss: 1.281725604\n",
            "5BVS_1_A\n",
            "[68, 93, 71, 34]\n",
            "38652/39120 [============================>.] - ETA: 41s - loss: 1.28173086\n",
            "1FXW_2_F\n",
            "[12, 37, 98, 33]\n",
            "38653/39120 [============================>.] - ETA: 40s - loss: 1.281713620\n",
            "2YK0_1_A\n",
            "[5, 46, 53, 22]\n",
            "38654/39120 [============================>.] - ETA: 40s - loss: 1.281738040\n",
            "4EHS_1_A\n",
            "[28, 90, 63, 98]\n",
            "38655/39120 [============================>.] - ETA: 40s - loss: 1.281726618\n",
            "1SZH_1_A\n",
            "[31, 1, 21, 33]\n",
            "38656/39120 [============================>.] - ETA: 40s - loss: 1.281726949\n",
            "2YYJ_1_A\n",
            "[93, 56, 52, 60]\n",
            "38657/39120 [============================>.] - ETA: 40s - loss: 1.28175709\n",
            "2NTE_1_A\n",
            "[86, 95, 52, 15]\n",
            "38658/39120 [============================>.] - ETA: 40s - loss: 1.281718045\n",
            "1V1H_d1v1hf1\n",
            "[92, 90, 68, 70]\n",
            "38659/39120 [============================>.] - ETA: 40s - loss: 1.281725419\n",
            "5C5V_1_A\n",
            "[7, 86, 2, 84]\n",
            "38660/39120 [============================>.] - ETA: 40s - loss: 1.281733479\n",
            "2FKB_1_A\n",
            "[84, 91, 21, 38]\n",
            "38661/39120 [============================>.] - ETA: 40s - loss: 1.281736241\n",
            "2WTE_1_A\n",
            "[43, 49, 48, 30]\n",
            "38662/39120 [============================>.] - ETA: 40s - loss: 1.28178194\n",
            "3GGY_1_A\n",
            "[35, 80, 90, 11]\n",
            "38663/39120 [============================>.] - ETA: 40s - loss: 1.2817885\n",
            "4AUC_1_A\n",
            "[73, 5, 32, 3]\n",
            "38664/39120 [============================>.] - ETA: 39s - loss: 1.28174794\n",
            "3NKH_1_A\n",
            "[66, 92, 59, 12]\n",
            "38665/39120 [============================>.] - ETA: 39s - loss: 1.281731811\n",
            "4AUK_1_A\n",
            "[86, 56, 10, 70]\n",
            "38666/39120 [============================>.] - ETA: 39s - loss: 1.28173670\n",
            "1DBF_1_A\n",
            "[37, 22, 50, 65]\n",
            "38667/39120 [============================>.] - ETA: 39s - loss: 1.281710488\n",
            "3N5L_1_A\n",
            "[24, 63, 72, 39]\n",
            "38668/39120 [============================>.] - ETA: 39s - loss: 1.281732335\n",
            "3FAC_1_A\n",
            "[49, 61, 40, 4]\n",
            "38669/39120 [============================>.] - ETA: 39s - loss: 1.28175436\n",
            "2KDK_1_A\n",
            "[95, 15, 24, 3]\n",
            "38670/39120 [============================>.] - ETA: 39s - loss: 1.281729597\n",
            "3JBP_26_P\n",
            "[55, 83, 15, 39]\n",
            "38671/39120 [============================>.] - ETA: 39s - loss: 1.281735605\n",
            "4KP3_3_E\n",
            "[64, 29, 50, 53]\n",
            "38672/39120 [============================>.] - ETA: 39s - loss: 1.281711102\n",
            "1U1J_d1u1ja1\n",
            "[77, 9, 30, 90]\n",
            "38673/39120 [============================>.] - ETA: 39s - loss: 1.281825393\n",
            "4WED_1_A\n",
            "[47, 67, 84, 53]\n",
            "38674/39120 [============================>.] - ETA: 39s - loss: 1.281819108\n",
            "3GRF_d3grfa2\n",
            "[43, 46, 21, 32]\n",
            "38675/39120 [============================>.] - ETA: 38s - loss: 1.281834958\n",
            "2GJX_d2gjxh2\n",
            "[31, 7, 53, 80]\n",
            "38676/39120 [============================>.] - ETA: 38s - loss: 1.28183001\n",
            "2WW5_1_A\n",
            "[89, 67, 31, 73]\n",
            "38677/39120 [============================>.] - ETA: 38s - loss: 1.281830138\n",
            "2XST_1_A\n",
            "[78, 86, 88, 81]\n",
            "38678/39120 [============================>.] - ETA: 38s - loss: 1.281830801\n",
            "4MPO_1_A\n",
            "[66, 85, 86, 52]\n",
            "38679/39120 [============================>.] - ETA: 38s - loss: 1.28184287\n",
            "4RHS_1_A\n",
            "[24, 16, 4, 17]\n",
            "38680/39120 [============================>.] - ETA: 38s - loss: 1.281813696\n",
            "1PBY_d1pbya3\n",
            "[37, 32, 46, 99]\n",
            "38681/39120 [============================>.] - ETA: 38s - loss: 1.28186555\n",
            "2IGS_1_A\n",
            "[2, 0, 1, 3]\n",
            "38682/39120 [============================>.] - ETA: 38s - loss: 1.281731394\n",
            "2QE7_2_D\n",
            "[37, 25, 82, 52]\n",
            "38683/39120 [============================>.] - ETA: 38s - loss: 1.28187562\n",
            "1NOZ_1_A\n",
            "[47, 83, 96, 53]\n",
            "38684/39120 [============================>.] - ETA: 38s - loss: 1.28179422\n",
            "1NYC_1_A\n",
            "[4, 2, 7, 6]\n",
            "38685/39120 [============================>.] - ETA: 38s - loss: 1.281819602\n",
            "2DFK_1_A\n",
            "[86, 62, 80, 47]\n",
            "38686/39120 [============================>.] - ETA: 38s - loss: 1.281721574\n",
            "2DM1_1_A\n",
            "[65, 1, 3, 28]\n",
            "38687/39120 [============================>.] - ETA: 37s - loss: 1.281737933\n",
            "2K5H_1_A\n",
            "[56, 40, 85, 77]\n",
            "38688/39120 [============================>.] - ETA: 37s - loss: 1.28177730\n",
            "3FUY_1_A\n",
            "[24, 0, 7, 14]\n",
            "38689/39120 [============================>.] - ETA: 37s - loss: 1.281738699\n",
            "1OC7_1_A\n",
            "[31, 73, 19, 12]\n",
            "38690/39120 [============================>.] - ETA: 37s - loss: 1.281736843\n",
            "1TUH_1_A\n",
            "[82, 16, 75, 83]\n",
            "38691/39120 [============================>.] - ETA: 37s - loss: 1.281725591\n",
            "2EHJ_1_A\n",
            "[61, 89, 41, 47]\n",
            "38692/39120 [============================>.] - ETA: 37s - loss: 1.28174090\n",
            "4ZJ9_1_A\n",
            "[71, 82, 78, 17]\n",
            "38693/39120 [============================>.] - ETA: 37s - loss: 1.281731099\n",
            "3CL3_1_A\n",
            "[86, 90, 64, 69]\n",
            "38694/39120 [============================>.] - ETA: 37s - loss: 1.281729485\n",
            "5I5M_d5i5mb2\n",
            "[66, 73, 38, 97]\n",
            "38695/39120 [============================>.] - ETA: 37s - loss: 1.28179549\n",
            "4L4E_1_A\n",
            "[73, 22, 63, 74]\n",
            "38696/39120 [============================>.] - ETA: 37s - loss: 1.281711443\n",
            "3C7J_1_A\n",
            "[55, 9, 89, 5]\n",
            "38697/39120 [============================>.] - ETA: 37s - loss: 1.28172558\n",
            "4WHX_1_A\n",
            "[83, 4, 25, 91]\n",
            "38698/39120 [============================>.] - ETA: 36s - loss: 1.281728291\n",
            "2DCN_1_A\n",
            "[77, 57, 2, 66]\n",
            "38699/39120 [============================>.] - ETA: 36s - loss: 1.281717363\n",
            "1XEU_1_A\n",
            "[38, 23, 26, 60]\n",
            "38700/39120 [============================>.] - ETA: 36s - loss: 1.281727531\n",
            "1KCX_1_A\n",
            "[44, 28, 10, 67]\n",
            "38701/39120 [============================>.] - ETA: 36s - loss: 1.281814239\n",
            "4QIC_2_B\n",
            "[23, 10, 46, 22]\n",
            "38702/39120 [============================>.] - ETA: 36s - loss: 1.28189917\n",
            "1WP9_1_A\n",
            "[9, 8, 49, 96]\n",
            "38703/39120 [============================>.] - ETA: 36s - loss: 1.28173212\n",
            "4ZBY_1_A\n",
            "[56, 0, 98, 24]\n",
            "38704/39120 [============================>.] - ETA: 36s - loss: 1.281713958\n",
            "4YYF_1_A\n",
            "[80, 68, 89, 27]\n",
            "38705/39120 [============================>.] - ETA: 36s - loss: 1.281834753\n",
            "1IXB_1_A\n",
            "[45, 39, 27, 15]\n",
            "38706/39120 [============================>.] - ETA: 36s - loss: 1.28186299\n",
            "2EIF_d2eifa2\n",
            "[84, 10, 70, 51]\n",
            "38707/39120 [============================>.] - ETA: 36s - loss: 1.281821973\n",
            "5A4P_1_A\n",
            "[81, 50, 34, 39, 26]\n",
            "38708/39120 [============================>.] - ETA: 36s - loss: 1.281812018\n",
            "1KQF_1_A\n",
            "[80, 1, 52, 35]\n",
            "38709/39120 [============================>.] - ETA: 36s - loss: 1.28184202\n",
            "2FY3_d2fy3a1\n",
            "[92, 9, 6, 64]\n",
            "38710/39120 [============================>.] - ETA: 35s - loss: 1.281811099\n",
            "2RN7_1_A\n",
            "[5, 83, 67, 2]\n",
            "38711/39120 [============================>.] - ETA: 35s - loss: 1.281817898\n",
            "4ISQ_2_D\n",
            "[13, 8, 0, 6]\n",
            "38712/39120 [============================>.] - ETA: 35s - loss: 1.281713573\n",
            "2FHW_2_A\n",
            "[34, 0, 37, 6]\n",
            "38713/39120 [============================>.] - ETA: 35s - loss: 1.28171211\n",
            "2G9L_1_A\n",
            "[19, 61, 17, 47]\n",
            "38714/39120 [============================>.] - ETA: 35s - loss: 1.28174106\n",
            "4ICI_1_A\n",
            "[72, 2, 80, 64]\n",
            "38715/39120 [============================>.] - ETA: 35s - loss: 1.28174194\n",
            "2O95_1_A\n",
            "[85, 14, 86, 97]\n",
            "38716/39120 [============================>.] - ETA: 35s - loss: 1.281724682\n",
            "3JBP_22_H\n",
            "[52, 78, 53, 24]\n",
            "38717/39120 [============================>.] - ETA: 35s - loss: 1.281734463\n",
            "1QHD_1_A\n",
            "[4, 3, 0, 13]\n",
            "38718/39120 [============================>.] - ETA: 35s - loss: 1.28177931\n",
            "4O1N_d4o1nf1\n",
            "[7, 49, 64, 27]\n",
            "38719/39120 [============================>.] - ETA: 35s - loss: 1.28179617\n",
            "2VQC_1_A\n",
            "[5, 0, 4, 2]\n",
            "38720/39120 [============================>.] - ETA: 35s - loss: 1.281734670\n",
            "2N02_1_A\n",
            "[10, 57, 56, 48]\n",
            "38721/39120 [============================>.] - ETA: 34s - loss: 1.281726303\n",
            "1KD8_2_B\n",
            "[0]\n",
            "38722/39120 [============================>.] - ETA: 34s - loss: 1.281711945\n",
            "3E7D_1_A\n",
            "[0, 6, 87, 4]\n",
            "38723/39120 [============================>.] - ETA: 34s - loss: 1.281730915\n",
            "4XB3_1_A\n",
            "[44, 78, 47, 28]\n",
            "38724/39120 [============================>.] - ETA: 34s - loss: 1.281735788\n",
            "2LNH_3_C\n",
            "[9, 14, 10, 1]\n",
            "38725/39120 [============================>.] - ETA: 34s - loss: 1.28179793\n",
            "2MOX_1_A\n",
            "[0, 36, 1, 88]\n",
            "38726/39120 [============================>.] - ETA: 34s - loss: 1.28171373\n",
            "3K8Z_d3k8zf1\n",
            "[36, 76, 97, 9]\n",
            "38727/39120 [============================>.] - ETA: 34s - loss: 1.281718322\n",
            "2YHE_1_A\n",
            "[47, 20, 88, 26]\n",
            "38728/39120 [============================>.] - ETA: 34s - loss: 1.281714063\n",
            "3JVO_1_A\n",
            "[46, 40, 3, 32]\n",
            "38729/39120 [============================>.] - ETA: 34s - loss: 1.28176104\n",
            "4B6H_2_C\n",
            "[17, 16, 52, 51]\n",
            "38730/39120 [============================>.] - ETA: 34s - loss: 1.281722739\n",
            "2QRT_1_A\n",
            "[71, 1, 20, 57]\n",
            "38731/39120 [============================>.] - ETA: 34s - loss: 1.281716840\n",
            "4TR6_1_A\n",
            "[61, 27, 73, 22]\n",
            "38732/39120 [============================>.] - ETA: 33s - loss: 1.281736819\n",
            "4TZQ_1_A\n",
            "[80, 55, 42, 5, 48]\n",
            "38733/39120 [============================>.] - ETA: 33s - loss: 1.28175909\n",
            "4F2N_d4f2nl2\n",
            "[17, 49, 36, 62]\n",
            "38734/39120 [============================>.] - ETA: 33s - loss: 1.28174225\n",
            "3JCR_1_G\n",
            "[23, 35, 98, 97]\n",
            "38735/39120 [============================>.] - ETA: 33s - loss: 1.281729048\n",
            "2GJV_d2gjvf2\n",
            "[28, 96, 12, 22]\n",
            "38736/39120 [============================>.] - ETA: 33s - loss: 1.281827974\n",
            "4IUS_1_A\n",
            "[92, 30, 79, 19]\n",
            "38737/39120 [============================>.] - ETA: 33s - loss: 1.281811499\n",
            "4HFI_1_A\n",
            "[40, 98, 38, 43]\n",
            "38738/39120 [============================>.] - ETA: 33s - loss: 1.281823036\n",
            "2J9A_1_A\n",
            "[26, 33, 32, 94]\n",
            "38739/39120 [============================>.] - ETA: 33s - loss: 1.281818112\n",
            "1DE4_d1de4g1\n",
            "[47, 65, 54, 35]\n",
            "38740/39120 [============================>.] - ETA: 33s - loss: 1.281833824\n",
            "1Q9J_1_A\n",
            "[88, 5, 73, 95]\n",
            "38741/39120 [============================>.] - ETA: 33s - loss: 1.28187524\n",
            "4LGC_1_A\n",
            "[59, 31, 86, 58]\n",
            "38742/39120 [============================>.] - ETA: 33s - loss: 1.281821719\n",
            "1NTY_d1ntya1\n",
            "[4, 77, 62, 90]\n",
            "38743/39120 [============================>.] - ETA: 33s - loss: 1.281814603\n",
            "3L5O_1_A\n",
            "[60, 13, 39, 45]\n",
            "38744/39120 [============================>.] - ETA: 32s - loss: 1.281828543\n",
            "1JD1_1_A\n",
            "[26, 78, 23, 77]\n",
            "38745/39120 [============================>.] - ETA: 32s - loss: 1.281822391\n",
            "4OMH_1_A\n",
            "[96, 8, 95, 92]\n",
            "38746/39120 [============================>.] - ETA: 32s - loss: 1.281821771\n",
            "4JQ6_1_A\n",
            "[36, 56, 62, 85]\n",
            "38747/39120 [============================>.] - ETA: 32s - loss: 1.28187189\n",
            "1DD3_1_A\n",
            "[29, 13, 61, 47]\n",
            "38748/39120 [============================>.] - ETA: 32s - loss: 1.281820192\n",
            "2CX1_d2cx1a2\n",
            "[34, 24, 79, 70]\n",
            "38749/39120 [============================>.] - ETA: 32s - loss: 1.281812161\n",
            "2G2S_1_A\n",
            "[18, 52, 63, 13]\n",
            "38750/39120 [============================>.] - ETA: 32s - loss: 1.281834313\n",
            "2BDQ_1_A\n",
            "[39, 63, 30, 47]\n",
            "38751/39120 [============================>.] - ETA: 32s - loss: 1.281837938\n",
            "4K1X_d4k1xb1\n",
            "[20, 49, 93, 51]\n",
            "38752/39120 [============================>.] - ETA: 32s - loss: 1.281826675\n",
            "5G0R_d5g0rd1\n",
            "[2, 17, 38, 54]\n",
            "38753/39120 [============================>.] - ETA: 32s - loss: 1.281829779\n",
            "4E6N_2_B\n",
            "[70, 14, 30, 74]\n",
            "38754/39120 [============================>.] - ETA: 32s - loss: 1.28181540\n",
            "4RWE_1_A\n",
            "[38, 40, 8, 98]\n",
            "38755/39120 [============================>.] - ETA: 31s - loss: 1.281821485\n",
            "3FHT_d3fhtb1\n",
            "[4, 28, 67, 58]\n",
            "38756/39120 [============================>.] - ETA: 31s - loss: 1.281832982\n",
            "1ULV_d1ulva1\n",
            "[28, 16, 59, 44]\n",
            "38757/39120 [============================>.] - ETA: 31s - loss: 1.28184541\n",
            "2LX9_1_A\n",
            "[60, 72, 57, 7]\n",
            "38758/39120 [============================>.] - ETA: 31s - loss: 1.281818700\n",
            "3BMX_1_A\n",
            "[27, 85, 23, 77]\n",
            "38759/39120 [============================>.] - ETA: 31s - loss: 1.28187698\n",
            "1BSM_d1bsmb2\n",
            "[64, 32, 57, 25]\n",
            "38760/39120 [============================>.] - ETA: 31s - loss: 1.281826815\n",
            "1WM7_1_A\n",
            "[11, 9, 0, 3]\n",
            "38761/39120 [============================>.] - ETA: 31s - loss: 1.281834029\n",
            "2UUC_d2uucc1\n",
            "[56, 37, 88, 58]\n",
            "38762/39120 [============================>.] - ETA: 31s - loss: 1.28183923\n",
            "3NJ2_1_A\n",
            "[78, 27, 14, 79]\n",
            "38763/39120 [============================>.] - ETA: 31s - loss: 1.281822155\n",
            "2LEV_1_A\n",
            "[2, 23, 61, 6]\n",
            "38764/39120 [============================>.] - ETA: 31s - loss: 1.281810557\n",
            "1G91_1_A\n",
            "[60, 47, 36, 32]\n",
            "38765/39120 [============================>.] - ETA: 31s - loss: 1.281810219\n",
            "3OP1_d3op1b2\n",
            "[62, 30, 61, 57]\n",
            "38766/39120 [============================>.] - ETA: 31s - loss: 1.281822577\n",
            "3WBH_1_A\n",
            "[3, 75, 97, 41, 45]\n",
            "38767/39120 [============================>.] - ETA: 30s - loss: 1.281817138\n",
            "2UWM_d2uwmb2\n",
            "[89, 35, 58, 49]\n",
            "38768/39120 [============================>.] - ETA: 30s - loss: 1.28188493\n",
            "3VSK_1_A\n",
            "[86, 24, 4, 91]\n",
            "38769/39120 [============================>.] - ETA: 30s - loss: 1.281828702\n",
            "1T84_1_A\n",
            "[61, 58, 74, 54]\n",
            "38770/39120 [============================>.] - ETA: 30s - loss: 1.281833403\n",
            "1SKN_3_P\n",
            "[38, 27, 2, 65]\n",
            "38771/39120 [============================>.] - ETA: 30s - loss: 1.281829141\n",
            "3QAX_1_A\n",
            "[82, 50, 66, 57]\n",
            "38772/39120 [============================>.] - ETA: 30s - loss: 1.28188077\n",
            "3M48_1_A\n",
            "[46, 63, 44, 57]\n",
            "38773/39120 [============================>.] - ETA: 30s - loss: 1.281820849\n",
            "4TX3_2_B\n",
            "[92, 84, 50, 73]\n",
            "38774/39120 [============================>.] - ETA: 30s - loss: 1.281827061\n",
            "1PP0_1_A\n",
            "[74, 84, 75, 43]\n",
            "38775/39120 [============================>.] - ETA: 30s - loss: 1.28183575\n",
            "3CEW_1_A\n",
            "[90, 25, 48, 59]\n",
            "38776/39120 [============================>.] - ETA: 30s - loss: 1.281815415\n",
            "2Q66_d2q66a1\n",
            "[99, 90, 31, 69]\n",
            "38777/39120 [============================>.] - ETA: 30s - loss: 1.28185099\n",
            "4R52_1_A\n",
            "[22, 58, 13, 82]\n",
            "38778/39120 [============================>.] - ETA: 29s - loss: 1.281837800\n",
            "4Y7I_1_A\n",
            "[43, 20, 38, 21]\n",
            "38779/39120 [============================>.] - ETA: 29s - loss: 1.281817302\n",
            "4AG1_2_C\n",
            "[19, 32, 38, 94]\n",
            "38780/39120 [============================>.] - ETA: 29s - loss: 1.281837039\n",
            "3IFN_3_P\n",
            "[29, 1, 14, 8, 0]\n",
            "38781/39120 [============================>.] - ETA: 29s - loss: 1.28189212\n",
            "4NFW_1_A\n",
            "[29, 87, 37, 40]\n",
            "38782/39120 [============================>.] - ETA: 29s - loss: 1.281833017\n",
            "3LED_1_A\n",
            "[24, 0, 50, 22]\n",
            "38783/39120 [============================>.] - ETA: 29s - loss: 1.281818863\n",
            "4Q6J_1_A\n",
            "[14, 99, 62, 37]\n",
            "38784/39120 [============================>.] - ETA: 29s - loss: 1.28181377\n",
            "4V4W_48_BZ\n",
            "[71, 23, 97, 36]\n",
            "38785/39120 [============================>.] - ETA: 29s - loss: 1.281827906\n",
            "2W57_d2w57b-\n",
            "[91, 95, 65, 2]\n",
            "38786/39120 [============================>.] - ETA: 29s - loss: 1.281834738\n",
            "4V4E_d1vlfx2\n",
            "[71, 75, 47, 54]\n",
            "38787/39120 [============================>.] - ETA: 29s - loss: 1.281817676\n",
            "1U0I_2_B\n",
            "[0]\n",
            "38788/39120 [============================>.] - ETA: 29s - loss: 1.281821045\n",
            "2APN_1_A\n",
            "[37, 48, 53, 38]\n",
            "38789/39120 [============================>.] - ETA: 28s - loss: 1.28184637\n",
            "4HR3_d4hr3a1\n",
            "[44, 16, 97, 60]\n",
            "38790/39120 [============================>.] - ETA: 28s - loss: 1.28185100\n",
            "1R71_d1r71b-\n",
            "[36, 90, 31, 86]\n",
            "38791/39120 [============================>.] - ETA: 28s - loss: 1.281826806\n",
            "2IBF_2_B\n",
            "[0]\n",
            "38792/39120 [============================>.] - ETA: 28s - loss: 1.281825352\n",
            "1HCN_1_A\n",
            "[17, 52, 40, 13]\n",
            "38793/39120 [============================>.] - ETA: 28s - loss: 1.281839016\n",
            "3U5O_2_I\n",
            "[26, 32, 75, 57]\n",
            "38794/39120 [============================>.] - ETA: 28s - loss: 1.281836148\n",
            "1R4K_1_A\n",
            "[10, 96, 4, 80]\n",
            "38795/39120 [============================>.] - ETA: 28s - loss: 1.281831513\n",
            "4X0R_1_B\n",
            "[57, 97, 39, 96]\n",
            "38796/39120 [============================>.] - ETA: 28s - loss: 1.281827602\n",
            "1BVU_1_A\n",
            "[54, 17, 16, 68]\n",
            "38797/39120 [============================>.] - ETA: 28s - loss: 1.28182808\n",
            "4W9U_1_A\n",
            "[79, 93, 69, 40]\n",
            "38798/39120 [============================>.] - ETA: 28s - loss: 1.281817523\n",
            "2OZ6_d2oz6a1\n",
            "[70, 56, 74, 40]\n",
            "38799/39120 [============================>.] - ETA: 28s - loss: 1.28184648\n",
            "4AIE_1_A\n",
            "[51, 94, 35, 75]\n",
            "38800/39120 [============================>.] - ETA: 28s - loss: 1.281812480\n",
            "1V9L_d1v9lf2\n",
            "[74, 92, 44, 68]\n",
            "38801/39120 [============================>.] - ETA: 27s - loss: 1.281812316\n",
            "4GS5_1_A\n",
            "[46, 57, 79, 7]\n",
            "38802/39120 [============================>.] - ETA: 27s - loss: 1.281820641\n",
            "2DSY_1_A\n",
            "[61, 39, 4, 17]\n",
            "38803/39120 [============================>.] - ETA: 27s - loss: 1.281834256\n",
            "3CA7_1_A\n",
            "[58, 77, 24, 63]\n",
            "38804/39120 [============================>.] - ETA: 27s - loss: 1.281816721\n",
            "2YMO_1_A\n",
            "[87, 63, 99, 62]\n",
            "38805/39120 [============================>.] - ETA: 27s - loss: 1.28186472\n",
            "2YPV_1_A\n",
            "[31, 94, 85, 37]\n",
            "38806/39120 [============================>.] - ETA: 27s - loss: 1.281834206\n",
            "3IWZ_1_A\n",
            "[22, 80, 50, 61]\n",
            "38807/39120 [============================>.] - ETA: 27s - loss: 1.281810228\n",
            "4V8M_19_AK\n",
            "[39, 8, 85, 60]\n",
            "38808/39120 [============================>.] - ETA: 27s - loss: 1.28189410\n",
            "3P8B_2_B\n",
            "[5, 31, 21, 98]\n",
            "38809/39120 [============================>.] - ETA: 27s - loss: 1.281818593\n",
            "3NJE_d3njea-\n",
            "[8, 30, 50, 79]\n",
            "38810/39120 [============================>.] - ETA: 27s - loss: 1.281823929\n",
            "1PC0_1_A\n",
            "[97, 19, 63, 33]\n",
            "38811/39120 [============================>.] - ETA: 27s - loss: 1.281834240\n",
            "1CNZ_1_A\n",
            "[93, 96, 42, 1]\n",
            "38812/39120 [============================>.] - ETA: 26s - loss: 1.2818569\n",
            "4O47_1_A\n",
            "[86, 89, 80, 28]\n",
            "38813/39120 [============================>.] - ETA: 26s - loss: 1.281828901\n",
            "2DUM_1_A\n",
            "[88, 40, 32, 25]\n",
            "38814/39120 [============================>.] - ETA: 26s - loss: 1.281826613\n",
            "1G0D_d1g0da3\n",
            "[82, 12, 38, 59]\n",
            "38815/39120 [============================>.] - ETA: 26s - loss: 1.281828897\n",
            "1NC5_1_A\n",
            "[25, 76, 54, 88]\n",
            "38816/39120 [============================>.] - ETA: 26s - loss: 1.281831353\n",
            "2Z00_1_A\n",
            "[40, 24, 59, 49]\n",
            "38817/39120 [============================>.] - ETA: 26s - loss: 1.281817795\n",
            "3CJH_1_A\n",
            "[84, 17, 88, 34]\n",
            "38818/39120 [============================>.] - ETA: 26s - loss: 1.28184423\n",
            "4JE3_2_B\n",
            "[42, 30, 78, 3]\n",
            "38819/39120 [============================>.] - ETA: 26s - loss: 1.281815432\n",
            "2AH2_d2ah2a1\n",
            "[48, 90, 58, 9]\n",
            "38820/39120 [============================>.] - ETA: 26s - loss: 1.281834109\n",
            "2QSA_1_A\n",
            "[86, 65, 69, 11]\n",
            "38821/39120 [============================>.] - ETA: 26s - loss: 1.281819910\n",
            "5ACS_1_A\n",
            "[66, 94, 81, 61]\n",
            "38822/39120 [============================>.] - ETA: 26s - loss: 1.28182836\n",
            "4A5X_1_A\n",
            "[75, 62, 33, 53]\n",
            "38823/39120 [============================>.] - ETA: 26s - loss: 1.281810519\n",
            "4HOM_1_A\n",
            "[25, 86, 12, 32]\n",
            "38824/39120 [============================>.] - ETA: 25s - loss: 1.281834458\n",
            "3VQI_1_A\n",
            "[49, 28, 66, 99]\n",
            "38825/39120 [============================>.] - ETA: 25s - loss: 1.281810037\n",
            "1WWU_1_A\n",
            "[82, 80, 77, 54]\n",
            "38826/39120 [============================>.] - ETA: 25s - loss: 1.28185167\n",
            "4MAI_1_A\n",
            "[94, 69, 1, 11]\n",
            "38827/39120 [============================>.] - ETA: 25s - loss: 1.281838872\n",
            "2M2Q_1_A\n",
            "[1, 2, 0, 4]\n",
            "38828/39120 [============================>.] - ETA: 25s - loss: 1.281817508\n",
            "2RP5_1_A\n",
            "[1, 4, 2, 0]\n",
            "38829/39120 [============================>.] - ETA: 25s - loss: 1.2818136\n",
            "4UER_16_F\n",
            "[62, 59, 81, 22]\n",
            "38830/39120 [============================>.] - ETA: 25s - loss: 1.2818120\n",
            "1QSD_1_A\n",
            "[40, 44, 6, 25]\n",
            "38831/39120 [============================>.] - ETA: 25s - loss: 1.281824959\n",
            "5ANR_3_C\n",
            "[20, 26, 33, 50]\n",
            "38832/39120 [============================>.] - ETA: 25s - loss: 1.281829890\n",
            "1TJO_1_A\n",
            "[36, 88, 0, 65]\n",
            "38833/39120 [============================>.] - ETA: 25s - loss: 1.281810923\n",
            "3EMX_1_A\n",
            "[95, 98, 64, 68]\n",
            "38834/39120 [============================>.] - ETA: 25s - loss: 1.281824459\n",
            "2HFE_3_C\n",
            "[4, 80, 42, 37]\n",
            "38835/39120 [============================>.] - ETA: 24s - loss: 1.281729786\n",
            "3OA1_1_A\n",
            "[19, 18, 33, 25]\n",
            "38836/39120 [============================>.] - ETA: 24s - loss: 1.281721233\n",
            "2HEW_1_F\n",
            "[41, 33, 43, 40]\n",
            "38837/39120 [============================>.] - ETA: 24s - loss: 1.2817430\n",
            "4QL6_1_A\n",
            "[56, 10, 61, 16, 95, 5, 66, 88]\n",
            "38838/39120 [============================>.] - ETA: 24s - loss: 1.281711684\n",
            "4TKT_1_A\n",
            "[63, 69, 45, 90]\n",
            "38839/39120 [============================>.] - ETA: 24s - loss: 1.281713428\n",
            "1PKU_1_A\n",
            "[32, 89, 17, 90]\n",
            "38840/39120 [============================>.] - ETA: 24s - loss: 1.281738008\n",
            "3E5T_1_A\n",
            "[0, 59, 57, 26]\n",
            "38841/39120 [============================>.] - ETA: 24s - loss: 1.281721799\n",
            "2DJ4_1_A\n",
            "[38, 1, 80, 51]\n",
            "38842/39120 [============================>.] - ETA: 24s - loss: 1.2817700\n",
            "4YDH_1_A\n",
            "[32, 31, 4, 73]\n",
            "38843/39120 [============================>.] - ETA: 24s - loss: 1.28174313\n",
            "2B67_1_A\n",
            "[79, 55, 67, 40]\n",
            "38844/39120 [============================>.] - ETA: 24s - loss: 1.281717255\n",
            "2ZKZ_1_A\n",
            "[70, 82, 27, 35]\n",
            "38845/39120 [============================>.] - ETA: 24s - loss: 1.281729761\n",
            "1NHI_1_A\n",
            "[18, 65, 25, 51]\n",
            "38846/39120 [============================>.] - ETA: 23s - loss: 1.281724606\n",
            "1VPP_2_X\n",
            "[0]\n",
            "38847/39120 [============================>.] - ETA: 23s - loss: 1.281727203\n",
            "5AQ9_1_A\n",
            "[47, 11, 94, 69]\n",
            "38848/39120 [============================>.] - ETA: 23s - loss: 1.281732826\n",
            "3HBW_d3hbwb-\n",
            "[66, 19, 91, 88]\n",
            "38849/39120 [============================>.] - ETA: 23s - loss: 1.281715037\n",
            "3ZUD_1_A\n",
            "[10, 77, 73, 69]\n",
            "38850/39120 [============================>.] - ETA: 23s - loss: 1.281715471\n",
            "3ZIB_1_A\n",
            "[83, 93, 96, 78]\n",
            "38851/39120 [============================>.] - ETA: 23s - loss: 1.28182951\n",
            "4HBD_1_A\n",
            "[18, 92, 91, 1]\n",
            "38852/39120 [============================>.] - ETA: 23s - loss: 1.281724291\n",
            "1B3Q_d1b3qb1\n",
            "[43, 76, 51, 45]\n",
            "38853/39120 [============================>.] - ETA: 23s - loss: 1.281827728\n",
            "1B9L_1_A\n",
            "[82, 75, 71, 64]\n",
            "38854/39120 [============================>.] - ETA: 23s - loss: 1.281723052\n",
            "2EWH_1_A\n",
            "[90, 33, 14, 86]\n",
            "38855/39120 [============================>.] - ETA: 23s - loss: 1.281714418\n",
            "3VM7_d3vm7a1\n",
            "[23, 40, 77, 80]\n",
            "38856/39120 [============================>.] - ETA: 23s - loss: 1.28174156\n",
            "4V3P_52_Lb\n",
            "[41, 27, 87, 50]\n",
            "38857/39120 [============================>.] - ETA: 23s - loss: 1.281727578\n",
            "1GV3_d1gv3b2\n",
            "[94, 93, 73, 53]\n",
            "38858/39120 [============================>.] - ETA: 22s - loss: 1.281723712\n",
            "2HCF_1_A\n",
            "[20, 50, 68, 86]\n",
            "38859/39120 [============================>.] - ETA: 22s - loss: 1.281718284\n",
            "3KR3_1_D\n",
            "[86, 56, 7, 99, 90]\n",
            "38860/39120 [============================>.] - ETA: 22s - loss: 1.281725110\n",
            "2OCH_1_A\n",
            "[20, 58, 23, 28]\n",
            "38861/39120 [============================>.] - ETA: 22s - loss: 1.281732303\n",
            "2DDB_d2ddbd2\n",
            "[26, 46, 83, 51]\n",
            "38862/39120 [============================>.] - ETA: 22s - loss: 1.281727566\n",
            "4S21_1_A\n",
            "[16, 30, 48, 33]\n",
            "38863/39120 [============================>.] - ETA: 22s - loss: 1.28174835\n",
            "1T3D_1_A\n",
            "[69, 63, 14, 97]\n",
            "38864/39120 [============================>.] - ETA: 22s - loss: 1.28179695\n",
            "1E5X_1_A\n",
            "[83, 15, 67, 92]\n",
            "38865/39120 [============================>.] - ETA: 22s - loss: 1.281713716\n",
            "4KLK_1_A\n",
            "[35, 13, 16, 87]\n",
            "38866/39120 [============================>.] - ETA: 22s - loss: 1.281711727\n",
            "1KUG_1_A\n",
            "[59, 13, 64, 50]\n",
            "38867/39120 [============================>.] - ETA: 22s - loss: 1.281718595\n",
            "3TRE_d3trea1\n",
            "[11, 51, 2, 99]\n",
            "38868/39120 [============================>.] - ETA: 22s - loss: 1.281726029\n",
            "3D7R_1_A\n",
            "[35, 86, 56, 14]\n",
            "38869/39120 [============================>.] - ETA: 21s - loss: 1.281727915\n",
            "2EDP_1_A\n",
            "[2, 75, 82, 95]\n",
            "38870/39120 [============================>.] - ETA: 21s - loss: 1.281738775\n",
            "4V7E_4_BY\n",
            "[75, 24, 29, 23]\n",
            "38871/39120 [============================>.] - ETA: 21s - loss: 1.281722858\n",
            "2CCL_2_B\n",
            "[90, 88, 80, 31]\n",
            "38872/39120 [============================>.] - ETA: 21s - loss: 1.281735183\n",
            "4P4H_1_A\n",
            "[88, 72, 48, 31]\n",
            "38873/39120 [============================>.] - ETA: 21s - loss: 1.281736837\n",
            "2XHG_1_A\n",
            "[20, 18, 91, 43]\n",
            "38874/39120 [============================>.] - ETA: 21s - loss: 1.281717398\n",
            "4U6F_21_C9\n",
            "[56, 73, 70, 41]\n",
            "38875/39120 [============================>.] - ETA: 21s - loss: 1.281719906\n",
            "4J39_1_A\n",
            "[6, 0, 5, 4]\n",
            "38876/39120 [============================>.] - ETA: 21s - loss: 1.281713500\n",
            "1W26_d1w26b3\n",
            "[7, 61, 96, 18]\n",
            "38877/39120 [============================>.] - ETA: 21s - loss: 1.2817915\n",
            "2P5Z_d2p5zx3\n",
            "[40, 93, 75, 18]\n",
            "38878/39120 [============================>.] - ETA: 21s - loss: 1.281712309\n",
            "2XOD_1_A\n",
            "[50, 72, 77, 75]\n",
            "38879/39120 [============================>.] - ETA: 21s - loss: 1.281722005\n",
            "4TX1_1_A\n",
            "[49, 75, 86, 79]\n",
            "38880/39120 [============================>.] - ETA: 21s - loss: 1.281813930\n",
            "2ZPY_d2zpya1\n",
            "[33, 74, 38, 11]\n",
            "38881/39120 [============================>.] - ETA: 20s - loss: 1.28182409\n",
            "2XDY_1_A\n",
            "[23, 29, 66, 25]\n",
            "38882/39120 [============================>.] - ETA: 20s - loss: 1.281710587\n",
            "1ZME_3_C\n",
            "[34, 33, 23, 26]\n",
            "38883/39120 [============================>.] - ETA: 20s - loss: 1.281718568\n",
            "4BF5_1_A\n",
            "[71, 49, 78, 16]\n",
            "38884/39120 [============================>.] - ETA: 20s - loss: 1.281712684\n",
            "1KZF_1_A\n",
            "[30, 40, 88, 85]\n",
            "38885/39120 [============================>.] - ETA: 20s - loss: 1.281717295\n",
            "1G6P_1_A\n",
            "[72, 99, 82, 93]\n",
            "38886/39120 [============================>.] - ETA: 20s - loss: 1.28188111\n",
            "4BOP_1_A\n",
            "[17, 34, 79, 12]\n",
            "38887/39120 [============================>.] - ETA: 20s - loss: 1.281825519\n",
            "2MZ8_1_A\n",
            "[63, 3, 24, 42]\n",
            "38888/39120 [============================>.] - ETA: 20s - loss: 1.281819340\n",
            "1UL4_1_A\n",
            "[9, 74, 76, 14]\n",
            "38889/39120 [============================>.] - ETA: 20s - loss: 1.281814078\n",
            "2FNE_1_A\n",
            "[30, 29, 87, 68]\n",
            "38890/39120 [============================>.] - ETA: 20s - loss: 1.281819172\n",
            "4JZ5_1_A\n",
            "[79, 19, 71, 78]\n",
            "38891/39120 [============================>.] - ETA: 20s - loss: 1.28185623\n",
            "3S25_1_A\n",
            "[77, 62, 27, 22]\n",
            "38892/39120 [============================>.] - ETA: 19s - loss: 1.281819654\n",
            "2MLT_1_A\n",
            "[3, 2, 1, 4]\n",
            "38893/39120 [============================>.] - ETA: 19s - loss: 1.281816024\n",
            "1S29_1_A\n",
            "[43, 36, 6, 84]\n",
            "38894/39120 [============================>.] - ETA: 19s - loss: 1.28182059\n",
            "3O85_1_A\n",
            "[97, 76, 19, 90]\n",
            "38895/39120 [============================>.] - ETA: 19s - loss: 1.281838575\n",
            "2MF8_1_A\n",
            "[27, 0, 80, 1]\n",
            "38896/39120 [============================>.] - ETA: 19s - loss: 1.281832717\n",
            "4YXY_1_A\n",
            "[0]\n",
            "38897/39120 [============================>.] - ETA: 19s - loss: 1.281831693\n",
            "3RIM_1_A\n",
            "[58, 35, 84, 44]\n",
            "38898/39120 [============================>.] - ETA: 19s - loss: 1.281714297\n",
            "2B7Y_1_A\n",
            "[78, 25, 98, 66]\n",
            "38899/39120 [============================>.] - ETA: 19s - loss: 1.281737336\n",
            "4P6Z_1_G\n",
            "[32, 31, 70, 1]\n",
            "38900/39120 [============================>.] - ETA: 19s - loss: 1.281723537\n",
            "3J9M_62_AH\n",
            "[70, 57, 16, 3]\n",
            "38901/39120 [============================>.] - ETA: 19s - loss: 1.28178497\n",
            "3NEK_1_A\n",
            "[73, 88, 23, 47]\n",
            "38902/39120 [============================>.] - ETA: 19s - loss: 1.281732353\n",
            "1UG3_d1ug3b1\n",
            "[28, 83, 48, 71]\n",
            "38903/39120 [============================>.] - ETA: 19s - loss: 1.28178970\n",
            "5AJJ_2_B\n",
            "[36, 9, 52, 39]\n",
            "38904/39120 [============================>.] - ETA: 18s - loss: 1.281721689\n",
            "4CQI_1_A\n",
            "[62, 26, 34, 45]\n",
            "38905/39120 [============================>.] - ETA: 18s - loss: 1.281736132\n",
            "2BA2_1_A\n",
            "[6, 10, 7, 3]\n",
            "38906/39120 [============================>.] - ETA: 18s - loss: 1.28171757\n",
            "4X28_2_D\n",
            "[56, 34, 18, 40]\n",
            "38907/39120 [============================>.] - ETA: 18s - loss: 1.281722168\n",
            "2L5G_1_A\n",
            "[20, 5, 48, 27]\n",
            "38908/39120 [============================>.] - ETA: 18s - loss: 1.281724618\n",
            "3E73_1_A\n",
            "[20, 98, 84, 73]\n",
            "38909/39120 [============================>.] - ETA: 18s - loss: 1.281727406\n",
            "1UST_1_A\n",
            "[44, 37, 73, 61]\n",
            "38910/39120 [============================>.] - ETA: 18s - loss: 1.281737829\n",
            "3BZ6_d3bz6a1\n",
            "[97, 16, 77, 89]\n",
            "38911/39120 [============================>.] - ETA: 18s - loss: 1.28172394\n",
            "1XO1_d1xo1b1\n",
            "[48, 20, 47, 36]\n",
            "38912/39120 [============================>.] - ETA: 18s - loss: 1.281726450\n",
            "3LIB_1_A\n",
            "[19, 53, 45, 28]\n",
            "38913/39120 [============================>.] - ETA: 18s - loss: 1.281718382\n",
            "1HWN_2_B\n",
            "[25, 70, 37, 60]\n",
            "38914/39120 [============================>.] - ETA: 18s - loss: 1.281735119\n",
            "1T0A_1_A\n",
            "[94, 79, 69, 77]\n",
            "38915/39120 [============================>.] - ETA: 17s - loss: 1.281724534\n",
            "2M6A_1_A\n",
            "[6, 2, 8, 7]\n",
            "38916/39120 [============================>.] - ETA: 17s - loss: 1.28178770\n",
            "4MYP_1_A\n",
            "[26, 64, 8, 6]\n",
            "38917/39120 [============================>.] - ETA: 17s - loss: 1.281732578\n",
            "1Y74_1_A\n",
            "[18, 27, 46, 62]\n",
            "38918/39120 [============================>.] - ETA: 17s - loss: 1.281738708\n",
            "4KI9_1_A\n",
            "[62, 18, 23, 28]\n",
            "38919/39120 [============================>.] - ETA: 17s - loss: 1.28172431\n",
            "3LNB_1_A\n",
            "[75, 65, 22, 9]\n",
            "38920/39120 [============================>.] - ETA: 17s - loss: 1.281715101\n",
            "3LPP_d3lppd3\n",
            "[4, 41, 21, 7]\n",
            "38921/39120 [============================>.] - ETA: 17s - loss: 1.281730503\n",
            "1YLH_d1ylha1\n",
            "[45, 65, 16, 46]\n",
            "38922/39120 [============================>.] - ETA: 17s - loss: 1.281732663\n",
            "2HFG_3_R\n",
            "[9, 2, 17, 14]\n",
            "38923/39120 [============================>.] - ETA: 17s - loss: 1.281712857\n",
            "5FN8_1_A\n",
            "[78, 72, 30, 45]\n",
            "38924/39120 [============================>.] - ETA: 17s - loss: 1.281713320\n",
            "2PF2_d2pf2a2\n",
            "[43, 68, 39, 55]\n",
            "38925/39120 [============================>.] - ETA: 17s - loss: 1.281724181\n",
            "2MSF_1_A\n",
            "[78, 23, 79, 70]\n",
            "38926/39120 [============================>.] - ETA: 16s - loss: 1.281715689\n",
            "2Q79_1_A\n",
            "[81, 48, 59, 84]\n",
            "38927/39120 [============================>.] - ETA: 16s - loss: 1.281726\n",
            "2HS3_d2hs3a1\n",
            "[7, 17, 27, 18]\n",
            "38928/39120 [============================>.] - ETA: 16s - loss: 1.281710747\n",
            "2K38_1_A\n",
            "[0, 1]\n",
            "38929/39120 [============================>.] - ETA: 16s - loss: 1.28175024\n",
            "2XT9_2_B\n",
            "[43, 67, 32, 70]\n",
            "38930/39120 [============================>.] - ETA: 16s - loss: 1.281720425\n",
            "4Z64_1_A\n",
            "[33, 75, 53, 6]\n",
            "38931/39120 [============================>.] - ETA: 16s - loss: 1.281712088\n",
            "5COG_1_A\n",
            "[74, 62, 0, 14]\n",
            "38932/39120 [============================>.] - ETA: 16s - loss: 1.281730727\n",
            "3VMA_1_A\n",
            "[49, 15, 90, 81]\n",
            "38933/39120 [============================>.] - ETA: 16s - loss: 1.281729286\n",
            "3ZX3_1_A\n",
            "[75, 58, 60, 5, 36]\n",
            "38934/39120 [============================>.] - ETA: 16s - loss: 1.281722956\n",
            "2B86_1_A\n",
            "[20, 15, 43, 95]\n",
            "38935/39120 [============================>.] - ETA: 16s - loss: 1.281729207\n",
            "1J2O_d1j2oa2\n",
            "[21, 65, 54, 99]\n",
            "38936/39120 [============================>.] - ETA: 16s - loss: 1.281730142\n",
            "5IO9_1_A\n",
            "[62, 92, 14, 67]\n",
            "38937/39120 [============================>.] - ETA: 16s - loss: 1.281717037\n",
            "3MZ1_1_A\n",
            "[19, 91, 81, 87]\n",
            "38938/39120 [============================>.] - ETA: 15s - loss: 1.281721975\n",
            "3O0F_1_A\n",
            "[16, 34, 79, 31]\n",
            "38939/39120 [============================>.] - ETA: 15s - loss: 1.281811966\n",
            "3BYI_1_A\n",
            "[17, 19, 46, 34]\n",
            "38940/39120 [============================>.] - ETA: 15s - loss: 1.28181141\n",
            "4RM7_d4rm7a1\n",
            "[7, 42, 45, 16]\n",
            "38941/39120 [============================>.] - ETA: 15s - loss: 1.28182616\n",
            "2PPT_1_A\n",
            "[35, 39, 16, 65]\n",
            "38942/39120 [============================>.] - ETA: 15s - loss: 1.28182363\n",
            "2O3F_d2o3fc-\n",
            "[64, 89, 83, 41]\n",
            "38943/39120 [============================>.] - ETA: 15s - loss: 1.281823586\n",
            "2BZ8_1_A\n",
            "[78, 9, 62, 52]\n",
            "38944/39120 [============================>.] - ETA: 15s - loss: 1.281735380\n",
            "3NAT_1_A\n",
            "[40, 85, 12, 61]\n",
            "38945/39120 [============================>.] - ETA: 15s - loss: 1.281710846\n",
            "3WJZ_1_A\n",
            "[46, 37, 91, 59]\n",
            "38946/39120 [============================>.] - ETA: 15s - loss: 1.281719031\n",
            "3AZC_1_A\n",
            "[93, 45, 79, 81]\n",
            "38947/39120 [============================>.] - ETA: 15s - loss: 1.281721087\n",
            "2XSJ_1_A\n",
            "[66, 86, 61, 1]\n",
            "38948/39120 [============================>.] - ETA: 15s - loss: 1.281720102\n",
            "3IMH_1_A\n",
            "[61, 85, 97, 48]\n",
            "38949/39120 [============================>.] - ETA: 14s - loss: 1.281717207\n",
            "3EH2_1_A\n",
            "[12, 22, 80, 81]\n",
            "38950/39120 [============================>.] - ETA: 14s - loss: 1.281820281\n",
            "4PKM_1_A\n",
            "[15, 32, 90, 47]\n",
            "38951/39120 [============================>.] - ETA: 14s - loss: 1.281812300\n",
            "1YGS_1_A\n",
            "[45, 3, 28, 67]\n",
            "38952/39120 [============================>.] - ETA: 14s - loss: 1.281815049\n",
            "4WYS_d4wysd1\n",
            "[76, 46, 98, 96]\n",
            "38953/39120 [============================>.] - ETA: 14s - loss: 1.281823152\n",
            "4Z2Z_1_A\n",
            "[90, 95, 30, 36]\n",
            "38954/39120 [============================>.] - ETA: 14s - loss: 1.281838587\n",
            "4KN9_2_L\n",
            "[48, 97, 53, 17]\n",
            "38955/39120 [============================>.] - ETA: 14s - loss: 1.28186897\n",
            "5C6K_d5c6kb-\n",
            "[84, 63, 0, 37]\n",
            "38956/39120 [============================>.] - ETA: 14s - loss: 1.28183572\n",
            "2Z3Z_1_A\n",
            "[6, 49, 27, 85]\n",
            "38957/39120 [============================>.] - ETA: 14s - loss: 1.281823024\n",
            "2ZCM_1_A\n",
            "[41, 66, 72, 65]\n",
            "38958/39120 [============================>.] - ETA: 14s - loss: 1.28181247\n",
            "2YS1_1_A\n",
            "[41, 89, 46, 31]\n",
            "38959/39120 [============================>.] - ETA: 14s - loss: 1.28181956\n",
            "3IDU_1_A\n",
            "[4, 64, 83, 3]\n",
            "38960/39120 [============================>.] - ETA: 14s - loss: 1.281836373\n",
            "1WIX_1_A\n",
            "[46, 92, 0, 6]\n",
            "38961/39120 [============================>.] - ETA: 13s - loss: 1.281837992\n",
            "5CET_1_A\n",
            "[56, 81, 92, 62]\n",
            "38962/39120 [============================>.] - ETA: 13s - loss: 1.281819197\n",
            "3IML_d3imla1\n",
            "[35, 59, 23, 48]\n",
            "38963/39120 [============================>.] - ETA: 13s - loss: 1.281816105\n",
            "1YDY_1_A\n",
            "[35, 91, 60, 83]\n",
            "38964/39120 [============================>.] - ETA: 13s - loss: 1.281819671\n",
            "1IM9_d1im9e2\n",
            "[11, 94, 77, 30]\n",
            "38965/39120 [============================>.] - ETA: 13s - loss: 1.281815993\n",
            "3O34_2_B\n",
            "[49, 91, 9, 53]\n",
            "38966/39120 [============================>.] - ETA: 13s - loss: 1.281824397\n",
            "1QW9_1_A\n",
            "[26, 79, 83, 30]\n",
            "38967/39120 [============================>.] - ETA: 13s - loss: 1.281818233\n",
            "2O9U_1_X\n",
            "[54, 21, 67, 34]\n",
            "38968/39120 [============================>.] - ETA: 13s - loss: 1.281813740\n",
            "3ZRZ_2_C\n",
            "[1, 3, 4, 0]\n",
            "38969/39120 [============================>.] - ETA: 13s - loss: 1.281833347\n",
            "2D8M_1_A\n",
            "[66, 29, 25, 6]\n",
            "38970/39120 [============================>.] - ETA: 13s - loss: 1.2818187\n",
            "1GXS_1_A\n",
            "[8, 52, 93, 71]\n",
            "38971/39120 [============================>.] - ETA: 13s - loss: 1.281819402\n",
            "4PR3_1_A\n",
            "[96, 48, 34, 73]\n",
            "38972/39120 [============================>.] - ETA: 12s - loss: 1.28181261\n",
            "5BY3_1_A\n",
            "[77, 72, 38, 97]\n",
            "38973/39120 [============================>.] - ETA: 12s - loss: 1.28181421\n",
            "3J9X_1_A\n",
            "[6, 3, 5, 1]\n",
            "38974/39120 [============================>.] - ETA: 12s - loss: 1.281828118\n",
            "2A6S_1_A\n",
            "[12, 39, 49, 3]\n",
            "38975/39120 [============================>.] - ETA: 12s - loss: 1.281816326\n",
            "3BBA_1_A\n",
            "[52, 5, 17, 55]\n",
            "38976/39120 [============================>.] - ETA: 12s - loss: 1.281720871\n",
            "4V0V_2_B\n",
            "[2, 28, 19, 21]\n",
            "38977/39120 [============================>.] - ETA: 12s - loss: 1.281836501\n",
            "4PH8_1_A\n",
            "[0, 2, 3, 1]\n",
            "38978/39120 [============================>.] - ETA: 12s - loss: 1.281718903\n",
            "3JAQ_29_Z\n",
            "[76, 71, 3, 39]\n",
            "38979/39120 [============================>.] - ETA: 12s - loss: 1.281734976\n",
            "4L0P_2_B\n",
            "[56, 62, 80, 97]\n",
            "38980/39120 [============================>.] - ETA: 12s - loss: 1.281714506\n",
            "1UN8_d1un8b1\n",
            "[0, 39, 96, 81]\n",
            "38981/39120 [============================>.] - ETA: 12s - loss: 1.281814222\n",
            "4UN1_1_A\n",
            "[5, 38, 2, 31]\n",
            "38982/39120 [============================>.] - ETA: 12s - loss: 1.281733881\n",
            "2ROP_1_A\n",
            "[8, 59, 38, 85]\n",
            "38983/39120 [============================>.] - ETA: 11s - loss: 1.281711307\n",
            "1HE1_1_A\n",
            "[20, 18, 6, 14]\n",
            "38984/39120 [============================>.] - ETA: 11s - loss: 1.281727704\n",
            "3RJ1_3_C\n",
            "[58, 66, 70, 89]\n",
            "38985/39120 [============================>.] - ETA: 11s - loss: 1.28177815\n",
            "2F8Y_1_A\n",
            "[45, 3, 96, 39]\n",
            "38986/39120 [============================>.] - ETA: 11s - loss: 1.281723999\n",
            "1O8B_1_A\n",
            "[95, 2, 39, 7]\n",
            "38987/39120 [============================>.] - ETA: 11s - loss: 1.281722274\n",
            "4RYD_d4rydf2\n",
            "[31, 33, 7, 63]\n",
            "38988/39120 [============================>.] - ETA: 11s - loss: 1.28173669\n",
            "1NWZ_1_A\n",
            "[30, 71, 61, 92]\n",
            "38989/39120 [============================>.] - ETA: 11s - loss: 1.281730582\n",
            "2DO5_1_A\n",
            "[19, 7, 8, 13]\n",
            "38990/39120 [============================>.] - ETA: 11s - loss: 1.281717853\n",
            "4HK1_d4hk1a2\n",
            "[23, 98, 78, 18]\n",
            "38991/39120 [============================>.] - ETA: 11s - loss: 1.281725998\n",
            "4YF2_1_A\n",
            "[91, 98, 10, 20]\n",
            "38992/39120 [============================>.] - ETA: 11s - loss: 1.281719799\n",
            "2XGR_1_A\n",
            "[71, 96, 36, 61]\n",
            "38993/39120 [============================>.] - ETA: 11s - loss: 1.28172711\n",
            "4KSF_1_A\n",
            "[14, 1, 41, 96]\n",
            "38994/39120 [============================>.] - ETA: 11s - loss: 1.281718216\n",
            "3L0Z_1_A\n",
            "[29, 55, 18, 87]\n",
            "38995/39120 [============================>.] - ETA: 10s - loss: 1.281717448\n",
            "5D3K_1_A\n",
            "[57, 58, 45, 44]\n",
            "38996/39120 [============================>.] - ETA: 10s - loss: 1.281713382\n",
            "3TKL_2_B\n",
            "[59, 34, 21, 86]\n",
            "38997/39120 [============================>.] - ETA: 10s - loss: 1.28176268\n",
            "2I00_d2i00f1\n",
            "[5, 72, 24, 79]\n",
            "38998/39120 [============================>.] - ETA: 10s - loss: 1.281713263\n",
            "1YGP_1_A\n",
            "[74, 45, 49, 76]\n",
            "38999/39120 [============================>.] - ETA: 10s - loss: 1.281721579\n",
            "4V59_1_A\n",
            "[93, 57, 60, 79, 84]\n",
            "39000/39120 [============================>.] - ETA: 10s - loss: 1.281733289\n",
            "3DEM_d3demb2\n",
            "[74, 58, 27, 91]\n",
            "39001/39120 [============================>.] - ETA: 10s - loss: 1.28176964\n",
            "5AJ4_50_BF\n",
            "[26, 20, 61, 36]\n",
            "39002/39120 [============================>.] - ETA: 10s - loss: 1.281734365\n",
            "2ZYZ_1_A\n",
            "[42, 95, 81, 70]\n",
            "39003/39120 [============================>.] - ETA: 10s - loss: 1.281735806\n",
            "5C6B_1_F\n",
            "[79, 13, 10, 76, 22]\n",
            "39004/39120 [============================>.] - ETA: 10s - loss: 1.281734594\n",
            "2IH2_d2ih2d1\n",
            "[46, 28, 99, 40]\n",
            "39005/39120 [============================>.] - ETA: 10s - loss: 1.281837052\n",
            "4V8M_23_AP\n",
            "4V8M_23_AP\n",
            "[34, 48, 94, 81, 24]\n",
            "39006/39120 [============================>.] - ETA: 9s - loss: 1.2818 18947\n",
            "3WZ1_1_A\n",
            "[90, 53, 31, 98]\n",
            "39007/39120 [============================>.] - ETA: 9s - loss: 1.281820802\n",
            "2Q09_1_A\n",
            "[24, 69, 37, 3]\n",
            "39008/39120 [============================>.] - ETA: 9s - loss: 1.281820239\n",
            "4RWG_1_A\n",
            "[77, 54, 60, 48]\n",
            "39009/39120 [============================>.] - ETA: 9s - loss: 1.28188165\n",
            "2W3L_1_A\n",
            "[18, 34, 92, 8]\n",
            "39010/39120 [============================>.] - ETA: 9s - loss: 1.281824962\n",
            "2W2B_1_A\n",
            "[60, 53, 61, 34]\n",
            "39011/39120 [============================>.] - ETA: 9s - loss: 1.2817642\n",
            "1BUE_1_A\n",
            "[87, 84, 0, 49]\n",
            "39012/39120 [============================>.] - ETA: 9s - loss: 1.281735017\n",
            "3B0Z_1_A\n",
            "[8, 19, 50, 6]\n",
            "39013/39120 [============================>.] - ETA: 9s - loss: 1.281712345\n",
            "1J72_d1j72a2\n",
            "[62, 73, 38, 19]\n",
            "39014/39120 [============================>.] - ETA: 9s - loss: 1.281728919\n",
            "1U78_d1u78a2\n",
            "[47, 72, 37, 85]\n",
            "39015/39120 [============================>.] - ETA: 9s - loss: 1.28177504\n",
            "2WAA_1_A\n",
            "[31, 11, 54, 5]\n",
            "39016/39120 [============================>.] - ETA: 9s - loss: 1.281726267\n",
            "2F69_1_A\n",
            "[46, 39, 0, 93]\n",
            "39017/39120 [============================>.] - ETA: 9s - loss: 1.281710486\n",
            "2JXI_1_A\n",
            "[49, 30, 25, 60]\n",
            "39018/39120 [============================>.] - ETA: 8s - loss: 1.281736825\n",
            "4GZ9_1_A\n",
            "[93, 68, 59, 49]\n",
            "39019/39120 [============================>.] - ETA: 8s - loss: 1.281720430\n",
            "2K42_2_B\n",
            "[19, 1, 11, 8]\n",
            "39020/39120 [============================>.] - ETA: 8s - loss: 1.281712427\n",
            "4V6W_7_AM\n",
            "[76, 44, 49, 10]\n",
            "39021/39120 [============================>.] - ETA: 8s - loss: 1.28176985\n",
            "3E8Y_1_X\n",
            "[55, 1, 36, 20]\n",
            "39022/39120 [============================>.] - ETA: 8s - loss: 1.281718803\n",
            "4C97_1_A\n",
            "[66, 14, 6, 81]\n",
            "39023/39120 [============================>.] - ETA: 8s - loss: 1.281813614\n",
            "4HWD_1_D\n",
            "[73, 91, 23, 6]\n",
            "39024/39120 [============================>.] - ETA: 8s - loss: 1.281836407\n",
            "2YOY_1_A\n",
            "[76, 46, 61, 25]\n",
            "39025/39120 [============================>.] - ETA: 8s - loss: 1.281727880\n",
            "1NH2_4_B\n",
            "[26, 43, 71, 95]\n",
            "39026/39120 [============================>.] - ETA: 8s - loss: 1.28179694\n",
            "4XE5_3_G\n",
            "[9, 33, 2, 84]\n",
            "39027/39120 [============================>.] - ETA: 8s - loss: 1.281736812\n",
            "2F4W_1_A\n",
            "[6, 28, 78, 8]\n",
            "39028/39120 [============================>.] - ETA: 8s - loss: 1.281720774\n",
            "2F42_d2f42a2\n",
            "[69, 79, 54, 52]\n",
            "39029/39120 [============================>.] - ETA: 7s - loss: 1.2817853\n",
            "2Z63_1_A\n",
            "[89, 37, 2, 22]\n",
            "39030/39120 [============================>.] - ETA: 7s - loss: 1.28177208\n",
            "1YNA_1_A\n",
            "[88, 40, 81, 67]\n",
            "39031/39120 [============================>.] - ETA: 7s - loss: 1.28177257\n",
            "2JRZ_1_A\n",
            "[1, 58, 85, 63]\n",
            "39032/39120 [============================>.] - ETA: 7s - loss: 1.281714908\n",
            "4CAD_3_C\n",
            "[26, 65, 22, 51]\n",
            "39033/39120 [============================>.] - ETA: 7s - loss: 1.281712982\n",
            "1N2F_1_A\n",
            "[32, 92, 80, 10]\n",
            "39034/39120 [============================>.] - ETA: 7s - loss: 1.281729108\n",
            "1UHE_2_A\n",
            "[12, 27, 7, 25]\n",
            "39035/39120 [============================>.] - ETA: 7s - loss: 1.281718\n",
            "1KFW_1_A\n",
            "[95, 98, 77, 57]\n",
            "39036/39120 [============================>.] - ETA: 7s - loss: 1.281733737\n",
            "5CPS_1_A\n",
            "[50, 22, 74, 77]\n",
            "39037/39120 [============================>.] - ETA: 7s - loss: 1.281735940\n",
            "3DMY_1_A\n",
            "[47, 98, 89, 65]\n",
            "39038/39120 [============================>.] - ETA: 7s - loss: 1.281723854\n",
            "2MV7_2_B\n",
            "[4, 0, 2, 6]\n",
            "39039/39120 [============================>.] - ETA: 7s - loss: 1.28176628\n",
            "3R8Q_1_A\n",
            "[52, 77, 7, 51]\n",
            "39040/39120 [============================>.] - ETA: 7s - loss: 1.281713595\n",
            "2ZAU_1_A\n",
            "[71, 12, 28, 99]\n",
            "39041/39120 [============================>.] - ETA: 6s - loss: 1.28171114\n",
            "1IZ5_d1iz5b2\n",
            "[17, 69, 1, 9]\n",
            "39042/39120 [============================>.] - ETA: 6s - loss: 1.281725172\n",
            "2P3H_1_A\n",
            "[5, 48, 87, 40]\n",
            "39043/39120 [============================>.] - ETA: 6s - loss: 1.281714262\n",
            "5DF6_1_A\n",
            "[60, 29, 74, 89]\n",
            "39044/39120 [============================>.] - ETA: 6s - loss: 1.28178352\n",
            "2PK8_1_A\n",
            "[42, 29, 1, 30]\n",
            "39045/39120 [============================>.] - ETA: 6s - loss: 1.28177002\n",
            "2NZU_1_G\n",
            "[40, 23, 25, 89]\n",
            "39046/39120 [============================>.] - ETA: 6s - loss: 1.281712966\n",
            "3J9M_52_s\n",
            "[72, 22, 48, 80]\n",
            "39047/39120 [============================>.] - ETA: 6s - loss: 1.281727439\n",
            "1VP2_1_A\n",
            "[24, 69, 80, 73]\n",
            "39048/39120 [============================>.] - ETA: 6s - loss: 1.281713922\n",
            "4S1Z_2_F\n",
            "[61, 22, 3, 18]\n",
            "39049/39120 [============================>.] - ETA: 6s - loss: 1.281712796\n",
            "4V3P_42_LP\n",
            "[78, 68, 26, 84]\n",
            "39050/39120 [============================>.] - ETA: 6s - loss: 1.281711846\n",
            "5A9C_1_A\n",
            "[6, 7, 4, 3]\n",
            "39051/39120 [============================>.] - ETA: 6s - loss: 1.281717783\n",
            "5CWF_1_A\n",
            "[0]\n",
            "39052/39120 [============================>.] - ETA: 5s - loss: 1.281712678\n",
            "4V57_d2qp1g1\n",
            "[10, 75, 28, 60]\n",
            "39053/39120 [============================>.] - ETA: 5s - loss: 1.281737677\n",
            "4AYB_7_G\n",
            "[8, 19, 59, 30]\n",
            "39054/39120 [============================>.] - ETA: 5s - loss: 1.281724593\n",
            "2P4M_1_A\n",
            "[71, 90, 13, 72]\n",
            "39055/39120 [============================>.] - ETA: 5s - loss: 1.28172537\n",
            "3IPV_1_A\n",
            "[65, 94, 71, 53]\n",
            "39056/39120 [============================>.] - ETA: 5s - loss: 1.281716121\n",
            "1QDM_d1qdmc1\n",
            "[58, 59, 1, 13]\n",
            "39057/39120 [============================>.] - ETA: 5s - loss: 1.2817703\n",
            "2E4H_1_A\n",
            "[31, 95, 36, 79]\n",
            "39058/39120 [============================>.] - ETA: 5s - loss: 1.281736024\n",
            "4GCR_d4gcra2\n",
            "[99, 15, 95, 42]\n",
            "39059/39120 [============================>.] - ETA: 5s - loss: 1.281731390\n",
            "3I8T_1_A\n",
            "[90, 6, 4, 96]\n",
            "39060/39120 [============================>.] - ETA: 5s - loss: 1.28173942\n",
            "3LSG_1_A\n",
            "[52, 19, 64, 81]\n",
            "39061/39120 [============================>.] - ETA: 5s - loss: 1.28171268\n",
            "3N5N_1_X\n",
            "[57, 8, 33, 28]\n",
            "39062/39120 [============================>.] - ETA: 5s - loss: 1.28177631\n",
            "4TSR_1_A\n",
            "[81, 47, 82, 50]\n",
            "39063/39120 [============================>.] - ETA: 4s - loss: 1.281729106\n",
            "2CU2_1_A\n",
            "[68, 12, 46, 2]\n",
            "39064/39120 [============================>.] - ETA: 4s - loss: 1.28175211\n",
            "1A9X_d1a9xh1\n",
            "[76, 9, 71, 99]\n",
            "39065/39120 [============================>.] - ETA: 4s - loss: 1.281727872\n",
            "4TVA_1_A\n",
            "[12, 55, 4, 85]\n",
            "39066/39120 [============================>.] - ETA: 4s - loss: 1.281717537\n",
            "1F5X_1_A\n",
            "[72, 56, 41, 34]\n",
            "39067/39120 [============================>.] - ETA: 4s - loss: 1.281726833\n",
            "3SSB_3_I\n",
            "[10, 94, 85, 17]\n",
            "39068/39120 [============================>.] - ETA: 4s - loss: 1.28174691\n",
            "1D7M_1_A\n",
            "[7, 5, 6, 3]\n",
            "39069/39120 [============================>.] - ETA: 4s - loss: 1.281733172\n",
            "3O0Y_1_A\n",
            "[76, 27, 48, 79]\n",
            "39070/39120 [============================>.] - ETA: 4s - loss: 1.281622458\n",
            "5AHV_2_F\n",
            "[94, 84, 38, 17]\n",
            "39071/39120 [============================>.] - ETA: 4s - loss: 1.281638276\n",
            "3PEE_1_B\n",
            "[39, 46, 10, 25]\n",
            "39072/39120 [============================>.] - ETA: 4s - loss: 1.281619862\n",
            "3R6B_1_A\n",
            "[67, 41, 49, 33]\n",
            "39073/39120 [============================>.] - ETA: 4s - loss: 1.2816234\n",
            "4XAI_2_P\n",
            "[24, 16, 15, 10]\n",
            "39074/39120 [============================>.] - ETA: 4s - loss: 1.281614738\n",
            "5D98_1_A\n",
            "[31, 7, 36, 42]\n",
            "39075/39120 [============================>.] - ETA: 3s - loss: 1.281616665\n",
            "4U6F_73_O7\n",
            "[60, 56, 62, 89]\n",
            "39076/39120 [============================>.] - ETA: 3s - loss: 1.281635267\n",
            "1D3V_1_A\n",
            "[92, 80, 27, 25]\n",
            "39077/39120 [============================>.] - ETA: 3s - loss: 1.281622174\n",
            "3BJV_1_A\n",
            "[25, 95, 78, 49]\n",
            "39078/39120 [============================>.] - ETA: 3s - loss: 1.281624887\n",
            "4R8P_8_L\n",
            "[86, 92, 23, 96]\n",
            "39079/39120 [============================>.] - ETA: 3s - loss: 1.281629181\n",
            "2PJR_5_B\n",
            "[28, 37, 83, 49]\n",
            "39080/39120 [============================>.] - ETA: 3s - loss: 1.281637884\n",
            "2JK9_1_A\n",
            "[15, 76, 47, 98]\n",
            "39081/39120 [============================>.] - ETA: 3s - loss: 1.281723453\n",
            "3EJW_1_A\n",
            "[95, 73, 58, 71]\n",
            "39082/39120 [============================>.] - ETA: 3s - loss: 1.28178127\n",
            "2DN9_1_A\n",
            "[79, 18, 43, 22]\n",
            "39083/39120 [============================>.] - ETA: 3s - loss: 1.28176442\n",
            "3BVU_d3bvua1\n",
            "[65, 11, 29, 88]\n",
            "39084/39120 [============================>.] - ETA: 3s - loss: 1.28164754\n",
            "1FJ2_1_A\n",
            "[95, 70, 79, 3]\n",
            "39085/39120 [============================>.] - ETA: 3s - loss: 1.281618403\n",
            "4FDF_1_A\n",
            "[16, 29, 95, 14]\n",
            "39086/39120 [============================>.] - ETA: 2s - loss: 1.2816240\n",
            "4QKV_1_A\n",
            "[76, 16, 1, 17]\n",
            "39087/39120 [============================>.] - ETA: 2s - loss: 1.28168535\n",
            "1FUI_d1fuif1\n",
            "[57, 67, 7, 3]\n",
            "39088/39120 [============================>.] - ETA: 2s - loss: 1.281633371\n",
            "2NT0_1_A\n",
            "[6, 39, 60, 66]\n",
            "39089/39120 [============================>.] - ETA: 2s - loss: 1.281627762\n",
            "3QPD_1_A\n",
            "[11, 68, 90, 25]\n",
            "39090/39120 [============================>.] - ETA: 2s - loss: 1.281636456\n",
            "2P8I_1_A\n",
            "[68, 51, 49, 63]\n",
            "39091/39120 [============================>.] - ETA: 2s - loss: 1.28163060\n",
            "4OKR_1_A\n",
            "[16, 55, 81, 73]\n",
            "39092/39120 [============================>.] - ETA: 2s - loss: 1.281611683\n",
            "3VDP_1_A\n",
            "[75, 25, 4, 7]\n",
            "39093/39120 [============================>.] - ETA: 2s - loss: 1.281634942\n",
            "2A3Z_3_C\n",
            "[37, 36, 32, 13]\n",
            "39094/39120 [============================>.] - ETA: 2s - loss: 1.281637457\n",
            "3IRM_1_A\n",
            "[31, 1, 19, 96]\n",
            "39095/39120 [============================>.] - ETA: 2s - loss: 1.281610335\n",
            "4I9D_1_A\n",
            "[48, 44, 6, 64]\n",
            "39096/39120 [============================>.] - ETA: 2s - loss: 1.281621008\n",
            "2JI4_1_A\n",
            "[26, 21, 66, 68]\n",
            "39097/39120 [============================>.] - ETA: 2s - loss: 1.28169125\n",
            "3LLM_1_A\n",
            "[44, 28, 1, 51]\n",
            "39098/39120 [============================>.] - ETA: 1s - loss: 1.28164001\n",
            "3UMC_1_A\n",
            "[20, 66, 43, 10]\n",
            "39099/39120 [============================>.] - ETA: 1s - loss: 1.281637879\n",
            "3LQC_1_A\n",
            "[10, 34, 90, 8]\n",
            "39100/39120 [============================>.] - ETA: 1s - loss: 1.281621814\n",
            "4MS8_3_A\n",
            "[1, 53, 97, 59]\n",
            "39101/39120 [============================>.] - ETA: 1s - loss: 1.281634012\n",
            "4ATY_1_A\n",
            "[26, 77, 23, 86]\n",
            "39102/39120 [============================>.] - ETA: 1s - loss: 1.281632705\n",
            "3ALQ_2_R\n",
            "[60, 57, 85, 30]\n",
            "39103/39120 [============================>.] - ETA: 1s - loss: 1.28161514\n",
            "1OGL_1_A\n",
            "[40, 60, 17, 90]\n",
            "39104/39120 [============================>.] - ETA: 1s - loss: 1.281636716\n",
            "4RMA_1_A\n",
            "[38, 57, 64, 65]\n",
            "39105/39120 [============================>.] - ETA: 1s - loss: 1.281621518\n",
            "1RYJ_1_A\n",
            "[14, 94, 43, 52]\n",
            "39106/39120 [============================>.] - ETA: 1s - loss: 1.281629148\n",
            "2WVG_d2wvgf1\n",
            "[33, 38, 52, 80]\n",
            "39107/39120 [============================>.] - ETA: 1s - loss: 1.281612923\n",
            "3C6F_1_A\n",
            "[86, 16, 67, 24]\n",
            "39108/39120 [============================>.] - ETA: 1s - loss: 1.281632654\n",
            "1E6V_d1e6ve2\n",
            "[18, 7, 20, 34]\n",
            "39109/39120 [============================>.] - ETA: 0s - loss: 1.281612973\n",
            "1YEL_1_A\n",
            "[24, 36, 66, 75]\n",
            "39110/39120 [============================>.] - ETA: 0s - loss: 1.281611465\n",
            "4IPB_1_A\n",
            "[25, 33, 6, 58]\n",
            "39111/39120 [============================>.] - ETA: 0s - loss: 1.281620580\n",
            "2N2C_1_A\n",
            "[19, 23, 16, 37]\n",
            "39112/39120 [============================>.] - ETA: 0s - loss: 1.28162702\n",
            "1R9H_1_A\n",
            "[18, 26, 41, 34]\n",
            "39113/39120 [============================>.] - ETA: 0s - loss: 1.281624685\n",
            "2MPQ_1_A\n",
            "[19, 7, 45, 65]\n",
            "39114/39120 [============================>.] - ETA: 0s - loss: 1.281623277\n",
            "5AJ4_65_BY\n",
            "[31, 48, 61, 84]\n",
            "39115/39120 [============================>.] - ETA: 0s - loss: 1.281617270\n",
            "3R6M_d3r6md2\n",
            "[73, 76, 6, 65]\n",
            "39116/39120 [============================>.] - ETA: 0s - loss: 1.281611512\n",
            "2QIH_1_A\n",
            "[2, 34, 13, 17]\n",
            "39117/39120 [============================>.] - ETA: 0s - loss: 1.281615529\n",
            "2M5T_1_A\n",
            "[52, 3, 74, 63]\n",
            "39118/39120 [============================>.] - ETA: 0s - loss: 1.281620424\n",
            "2NQ3_d2nq3a1\n",
            "[39, 17, 2, 41]\n",
            "39120/39120 [==============================] - 3428s 88ms/step - loss: 1.2816 - val_loss: 1.2832\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Sparks/SingleSequenceResnetAugmentationsModel/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ehLs_vpwY8D"
      },
      "source": [
        "#Evaluation\n",
        "bs_test = 1\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "#Load test data\n",
        "f3 = open(TEST_PATH, \"r\")\n",
        "sequences_test = []\n",
        "structures_test = []\n",
        "while True:\n",
        "  line = f3.readline()\n",
        "  if len(line) == 0:\n",
        "    break\n",
        "  if ((line).find('>') != -1):\n",
        "    sequence_test = f3.readline()\n",
        "    structure_test = f3.readline()\n",
        "    sequences_test.append(sequence_test)\n",
        "    structures_test.append(structure_test)\n",
        "\n",
        "#Initialize test data generator\n",
        "data_generator_test = DataGeneratorValidTest(sequences=sequences_test, structures=structures_test, batch_size=bs_test)\n",
        "\n",
        "#Load model weights\n",
        "model.load_weights(CHECKPOINT_PATH)\n",
        "\n",
        "#Evaluate the model\n",
        "results = model.evaluate(x=data_generator_test)\n",
        "print(\"test loss, test accuracy: \", results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}